{"/jekyll/2023-10-28-method_level_function_unit_testing.html": {
    "title": "Testing | Method-Level Functional Unit Testing (Unfinished)",
    "keywords": "software software_qualitiy Jekyll",
    "url": "/jekyll/2023-10-28-method_level_function_unit_testing.html",
    "body": "Software testing course notes from CCU, lecturer Nai-Wei Lin. 這章節主要開始介紹從 Method 為單位的 Specification，來對每個 Method 進行獨立的 Unit testing 以下是本章的主要內容 Combinational logic Decision tables Constraint logic programming UML/OCL Constraint logic graphs Constraint logic programming 4.1 Combinational Models Combinational logic 是一種有效組合各種不同輸入條件的方法，並使不同輸入條件的組合來選擇輸出動作變的可能 Many applications must select output actions by evaluating combinationsof input conditions (constraints on input variables). Input variables can also be either parametersof the method, static variables of the class, or instance variables of the object. Combinational logic provides an effective language for these kinds of condition-action relationships. 例如一個 Method 有多個參數，而這些參數可能會有不同的組合，這些組合可能會對應到不同的輸出，這時候我們可以使用 Combinational logic 來描述這些組合，並且對應到不同的輸出 4.1.1 Equivalence Class Partitioning Decision Tables A combinational model uses a decision tableto represent the condition-action relationships and partition equivalence classes. A decision table has a condition sectionand an action section. The condition section lists constraints on inputvariables. The action section lists outputto be produced when corresponding constraints are true. 以 Decision table 來決定條件的組合，並且對應到輸出 Example: Class Triangle 假如有一個 Triangle Java class 如下，Triangle constructor 只要滿足 {sa + sb &gt; sc, sa + sc &gt; sb, sb + sc &gt; sa} 就視為合法的 Tringle，否則拋出 Exception。 classTriangle { inta;// lengths of sides intb; intc; public Triangle(intsa, intsb, intsc); public String category( ); }; 以這三個條件我們能獲得以下的 Decision table，在去除不可能發生的條件後，得到最後可能產生的 Input data。 這樣我們就能得到足夠測試 {sa + sb &gt; sc, sa + sc &gt; sb, sb + sc &gt; sa} 三個 Boundaries 的測試資料，並測試 Tringle constructor 是否能正確的拋出 Exception。 Constraint Logic Graph 可以透過 Constraint logic programming 來產生測資，以下是 Triangle constructor 的 Invalid Constraint logic graph， 會產生三個 Invalid equivalence classes，加上 Valid equivalence classes 就能得到跟上面 Decision table 一樣的測試資料。 Example: Method category The method category() returns the category of a Triangle object based on the lengths of its three sides: “Equilateral”, “Isosceles”, or “Scalene”. A Triangle object is an “Equilateral” triangle if it satisfies the following threeconstraints: {a = b, a = c, b = c}. A Triangle object is an “Isosceles” triangle if it satisfies one and only one of the following three constraints: {a = b, a = c, b = c}. Otherwise, It is a “Scalene” triangle. 關於 category 我們也可以透過 Decision table 來產生測試資料，以下是 category 的 Decision table 因為在 Triangle constructor 的測試中已經測試過 Valid equivalence classes，所以這裡只要使用 {a = b, a = c, b = c} 這三個條件約束就可以， 並且也可以透過 CLP 來產生測試資料，這樣我們就能測試完所有 category 有可能的路徑。 public String category( ) { if (a == b &amp;&amp; b == c) return \"Equilateral\"; else if (a == b || a == c || b == c) return \"Isosceles\"; else return \"Scalene\"; } 拿上面的程式碼來做比對，實際上這個 Decision table 就是去走過所有在程式中可能發生的路徑。 因為篇幅的關係這裡不會介紹 CLP 如何撰寫，考慮在之後另外寫一篇文章說明 CLP 如何使用 4.2 Unified Modeling Language Unified Modeling Language(UML) 是一種用於可視化、規範、建構和文件化軟體系統工程的圖形化語言 UML 提供一種標準化的方式來編寫系統的藍圖，包括概念性的事務，如業務流程和系統功能，以及具體的事務，如程式描述、Database 架構和可重用的軟體元件 4.2.1 UML Diagrams 在 Software testing 這門課中主要會用到的是 Class diagram、Sequence diagram、State machine diagram UML 2 defines thirteenbasic diagram types, divided into two general sets: Structural Modeling Diagrams: Structure diagrams define the staticarchitecture of a model. They are used to model the ‘things’ that make up a model. Behavioral Modeling Diagrams: Behavior diagrams capture the varieties of dynamicinteraction and instantaneous state within a model as it executes over time. 在之前我有更詳細的關於 UML 的介紹，詳細可見 Unified Modeling Language Concepts 4.2.2 Class Diagrams Class Diagram 描述了一個 Class 有哪些 Attributes 和 Methods，而不是詳細的實作細節 Class Diagram 在說明 Class 或 Interface 之間的關係時最為有用 Association(關聯)和 Generalization(泛化)分別表示連接和繼承 關於類圖可以看之前的筆記，有更詳細的描述 UML Structure Diagrams Introduction 1.1 Class diagram Association 表示兩個 Class 之間有所關聯，例如: Course 和 Student 之間有一個關聯，關聯可以是多對多的關係 Generalization 表示的是兩個 Class 之間有繼承關係，例如: Animal 和 Dog 之間有一個繼承關係 4.3 Object Constraint Language 通常只使用 UML 是不足以完全規範一個軟體系統 所以還需要 Constraint 來完全規範一個軟體系統 Constraint 是對軟體系統的一個或多個值的限制 Object Constraint Language(OCL) 是一種基於 Text 的語言，用於描述這些 Constraints 上圖展示了一個 Flight 的 Class invariant，如果 type == passenger，那麼 airplane.type 也必須為 passenger，同樣的 cargo 也只能對應 cargo 這意思就如果是客運航班就要對應客機，貨運航班就要對應貨機。 4.3.1 Kinds of Constraints Class invariant(不變式): a constraint that must alwaysbe met by all instances of the class. Precondition of an operation(操作前提): a constraint that must always be true beforethe execution of the operation. Postcondition of an operation(操作後置): a constraint that must always be true afterthe execution of the operation. 例如: 一個校園借書系統，那麼 Class invariant 必須為 Student，因為校外人士不能借閱， 而還書時 Precondition 必須為至少要有那本要還的書，Postcondition 則必須沒有已經還回去的書。 4.3.2 Constraint Context and Self Every OCL expression is bound to a specific context. The context is often the element (classor method) that the constraint is attached to. The context may be denoted within the expression using the keyword ‘self’. ‘self’ is implicit in all OCL expressions. Similar to ‘this’ in Java. 例如: 以下的 OCL，context Person 宣告了這個 Constraint 是屬於 Person 這個 Class，而 self.age &gt;= 0 則專指這個 Person attribute age &gt;= 0 context Person inv: self.age &gt;= 0 4.3.3 Notation OCL 可以單獨寫在一個文件中，也可以寫在 UML 的 Class diagram 裡面，這些表示方法都是相同的 4.3.4 Elements of an OCL Expression In an OCL expression these elements may be used: basic types: String, Boolean, Integer, Real. classifiers from the UML model and their features attributes, and class attributes query operations, and class query operations (i.e., those operations that do not have side effects) associations from the UML model Including Rolenames at either end of an association Basic types 以下表示了 OCL 的基本型別，可以使用在 OCL 的表達式 context Airline inv: name.toLower = 'klm' context Passenger inv: age &gt;= ((9.6 -3.5)* 3.1).floor implies mature = true Attributes OCL 中有專指 Object 實例的 Attribute，也有專指 Class 的 Attribute Class attribute 會在所有 Object 實例中共享 Object attribute 則是每個 Object 實例都有自己的 Attribute 以下是一個例子: -- Object attribute context Flight inv: self.maxNrPassengers&lt;= 1000 -- Class attribute context Passenger inv: age &gt;= Passenger.minAge The @Pre Keyword The @pre keyword indicates the value of an attribute at the start of the execution of the operation The keyword must be postfixed to the name of the item concernedsize = size@pre + 1 例如 size = size@pre + 1: - size@pre 表示在執行這個 Operation 前的 size - size 表示在執行這個 Operation 後的 size 4.3.5 OCL Examples with CLG 假如我們有以下 Java class Triangle，我們分別針對他的 Constructor 和 Method category 以及 Class invariant(Triangle Objects) 來撰寫 OCL class Triangle { int a; // lengths of sides int b; int c; public Triangle(int sa, int sb, int sc); public String category( ); }; Example: Triangle Objects 一個 Triangle 應該永遠滿足三邊長的條件，所以使用 Class invariant 來限制所有 Triangle 的三邊長 context Triangle inv: a + b &gt; c and a + c &gt; b and b + c &gt; a Example: Constructor Triangle context Triangle::Triangle(intsa, intsb, intsc) pre IllegealArgException: sa + sb &gt; sc and sa + sc &gt; sb and sb + sc &gt; sa post: a = sa and b = sb and c = sc 以上的 OCL 表示 Triangle 這個 Constructor Triangle 的 Precondition 和 Postcondition Precondition: 一個 Triangle constructor 的輸入必須滿足 sa + sb &gt; sc and sa + sc &gt; sb and sb + sc &gt; sa Postcondition: Triangle constructor 執行後應該滿足 a = sa and b = sb and c = sc Example: Method category 以下是一個 Method category 的 OCL，這個 OCL 會檢查 Triangle 的三邊長，並且回傳 Triangle 的類型 contextTriangle::category(): String post: result= if a@pre = b@pre then ifa@pre = c@pre then 'Equilateral' else 'Isosceles' endif else if a@pre = c@pre then 'Isosceles' else if b@pre = c@pre then'Isosceles' else 'Scalene' endif endif endif Constraint Logic Graph 我們依照上面的 Constructor Triangle 和 Method category 來建立 CLG，得到以下兩張圖，就可以以此來生成測試資料 例如我們想測試 category，能發現在 CLG 上一共有 5 條不同的路徑，我們把第一條路徑的條件放入 CLP 中求解，就能得到測試第一條路徑的測試資料。 Constraint, Pre a@+b@&gt;c@, a@+c@&gt;b@, b@+c@&gt;a@ Input Output a@=b@, a@=c@, result=’Equilateral’ 1, 1, 1 Equilateral a@=b@, a@!=c@, result=’Isosceles’ 2, 2, 1 Isosceles a@!=b@, a@=c@, result=’Isosceles’ 2, 1, 2 Isosceles a@!=b@, a@!=c@, b@=c@, result=’Isosceles’ 1, 2, 2 Isosceles a@!=b@, a@!=c@, b@!=c@, result=’Scalene’ 2, 3, 4 Scalene Post a = a@, b = b@, c = c@     依照這個 Table 這樣就能夠產生五條全部路徑的測試案例 Last Edit 10-29-2023 15:56"
  },"/jekylls/2023-10-26-syntax_analysis.html": {
    "title": "Compiler | Syntax Analysis Notes (Unfinished)",
    "keywords": "Compiler Jekylls",
    "url": "/jekylls/2023-10-26-syntax_analysis.html",
    "body": "Compilers course notes from CCU, lecturer Nai-Wei Lin. Syntax Analysis(語法分析) 在這個階段會檢查 Lexical Analysis 返回的 Token 是否符合語法規則，並且建立語法樹 以下是這個章節的主要大綱，Bison 不會在這篇介紹如何使用，主要是介紹 Syntax analysis 的概念 Introduction to parsers Context-free grammars Push-down automata Top-down parsing Buttom-up parsing Bison -a parser generator 4.1 Introduction to parsers 在編譯器模型中 Systax analysis 從 Lexical analysis 獲取由 Token 所組成的字串，我們期望語法分析器能夠以易於理解的方式回報語法錯誤。 概念上語法分析需要建構一個 Parse tree 傳遞給 Compiler 的其餘部分進行進一步處理，但實際上 Parse tree 並不需要明確的建構， 因為檢查與翻譯可以與 Parsing 交錯完成。 Last Edit 10-26-2023 17:50"
  },"/jekyll/2023-10-19-cpu_scheduler.html": {
    "title": "OS | CPU Scheduler (Unfinished)",
    "keywords": "OS Jekyll",
    "url": "/jekyll/2023-10-19-cpu_scheduler.html",
    "body": "Operating System: Design and Implementation course notes from CCU, lecturer Shiwu-Lo. 本章節會主要介紹 Linux Scheduler，Linux Scheduler 現在的的目標是: 如何從「好變為更好」 Noun, Concept definition 2.4 Scheduler 2.6 O(1) Scheduler 2.6 - 5.3 Complete fair scheduler(CFS) Linux Kernel 2.4 是一個非常長壽的版本，持續了大約 10 年左右，但即便這樣一個這麼長壽、穩定的 Scheduler， Linux Kernel 設計者仍然在考慮如何讓她變得更好。 4.1 Noun, Concept definition 4.1.1 Task 在 Linux 中，Process 和 Thread 都是 Task Process 之間不會共用任何資源，尤其是 Memory Thread 則是幾乎共用所有資源，尤其是 Memory Task 的生命週期中分為兩種情況 Using CPU Waiting，例如: Waiting mutex, I/O … Task 在使用 CPU 時分為: 執行於 User mode/Kernel mode 在 Linux Task 可以執行在 User/Kernel mode，改變模式稱作 Mode change，而 Kernel Thread 專指只有 Kernel mode 的 Task，例如: Device Driver Task &amp; Scheduling 以下是一個 Task 的生命週期，這裡從 Scheduler 角度來看的話主要影響的是兩個部分: Waining(semaphore): 怎麼在 Waiting 時，讓 Task 的使用率最大化 Cooperative multitasking(協同運作式多工), Preemptable OS(搶占式多任務處理) 4.1.2 Scheduler Types Preemptive OS: Task 會有一個 Time slice 執行，例如: 1/1000 Sec，執行結束就要做切換 Non-preemptive OS: 就是指只有 Task 自己放棄 CPU 使用權時，才會做 Context Switch Task 執行結束，這樣當然就交出 CPU 使用權 Task 發出 Blocking I/O request 因為要等待 I/O 完成，因此也會交出 CPU 使用權 當然也有 Async I/O，Vectored I/O 等方法，這裡先不討論 Last Edit 10-18-2023 23:21"
  },"/jekyll/2023-10-18-process_thread.html": {
    "title": "OS | Process and Thread",
    "keywords": "OS Jekyll",
    "url": "/jekyll/2023-10-18-process_thread.html",
    "body": "Operating System: Design and Implementation course notes from CCU, lecturer Shiwu-Lo. 這章節主要是介紹 Process 跟 Thread Process model Process Life Cycle Communication model between Process &amp; Process Communication method between Process &amp; Process Producer-consumer problem Context switch main overhead (使用 Thread 的動機) Thread model Process model 3.1 Process Concept An OS executes a variety of programs: Batch system – jobs Time-shared systems – user programs or tasks Process ≈ Task ≈ Job Process - a process is an instance of a program in execution +Program code (text section) +Program counter &amp; registers (CPU status) +Stack +Data section Batch system(批次系統): 是指被時間安排在 PC 上運行，不需要與使用者互動的工作 3.2 Process Memory 每個 Process 通常有自己完整的 Address space 32bit 為例，每個 Process 有 4GB 的 Address(Memory) space 64bit 的 x64 CPU，因為成本的考量，通常只會使用 48bit 的 Address space，也就是 256TB (遠超 Disk 的容量) Address space 表示一個 Process 最多能使用多少 Memory，實際上 RAM 通常遠小於 Process 的 Address space 通常將 Process 的 Address space 分為兩個部分，上半部分為 OS Kernel，下半部分為 Process 的 User space 以 64bit 為例，一個 Process 的 Memory address(User space) 為 0~128TB，Kernel 則為 256TB(264) 往下 128 TB 的部分 User space: 00000000 00000000 ~ 00007FFF FFFFFFFF Kernel: FFFF8000 00000000 ~ FFFFFFFF FFFFFFFF Why kernel/user space need half of the memory space 每個 Process 的 Kernel Space 都是共用的，在 SMP Processor 上所有 Process 都共用同一個 Linux Kernel DRAM 有很多用途，例如: 作為 I/O 加速的 Buffer/Cache I/O Buffer: CPU 的資料可以先寫入 DRAM buffer，然後再由 DMA controller 將資料寫入 Disk I/O Cache: Disk 的資料可以寫入 DRAM cache，因為 I/O request 會產生 overhead 讀取 4kb 和讀取 16kb 的速度是一樣的，那乾脆一次從 cache 讀取 16kb OS 會把相關的資料放在 cache，這樣下次讀取就可以直接從 cache 讀取，而不用再次讀取 Disk When Multi-Process running, what does the memory look like to users/programmers 這裡只討論 User space，一次只會執行一個 Process 這三個 Proces 各自有完整的 user space，當 Context switch 時除了 CPU 控制權會被交換外， 也會重新進行 Memory mapping(修改 MMU 的 mapping table) Internal memory configuration method of the Process 一個 Process 是怎麼在 Memeory 中進行分配的狀態 Local variables: 在 Stack 中分配 Global variables initialized value: 在 initialized data 分配 uninitialized value(BSS): 在 unitialized data 分配 Dynamic memory allocation: 在 Heap 中分配 Program code: 在 Text section 分配，例如 Main, malloc function 的指令 通常 OS 一次會給 4096(4K) 大小的 Memory，並且會清空，這樣就不會有安全性問題，但寫程式時最好只預設 BSS 段的值會是 0，例如 Stack 可能會因為因為 Call/Return 的關係，而有一些不可預期的值。 但即使這樣也盡量要給予初始值，例如: int a = 0;，減少不可預期的錯誤發生 The position of variable in the Process 在一個程式執行時 Text/initilized section 幾乎就是直接從 Disk copy 到 Memory Unitialized section 因為沒有資料儲存，所以可以透過一個資料結構來描述，並放在執行檔的 Header 中 Stack/Heap 會隨著程式執行而變大，所以放在最後面並且往下/上成長 但是 Stack 通常會被限制在固定大小，例如: 一開始分配 16KB，當需要成長時就 OS 就再分配 4KB，但最多長到 8MB，這個可以透過 ulimit 查看或修改 如果一個 Memory 被寫入 DRAM 後，但長時間沒有被使用，那麼這個 Memory 就會被 swap out 到 Disk，這樣就可以釋放出 DRAM 給其他 Process 使用 Linux kernel uses Logical meaning to manage memory segments of processes Linux Kernel 透過 task_struct, mm_struct, vm_area_struct 來管理 Process 的 Memory: task_struct: 描述 Task 相關的所有資訊 mm_struct: 描述 Task 的記憶體相關的資訊，例如: 該 Task 的 Memory space 有哪些 area vm_area_struct: 描述該 area 相關的資訊，例如: 該 area 的起始位置、大小、權限等等 例如除了 Text area 是可 Read, Execute(rx)，其他的 area 都是可 Read, Write(rw) Example: Lab main.c 我們用一個簡單的程式 main.c 來做測試: int a = 2; int b; int main() { int c, d; int* e = (int*)malloc(sizeof(int)*1024); printf(\"pid = %d\\n\", getpid()); printf(\"main = %p\\n\", main); printf(\"printf = %p\\n\", printf); printf(\"a=%p, b=%p, c=%p, d=%p, *e=%p\\n\", &amp;a, &amp;b, &amp;c, &amp;d, e); getchar(); return 0; } /* benson@vm:~/OSDI$ ./main.exe pid = 190697 main = 0x55d00a13218a printf = 0x7f94c1974cc0 a=0x55d00a135010, b=0x55d00a135018, c=0x7ffe4cb7e4b8, d=0x7ffe4cb7e4bc, *e=0x55d00aca62a0 */ 然後在 /proc//maps 中可以看到該 Process 的 Memory configuration: Address space layout randomization 如果我們重新執行一次程式，會發現 Address 又不一樣了，這是為了避免被攻擊，就是 Address space layout randomization(ASLR) 這樣可以避免攻擊者使用記憶體裡面的函數，例如: libc 裡面的 system()，如果可以執行 system()，那麼就可以執行任意的指令 OS 會隨機產生每個 Section 的 Address 幾乎所有的 OS 都支援 ASLR，例如: Linux, BSD, Windows, MacOS 但是 ASLR 也有缺點，如果不使用 ASLR 那就可以把常用的 Function 放在固定的位置，這樣就可以加速程式的執行 目前大部分硬體都使用 phy.cache 可以降低這部分的影響 現在的 Linux Kernel 都會使用 ASLR，即是 KASLR Program in Memory 目前大部分的作業系統設計中，執行檔與在 Memory 中的結構幾乎一樣，OS 只需要 Copy(mapping) 就可以執行了 例如: Linux 的 ELF(Executable and Linkable Format), Microsoft 的 PE(Portable Executable) 將執行檔 Mapping 1:1 映射到 Memory，這樣讓 OS 的工作能變得很簡單 延伸閱讀: Memory Layout of Kernel and UserSpace in Linux. Process Life Cycle 3.3 Process Life Cycle 下面是一個 Unix Process Life Cycle，但在這裡加入了一些 Linux 的觀念 Parent Process 通常是 Shell，透過 fork() 產生 Child Process Ready queue: 當一個新的 Process 產生會進入 Ready Queue，等待 CPU 資源 Running: 如果 Scheduler 選擇到該 Process，那麼就會進入 Running 狀態 Waiting: 在 Linux 中 Waiting 分為兩種 Interruptible: 可以被 Signal 打斷 Uninterruptible: 不能被 Signal 打斷，但是少數例外下例如 Kill -9 還是能夠 Interruptible Terminate: 這裡需要由 OS 去回收分配給 Process 的資源，例如: Memory, Kernel 中儲存的 Process 相關資訊 Zombie: Linux 中會剩下一個大約 4KB ~ 8KB 的 Task struct，稱作 Zombie 保留這個 Zombie 是為了讓 Parent Process 可以透過 wait() 取得 Child Process 的資訊， 這裡如果 Parent 沒有正確的回收 Child Process，但還是持續運行，這樣 Zombie 就會越來越多。 但如果 Parent 也結束了，那麼 Zombie 就會被 init process 回收，這樣就不會有 Zombie Process #include &lt;stdlib.h&gt; #include &lt;sys/types.h&gt; #include &lt;unistd.h&gt; int main() { pid_t child_pid; /* Create a child process */ child_pid = fork(); if (child_pid &gt; 0) { /* Parent sleep */ sleep(60); } else { /* This is clild process will end immediately */ printf(\"Child pid %d\\n\", getpid()); exit(0); } return 0; } 這個程式會印出 child_pid，此時去 top -p child_pid 就可以看到 child 變成 zombie 狀態。 fork() 會返回 child pid，但在 child process 中 child_pid 會是 0 3.4 Tack Contol Block(TCB, PCB) Process control block ≈ Task control block Process control block(PCB) 就是 OS 用來管理 Process 的資料結構，通常會包含以下資訊: Process state: 執行的狀態，例如: Running, Waiting, Ready CPU information: Process 的狀態，例如: PC, Register Memory information: Memory 狀態，例如: Text, Data section Schedule information: 排程資訊，例如: Priority I/O status information: I/O 狀態，例如: File descriptor Using resource: Process 使用的資源，例如: File, I/O device … 3.5 Three Scheduler Model Scheduler 不是只有 CPU Scheduler，還有 Long-term Scheduler, Mid-term Scheduler: Long-term Scheduler(Job scheduler): 決定哪些 Process 要進入 Ready Queue，通常在很大型的主機上，例如: 台灣杉 Linux 中並沒有 Long-term Scheduler，Task 產生後就會進入 Ready Queue Mid-term Scheduler(Swapper): 當 Degree of Multiprogramming 過高時可能造成(thrashing)，將一些 Task swap out 到 Disk，等到資源足夠時再 swap in Linux Kernel 目前也沒有 Mid-term Scheduler，但 Linux 依照 Task 記憶體的使用情況，在 Memory 不足時會將不活躍的 Task swap out 到 Disk Short-term Scheduler: CPU Scheduler 大部分的 OS 只有 CPU Scheduler，針對各種事件有專屬的 Waiting Queue，例如: 例如 I/O, Semaphore thrashing(輾轉現象) 指的是當虛擬記憶體被使用過度，導致大部分的工作在處理 Page fault 所造成的 Page Replacement，這樣就會造成 CPU 效能下降 3.6 Context Switch(ctx-sw) 目前主流的 OS 都是只有 Task 執行在 Kernel Space 時才能進行 Context switch Context switch 主要是切換 Register 與 Memory 的內容 Context switch 的 overhead 主要是發生在 Cache memory 的更新 首先 TaskA Mode change 到 Kernel mode 然後將 TaskA 的資訊(TCB) 儲存起來 載入 TaskB 的資訊 最後 TaskB Mode change 到 User mode Scheduler 也就是策略的部分主要是用 C 寫的，但切換的部分是用 Assembly 寫的，因為要直接操作 Register 3.7 Processes are divided into I/O and CPU I/O Bound process - I/O time » CPU time 例如: ftp server CPU Bound process - CPU time » I/O time 例如: image processing 如果可以選擇的話，讓系統中同時存在 I/O Bound process 與 CPU Bound process，可以讓系統的效率最大化 通常 I/O Bound 的優先權比較高，因為趕快讓 CPU 發出命令給 I/O device，然後就可以去執行其他的 Task I/O Bound 通常只需要一小部分的 CPU 資源，如果設定成 CPU Bound 優先權較高，反而會造成 I/O Bound 的 Task 在結束一段 I/O 後還要等待 CPU Bound 的 Task 結束 造成 CPU 使用率下降 3.8 Process Creation Linux 中可以透過 fork, vfork, clone 來產生 Process 實際上這三個在 Kernel 中都是呼叫 do_fork() 來完成 Linux 中 pid 0 是 idle process，優先權最低，只負責讓 CPU 進入睡眠狀態 通常也叫做 swapper，每顆 core 有一個自己的 idle task pid 1 是系統中第一個 user space 的行程，負責作業系統的初始化 例如: 當電腦啟動時的 Daemon Process fork 出的 Process 其程式碼與父 Process 完全相同，如果要載入新的程式碼到該 process 中，使用 execve 系統呼叫 如果需要大量的執行 execve，那使用 vfork 會比較好，因為 vfork 會 Block parent process pid 0 Process(idle process) 也是唯一沒有使用 fork() 產生的 Process，因為 pid 0 是系統啟動時就產生的 Process 使用 pstree -p 就能看到，所有的 Process 都是由 systemd(pid 1) 產生的 例如: 從 bash 去執行 ls 會有以下的流程 bash fork 出一個 child process，然後 parent process wait() child process 透過 execve() 去執行 ls ls 執行完後，透過 exit() 結束，回到 parent process 3.9 Process Termination 在 UNIX-Like OS 中，如果一個 Process Terminate，會變成 Zombie 狀態，Zombie Process 是無法被 kill 的，只能透過 Parent Process 使用 wait() 來回收 透過 wait() Parent Process 可以取得 Child Process 的結束狀態，例如: 使用了多少系統資源 基於特定的需求，也可以直接將 Process kill 掉 kill -9 pid 會直接發送 SIGKILL(signal 9) 給該 Process，讓該 Process 立即結束 kill pid 則是發送 SIGTERM(signal 15) 給該 Process，讓該 Process 優雅的結束自己 有些 OS 設計 Parent process kill 掉後，Child process 也會被 kill 掉 UNIX-Like OS 中，如果 Parent process 被 kill 掉，Child process 會被 init process(pid 1) 接管 init 內部有一個無窮迴圈，會不斷的執行 wait()，這樣就可以回收所有的 Zombie Process 例如我們可以透過 nohup 或 screen 來讓 Process 在背景執行，這樣就不會因為 Terminal 被關閉而被 kill 掉 Communication model between Process &amp; Process OS 保證每個 Process 之間都可以獨立的運行 但如果真的 Process 都完全獨立運行，那系統就會變得很難使用 例如: copy-paste 所以 OS 會提供一些方法讓 Process communication 3.10 Interprocess Communication(IPC) IPC 是指可以讓兩個獨立的 Process 互相傳遞訊息，傳遞訊息的目的多半是 傳遞資訊，例如: copy-paste、information sharing 同步，例如: Parallel computing 模組化設計，例如: 將 Request 與 Worker 分開 IPC Model 這裡談的主要是 IPC 的分類，而不是 IPC 的實作 如何在 Process 之間建立 IPC 可以建立多少條 IPC 在 Process 之間 可否多個 Process 同時使用同一個 IPC IPC 有沒有容量限制 IPC 中每一個 Message 的大小是否是固定的 IPC 是單向的還是雙向的 Direct communication(直接傳遞): 每個需要通訊必須明確的指定接收者或發送者 可以是單向也可以是雙向的 例如: Pipe Indirect communication(間接傳遞): Message 是發送到 Mailbox 中然後由 Receiver 自行取出 是雙向的，並且可以建立多條 IPC 或讓多個 Process 一起接收 因為有 Mailbox 所以就要考慮 Buffer 的問題 沒有 Buffer: 那就必須等到 Recv 結束，發送者才能繼續執行 優點是速度通常比較快，透過 Scheduler 或許某些資訊可以放在 Register 中直接傳遞 固定 Buffer: 發送者將資料 Send 到 Buffer 中就可以繼續執行 多個 Buffer: 發送者可以一直送資料，但通常會限制發送的數量避免惡意程式 Direct communication 通常使用 Process id 來將訊息丟給對方: send(P, message) receive(Q, message), receive(&amp;Q, message) Receiver 可以指定是要從哪裡收，或者收任何訊息，由 OS 來告知是誰送的 Feature 不需要特別的建立連接 由於使用 Process id 來傳遞訊息，因此只能是任兩個 Process 之間傳遞訊息 由 P 和 Q 兩個單項傳遞來組合成一個雙向傳遞 Indirect communication 需要由使用者來建立傳輸通道 例如: Linux 的 mkfifo, pipe 例如: TCP/IP (如果在同一台機器上傳輸資料，不會經過 Network card) Feature 溝通的行程可以建立多個通道，可以簡化設計複雜度 可以「多個傳輸行程」對「多個接收行程」，常見於 Server 的設計 雙向，例如: Shared memory 單向，例如: pipe Problems by many-to-many 如果有「多個傳輸行程」對「多個接收行程」 由誰接收 是否由「通道管理程式」決定? 誰先發起，就由誰收 收了訊息之後怎麼處理 移除訊息，通常用於 Server 將 Task 交給一個 Sub-Server 一直存在，類似於廣播 Blocking &amp; Non-Blocking 如果有足夠多的 Buffer 的話，Process 間的通訊可以是 Non-blocking 送出 Message 後 Process 繼續下一個工作 例如: signal 如果 Buffer 不足，或者根本沒有 Buffer 的話，就只能是 Blocking 送出 Message 後必須等待 Receiver 接收完畢，才能繼續工作 這個的好處是可以確認對方已經收到 Message 3.11 Communication method Direct or Indirect Shared Memory 在 Physical memory 上 Process A 和 Process B 是使用不同的區段，但是 Shared memory 就使用同一區段 要注意這裡是 Physical memory，但在 Process 中是不同的 Logical address 在 Linux 上可以透過 mmap() 來建立 Shared memory Message Passing 在 Process A 時呼叫 Kernel copy 資料到 Kernel space Context switch 到 Process B 時，Kernel 再將資料 copy 到 Process B 的 Memory Producer-Consumer problem 這裡先簡單討論 Producer-Consumer Problem 的概念，後面會再討論如何解決 假如有兩個 Process 共享一個固定大小的 Buffer，Producer 會不斷的產生資料，然後放到 Buffer 中由 Consumer 來取出 如果 Buffer 滿了，Producer 就必須等待 Consumer 取出資料 如果 Buffer 空了，Consumer 就必須等待 Producer 產生資料 這樣如果沒有設計好就容易造成 Deadlock 如果是單對單的 Producer-Consumer，可以透過一個環狀 Linked list 解決，詳情請看 OS-CH03-重要的生產消費問題 Thread concept 3.12 Context switch main overhead The overhead of context-switch Store/restore the register file (~1KB) TLB miss (~1KB) CPU cache miss (~1MB) 在 Context 中最主要的消耗就是 Cache miss，這取決於硬體的支援 Virtual cache: 就需要把 Flush Cache，透過 MMU 將 Virtual address 對應到 Physical address Physical cache: 不需要 Flush cache 需要 MMU 轉換 Virtual address 成 Physical address，才能放入 Cache，轉換的過程就會有 Latency 例如: CPU Cache miss 在等待 L2 Cache 抓到資料，或是 L1 miss 之後需要 MMU 轉換 L2 之後才能做存取 例如: Process A/B，進行了一個 A -&gt; B -&gt; A 的切換，它們各自執行的時候都會把資料放入 Cache，A 只能期望 B 沒有覆蓋掉需要的資料 Cache 是否支援 ASID (Address Space Identifier) 在 TLB 中加入一個 Process ID，只有當 ASID 與 Page number 都相同時，才會 Hit 3.13 Thread memory Thread 在同一塊 Virtual memory 中執行，但是有各自的 Stack 因為在同一塊 Virtual memory 中執行，所以 Thread1 可以存取 Thread2 的 Stack 要做這樣的存取要慎重，因為 Stack 會隨著 Function call 而變動 Thread Local Storage 同樣的 Thread 之間也會有各自的 Local variable，這些 Local variable 會放在 Thread Local Storage 中， 這是由 Compiler 來設計的，讓每個 TLS 偏移量都不一樣，這樣就能讓 Thread 存取自己的 Local variable。 3.14 Thread history Many to One One to One Many to Many Many to One 多對一就是兩個 Thread 共用一個 PCB，這樣的話如果其中一個 Thread 跑去做 I/O 的話，那整個 Process 就會被 Block，這樣就會造成整個 Process 都被 Block。 同時由於 OS 不會知道 PCB 上的是兩個 Thread，所以無法再多核心上執行，這樣就會造成效能的下降。 Green thread Green thread 是為了在底層的 OS 不支援 Thread 的情況下，透過 Library 來模擬 Thread 的行為，但這樣就只能使用 Many to One 的模型，例如: Java 的 Thread 通常只有在 OS Kernel 不支援 Multi-thread 的情況下，才會使用 Many to One，由於所有的 User thread 在 Kernel 都只有一個 PCB， 所以如果 Thread 跑去做 Block 的操作會導致其他 Thread 也被 Block。並且就算有很多 Processor 通常也只有一個 Thread 在執行，其他 Thread 都在等待。 One to One 通常是最多 OS 使用的 Model，每個 Thread 都有自己的 PCB，要透過 Memory control block 來判斷是 Thread 還是 Process， 如果共用 Memory control block 的話，那就判定他是一個 Thread。 由於每個 Thread 都有自己的 PCB，所以可以在多核心上執行 大部分都是 Non-blocking，所以在處理 Block 的任務上會很有彈性 Many to Many 上面的稱作 User thread，下面稱作 Kernel thread，對應的方式有很多種，例如下圖代表上面的 User thread 可以同時發出同等 Kernel thread 數量的 System call， 但缺點是非常複雜並寫不好寫，並且不易理解，讓程式設計者很難進行優化。 看起來是最有彈性的 Thread Sun Solaris 9 之前支援 Many to Many Model Sun Solaris 10 之後改為主要支援 One to One Model Last Edit 10-21-2023 18:52"
  },"/jekyll/2023-10-17-container_of.html": {
    "title": "Note | Linux Kernel Macro container_of &amp; offsetof",
    "keywords": "OS Jekyll",
    "url": "/jekyll/2023-10-17-container_of.html",
    "body": "container_of 這個 Macro 在 Linux kernel 會經常被用到，因此先理解 container_of 絕對非常重要 container_of container_of 的定義在 [&lt;include/linux/container_of.h&gt;]，並且需要使用 Marco offsetof，container_of 可以透過一個 struct 中的某個成員來獲得該 struct 的起始位置， 這樣的做法會在 Linux kernel 中被頻繁的使用到。 例如 Linux kernel 中的 &lt;lib/rbtree.c&gt;, &lt;include/linux/list.h&gt;，在 list.h 中 container_of 被用來找尋 list_last_entry, list_first_entry， 而在 rbtree.c 中則可以用來找尋父節點。 /** * container_of - cast a member of a structure out to the containing structure * @ptr: the pointer to the member. * @type: the type of the container struct this is embedded in. * @member: the name of the member within the struct. * */ #define container_of(ptr, type, member) ({ \\ const typeof( ((type *)0)-&gt;member ) *__mptr = (ptr); \\ (type *)( (char *)__mptr - offsetof(type,member) );}) typeof( ((type *)0 -&gt; member) ): 先宣告一個 (type *)0 (struct 的 Null 指標)，然後指向 struct 中的該 member，然後透過 typeof() 獲得 member 的 type const typeof( ((type *)0)-&gt;member ) *__mptr = (ptr): 宣告該 member type 的 pointer *__mptr 就能指向 ptr 所指向的位置 (char *)__mptr 將 __mptr 轉換為 char，因為 char 長度為 1 byte，這樣才能正確做之後運算 offsetof(type,member) 會返回從 struct 起始位置到 member 的偏移量(byte) (type *)( (char *)__mptr - offsetof(type,member) ) 最後將 __mptr - offset = struct 的起始位置，然後轉回 type* 下圖是如何透過 Offset 找到 Struct 起始位址的說明: 延伸閱讀: Rationale behind the container_of macro in linux/list.h, What is the purpose of __mptr in latest container_of macro? 延伸閱讀解釋了為什麼要另外去宣告 __mptr，我也好奇如果已經拿到 ptr 為什麼還要特別去使用 (type *)0 -&gt; member，這樣的方式來獲取 member type，如果將其改為以下程式碼， 一樣可以進行使用: Type 的檢查，這樣可以增加安全性，確保 ptr 真的與 member 型別相同 Kernel 使用的 C standard 有可能對這種寫法跳出 Warning #define container_of(ptr, type, member) ({ \\ (type *)( (char *)ptr - offsetof(type,member) );}) Last Edit 10-18-2023 23:55"
  },"/jekyll/2023-10-10-test_case_generation.html": {
    "title": "Testing | Test Case Generation",
    "keywords": "software software_qualitiy Jekyll",
    "url": "/jekyll/2023-10-10-test_case_generation.html",
    "body": "Software testing course notes from CCU, lecturer Nai-Wei Lin. Test case 的產生方式可能是無窮無盡的，因此也需要一些策略來幫助產生 Test case 以下是本章節主要介紹的目標，這個章節最後的基於限制式的測試會使用 ECLiPSeclp 來進行實作，不會在這裡介紹， 會另外開一篇講述如何使用 Constraint Logic Programming 來生成測試案例。 Test case generation Equivalence class partitioning Boundary value analysis Domain specific information Constraint-based testing Test case generation 的目標是從可能無窮(possibly infinite) Collection of candidate test cases， 選出盡可能少(Few)並且有效(Effective)的 Test case Domain knowledge 在測試特定領域的應用時能起到非常關鍵的作用 Two Main Issues 這就涉及兩個主要的問題，可以透過一些原則來解決: Few(少): 對 Input domains 所有的 Value 進行測試是不可能的，我們只能挑選一部分的 Subset 來測試 Equivalence class partitioning(等價類別劃分) Test coverage criteria(測試覆蓋標準) Effective(有效): 我們希望選擇一個 Subset，能夠找到最多的 Errors Boundary value analysis(邊界值分析) 拿一元二次方程式為例，公式解為: $ax^2 + bx + c = 0$, $r = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$ 將每個 Input variable 以 float(32 bit) 表示，所有可能的輸入值數量將會是: $2^{32} + 2^{32} + 2^{32} = 2^{96}$ 3.1 Equivalence Class Partitioning 一組精心選擇的輸入值應該能夠覆蓋許多其他輸入值 這代表我們應該把 Input domains(輸入域) 劃分為有限數量的 Equivalence classes(等價類別) 而測試每個 Equivalence class 中的 Representative value(代表值) 就等於測試了 Equivalence class 中的所有其他值 3.1.1 Valid and Invalid Equivalence Classes Equivalence classes 通常透過 Input constratint(輸入限制) 來劃分 Input domain(輸入域) 這裡會有兩種 Equivalence classes，Valid 和 Invalid Valid: 代表程式的有效輸入 Invalid: 代表所有其他可能的狀態 An Example: If an input constraint specifies a range of values (e.g., the count can be from 1 to 999), it identifies one valid equivalence class (1 ≤ count ≤ 999) and two invalid equivalence classes (count &lt; 1 and count &gt; 999) 3.1.2 Partitioning Equivalence Classes 如果程式中的 Valid/Invalid Equivalence classes 並不被程式以相同方式處理，則需要劃分更多的 Equivalence classes 如果我們有一個輸入年齡 Y 的程式: Invalid: 的輸入可能會被劃分為 Y &lt; 0 和 Y &gt; 1000 (因為根本不會有人活到 1000 歲) Valid: 我們也可以把 Y &gt; 65 跟 Y &lt;= 65 區分開來，因為大於 65 歲的退休人士可能有不同的行為 這樣我們就在 Invalid/Valid 中另外劃分了 2 個 Equivalence classes An Example: 回到一元二次方程式為例，方程式的解取決於: $d = b^2 - 4ac$ $The\\;equation\\;has\\;two\\;different\\;real\\;roots\\;if\\;d&gt;0$ $The\\;equation\\;has\\;two\\;identical\\;real\\;roots\\;if\\;d=0.$ $The\\;equation\\;has\\;no\\;real\\;root\\;if\\;d&lt;0.$ 將一元二次方程式依照 Root 的情況劃分為三種 Equivalence class，這樣就能在這三種情況下挑選 a, b, c 的代表值 3.1.3 Input Space, Vectors, Points Input Space: Let x1, x2, …, xn denote the input variables. Then these nvariables form an n-dimensional space that we call input space. Input Vector: The input space can be represented by a vector X, we call input vector, where X = [x1, x2, …, xn]. Test Point: When the input vector X takes a specific value, we call it a test pointor a test case, which corresponds to a point in the input space. 假如有一個 Function，接受兩個 Variable x, y，所有的可能輸入值就會是一個 Input Space， 那麼我們的 Input Vector 就是這個 2D 平面上的所有點，而 Test Point 就是這個我們選擇進行測試的點 3.1.4 Input Domain and Sub-Domain Domain: The input domainconsists of all the points representing all the allowable input combinations specified for the program in the product specification. Sub-Domain: An input sub-domainis a subset of the input domain. In general, a sun-domain can be defined by a set of inequalitiesin the form off(x1, x2, …, xn) &lt; K, where “&lt;” can also be replaced by other relational operators. Domain 就是在程式規格允許下的所有輸入值，而這些輸入值可以被程式中的不等式所劃分為 Sub-Domain Input Domain Partitioning An input domain partitioningis a partition of the input domain into a number of sub-domains. These partitioned sub-domains are mutually exclusive, and collectively exhaustive. 例如: 整數輸入可以被劃分為三個 Sub-Domain，n &lt; 0, n = 0, n &gt; 0，這三個 Sub-Domain 互斥且完全涵蓋了整個整數 Domain 3.2 Test Coverage Criteria 如果 Equivalence classes 的數量還是太多，那我們就需要 Test coverage criteria(測試覆蓋標準)來限制 Test Case 的數量， 在這裡我們還不會詳細談有哪幾種 Test coverage criteria。 Test Case Candidates Reduction: 下圖是一個減少 Test Case 的流程 3.3 Boundary Value Analysis 邊界上的測試案例通常是最有效的，因為邊界是最容易找到錯誤的地方 A boundaryis where two sub-domains meet. A point on a boundary is called a boundary point. Boundary points are input values with the highest probability of finding the most errors. 3.3.1 Definition of boundaries Linear Boundaries and Sub-Domains A boundary is a linear boundaryif it is defined by: $a_1x_1+ a_2x_2+ … + a_nx_n = K$ Otherwise, it is called a nonlinear boundary. A sub-domain is called a linear sub-domainif its boundaries are all linear ones. Open and Closed Boundaries A boundary is a closedone with respect to a specific sub-domain if all the boundary points belong to the sub-domain (&lt;=, &gt;=, =). A boundary is an openone with respect to a specific sub-domain if none of the boundary points belong to the sub-domain (&gt;, &lt;, !=). A sub-domain with all open boundaries is called an open sub-domain; One with all closed boundaries is called a closed sub-domain; otherwise it is a mixed sub-domain 如果一個邊界的 Point 在 Domain 中，那麼這個邊界就是 Close 的，否則就是 Open 的，例如: Domain 1 &lt; x &lt;= 100 邊界 1 並不屬於 Domain，因此這個邊界是 Open 的 邊界 100 屬於 Domain，因此這個邊界是 Close 的 Interior and Exterior Points 屬於 Sub-domain 但不在邊界上的點稱作 Interior point 不屬於 Sub-domain 並且不在邊界上的點稱作 Exterior point 而兩條以上的邊界相交的點稱作 Vertex point General Problems with Input Values Some input values cannot be handled by the program. These input values are under-defined. Some input values result in different output. These input values are over-defined. These problems are most likely to happen at boundaries. Under-defined input values(未定義的輸入值): 也就是程式無法處理的 Input value，例如: 除以零 Over-defined inpyt values(過度定義的輸入值): 也就是程式可以處理但是可能有不同輸出的 Input value，例如: 一個投票系統，可能會因為地方的法律而有不同的投票年齡限制 3.3.2 Boundary Problems 這裡列出 5 個主要的 Boundary Problems: Closure Problem(閉合問題): whether the boundary points belong to the sub-domain. Boundary shift/tilt Problem: where exactly a boundary is between the intended and the actual boundary. Boundary shift Problem: f(x1, x2, …, xn) = K, where a small change in K. Boundary tilt Problem: f(x1, x2, …, xn) = K, where a small change in some parameters. Missing/Extra boundary Problem: Missing: a boundary missing means that two neighboring sub-domains collapse into one sub-domain. Extra: An extra boundary further partitions a sub-domain into two smaller sub-domains. 3.4 Test Case Generation Strategy Weak N x 1 / 1 x 1 Strategy 都是一種用於邊界測試的策略，這裡會介紹這兩種策略的差異與優缺點 3.4.1 Weak N x 1 Strategy 3.4.3 Weak 1 x 1 Strategy 3.4.1 Weak N x 1 Strategy In an n-dimensional space, a boundary defined by a linear equationin the form off (x1, x2, …, xn) = K would need nlinearly independent pointsto define it. We can select nsuch boundary points, called ON points, to precisely define the boundary. We can also select a point, called an OFF point, that receives different processing. The OFF Points 閉合的邊界: 那麼它的 Off point 會位邊界的外部 開放的邊界: 那麼他的 On point 會位邊界的內部 0 &lt;= N &lt; 21 在這個例子上有兩個邊界，其中 0 是 Close boundary、21 是 Open boundary ON Points 是 0, 21 這兩個位於邊界上的點 0 是 Close boundary, Off point -1 位於外側 20 是 Open boundary, Off point 20 位於內側 Distance of the OFF Points 需要 Off point 的理由是，他與邊界非常的接近，以至於邊界的細微變化都將影響 Off point 的處理 實際應用上，使用 distance ε 作為 Off point 與邊界的偏移距離 For integers, ε = 1. For numbers with nbinary digits after the decimal point, ε = 1/2n. 例如: 有一個 0.001 作為邊界值，那麼 ε 就是 1/23 = 1/8 Position of the OFF Points Off point 應該要位於所有 On point 的中央 對於一個 2D 的空間來說，他應該選擇的方式如下: 選擇位於兩個 On point 的中點 根據這個邊界是 Closed 或 Opend 向外或向內移動 ε 的距離 Total Test Points 除了 ON/OFF Points 我們也會再選擇一個 Interior Point(內部點)做為該 Equivalence Class(Sub-Domain) 的代表， 因此一個 N Dimensional domain 將會有 (n + 1)*b + 1 個 Test Points。 Example: 假設有一個稅收級距如下，注意其中 Close 與 Open 的條件，這裡都是 Integers 這樣的話旁邊的 Sub-Domain OFF Points 剛好會重疊在一起可以省略掉， 並且 Open domain 也可以省略一個邊界的值，因此原本應該要有 3 * 2 + 5 * 3 = 21 個點，但是有 4 個邊是重疊的因此 21 - 4 * 2 = 13， 最終僅用上 13 個 Test Points。 Tax Rate: 0%: 0 &lt;= x &lt; 10000 (0~9999) 10%: 10000 &lt;= x &lt; 1000000 (10000~999999) 20%: 1000000 &lt;= x &lt; 100000000 (1000000~99999999) 30%: x &lt;= 100000000 (100000000~) 那如果假設一個 2D Sub-domain，並且四個邊都是封閉的，將會是 (2 + 1) * 4 + 1 = 13 個 Test Points，這裡忽略了與旁邊的 Sub-domain 重疊的點 3.4.2 Boundary Problem Detection of Werk N * 1 Strategy 這裡說明 Weak N x 1 Strategy 在處理 Boundary Problem 時能做到什麼，不能做到什麼 Closure problem 定義邊界是是否所有可能的邊界都被包含在內 Boundary shift problem 邊界是否有正確設置在應該的位置 Boundary tilt problem 邊界是否有正確的對齊或平行 Missing boundary problem 是否所有的邊界都有被定義 Extra boundary problem 是否有多餘的邊界 Weak N x 1 Strategy 可以很好的處理其他 Boundary problem 但無法完全偵測到 Extra boundary problem 3.4.3 Weak 1 x 1 Strategy Weak 1 x 1 Strategy 在每個邊界上只放置一個 On point 與一個 Off point，減少 Test Points 數量，但是也會有缺點 One of the major drawbacks of weak N x 1 strategy is the number of test points used, (n+1)xb+1 for ninput variables and boundaries. Weak 1 x 1 strategy uses just one ON point for each boundary, thus reducing the total number of test points to 2xb+1. The OFF point is just ε distance from the ON point and perpendicular to the boundary. Weak 1 x 1 Strategy 也可以處理 Boundary Problem，但是在傾斜上的表現不如 Weak N x 1 Strategy，並且跟 Weak N x 1 Strategy 一樣無法完全偵測到 Extra boundary problem 在 2D 平面上比較能表示出兩種策略的差異，可以看到 Weak N x 1 Strategy 在同個 Domain 的邊界上會有 3 個 Points，而 Weak 1 x 1 Strategy 則只有 2 個 Points， 下圖左右分別是 Weak N x 1 Strategy 和 Weak 1 x 1 Strategy: 3.5 Looking for Equivalence Classes 找尋 Equivalence Classes(等價類別)的方法與需要注意的點 Don’t forget equivalence classes for invalid inputs. Organize your classifications into a table or an outline. Look for ranges of numbers. Look for membership in a group. Analyze responses to lists and menus. Look for variables that must be equal. Create time-determined equivalence classes. Look for variable groups that must calculate to a certain value or range. Look for equivalent output events. Look for equivalent operating environments. Don’t Forget Equivalence Classes for Invalid Inputs 通常 Invalid Inputs 是最容易產生 Bugs 的來源 例如一個能接受 1 到 99 之間任何數字的程式，那就至少有四個 Equivalence Classes 1 &gt;= x &lt;= 99 x &lt; 1 x &gt; 99 Not a number(Is this true for all non-numbers?) Organize Your Classifications into a Table or an Outline 把分類整理成表格或者大綱 會發現有這麼多的 Input/Output constraints，跟相關的 Equivalence Classes，需要一種組織方法 最常用的方法就是 Table(表格)或者 OutLine(大綱) Look for Ranges of Numbers 如果找到一個數字的範圍，例如: 1 到 99，這些範圍就是 Equivalence Classes 通常會有三個 Invalid Equivalence Classes，小於 1、大於 99、以及不是數字的情況 當然也會有多個範圍的情況，例如: Tax Look for Membership in a Group 如果一個 Input 必須屬於某個 Group，那麼一個 Equivalence Class 則包含該 Group 的所有成員 而另一個 Equivalence Class 則包含所有不屬於該 Group 的成員 例如: 要求輸入一個國家的名稱，Valid Equivalence Class 就是所有國家的名稱，Invalid Equivalence Class 就是所有不是國家的名稱 但是，abbreviations(縮寫)、almost correct spellings(幾乎正確的拼寫)、native language spellings(母語拼寫)、name that are now out of date but were country names(曾經存在過的名稱)又該如何處理? 應該分別測試這些情況嗎? 通常 Specification 不會提到這些情況，但是在測試中可能會發現這些錯誤 Analyze Responses to Lists and Menus 對於必須從 List 或 Menu 中選擇的 Input，每個選項都是一個 Equivalence Class 每個 Input 都是其自身的 Equivalence Class Invaild Equivalence Class 則是所有不在 List 或 Menu 中的選項 例如: “Are you sure? (Y/N)”，一個 Equivalence Class 就是 Y，另一個 Equivalence Class 就是 N，Invalid Equivalence Class 就是其他所有選項 Look for Variables That Must Be Equal 例如一個可以輸入任何顏色的程式，但必須是黑色，那麼所有的顏色都是 Invalid Equivalence Class，而黑色就是 Valid Equivalence Class 有時這種限制在實際應用中可能會出現意外情況: 例如黑色已售罄，只剩下其他顏色 這種曾經有效但現在不再有效的選擇，應該為它們建立一個 Equivalence Class 例如: 在閏年時 February 有 29 天，但是在非閏年時 February 只有 28 天，這樣就會有兩個 Equivalence Classes Create Time-Determined Equivalence Classes 例如一個程式還沒有從 Disk 完成讀取，在進行中與結束上按下空格鍵是不同的 Equivalence Classes 這種情況通常會有三個 Equivalence Classes，一個是還沒開始讀取的情況，一個是讀取中的情況，一個是讀取完畢的情況 Look for Variable Groups That Must Calculate to a Certain Value or Range 例如輸入 Triangle 的三個邊長 在 Valid Equivalence Class 中，它們的總和應該等於 180° 而 Invalid Equivalence Class 則會有兩個分別是大於 180° 與小於 180° Look for Equivalent Output Events 在此之前我們強調的都是 Input 與 Invalid Input，這是因為 Output 通常更複雜，因為通過程式處理後的 Output 會有很多種可能的情況 例如我們有一個由程式控制的繪圖機，他最多可以一次畫 4 公尺的線條 怎麼判斷一個線條是 Valid Equivalence Class 還是 Invalid Equivalence Class? 有可能繪製了超過 4 公尺的線條 可能根本沒有繪製線條 也有可能繪製了根本不是線條的東西，例如: 圓形 在測試中不只要關注輸出的情況，也要關注輸出並找到 Equivalence Classes Of Output Look for Equivalent Operating Environments 同時對於環境的變化也要找到 Equivalence Classes 例如: 一個程式要求至少要 64K - 256K 的可用 Memory 這樣就會有三個 Equivalence Classes，符合規範與小於 64K、大於 256K的情況 Last Edit 10-28-2023 16:46 剩下的部分是 Constraint-based testing，會另外講述如何使用 CLP 來生成測試案例"
  },"/jekyll/2023-10-09-operating_system_structure.html": {
    "title": "OS | Operating System Structure",
    "keywords": "OS Jekyll",
    "url": "/jekyll/2023-10-09-operating_system_structure.html",
    "body": "Operating System: Design and Implementation course notes from CCU, lecturer Shiwu-Lo. 在這個章節有以下主要大綱 OS Service Graphical User Interface &amp; Text-based User Interface System calls OS Structure Profiling/Debugging an OS Kernel OS Service 2.1 Purpose of OS 一台作業系統的主要服務是使對於 User 而言 Hardware 變的更好使用，對 Designer 而言能提高系統使用率 Simple to use Communications 同一台電腦內部 Process 之間的 Communications(IPC)，例如: copy and paste 跨電腦之間的通訊，例如: Network neighborhood, Network file system(NFS) Error detection 當軟體發生錯誤時，OS 能採取適當的措施「處理」這個錯誤，例如: 使用者光碟機沒有「收合」，提示使用者 提供一般程式的除錯機制，例如: ptrace, core dump … OS Kernel 的除錯機制，例如: kgdb, kdb ptrace 是一種 System call，允許一個 Process 觀察另一個 Process，gdb 的底層就使用 ptrace 實現 提供使用者操作介面，例如: Gnome, KDE … 載入應用程式的能力，例如: execve() 多功能的作業系統，最少要能識別「執行檔」的檔案格式 部分嵌入式系統 Kernel 與 User application 編譯在同一個 mage，task 即為這個 mage 中的一個 Function， 這時候就不需要「執行檔」 處理 I/O 的能力，例如: 各種 Driver 檔案系統，例如: OS 將 Disk 上的一個 Block 抽象為 File，再將 File 抽象為 Folder，Folder 中可以放入 File Increase efficiency 分配各種資源，例如: Memory 僅有 4GB，A 程式需要 3.2GB，B 程式需要 1.4GB，如何分配「有限」的 Memory Debian 上可以透過 free -h，cat /proc/swaps 查看 swap 使用狀況 統計資源的使用率，例如: 可以使用 htop 監視 CPU、DRAM、I/O 等效能，使用率 Protection，確保 Process 只能擁有 OS 所分配的資源，Process 各自獨立，不會受到非法的干擾· Security，確保 User Login 後只能存取自己的資源，例如: 存取他人的家目錄 2.2 User interface GUI: GUI 將許多命令以 Icon 的形式表示，並且大部分可以 Drag and drop(拖動)的方式 再輸入方式包含: 滑鼠、觸控面板、觸控螢幕、多點觸控的直覺化控制 CLI: Text-mode 雖然需要時間學習，但能很準確的下達命令 也可以將命令組合成 Batch program，例如: shell script Text-mode 比 GUI 更穩定 可以使用輕量級的 Remote connection，例如: ssh Text-mode 也可以結合指標裝置(例如: 滑鼠)，也可以使用 Library(例如: ncurses) 模擬 GUI 介面(例如: Linux kernel memuconfig) System Call 2.3 System call System call 是 OS Kernel 對外開放的 API 注意恐龍書將 System call 定義為 OS 對外開放的 API 但 OS 涵蓋非常廣泛，因此 System call 應該限定於 Kernel 提供的 API Linux system call Linux 所有的 System call 可以到這個路徑去尋找 /arch/x86/entry/syscalls/syscall_64.tbl，或是到 Linux 的 syscalls(2) — Linux manual page， 前四個 System call 為: 1. read, 2. write, 3. open, 4. close Call System call 可以透過 libc(C standard library) 呼叫 System call 例如: read, write, open, close Linux 的 Man page 中，volume 2 即為 System call 的說明 例如: man 2 read，這裡要注意是否有安裝 sudo apt-get install manpages-dev 少數 System call 並未包含在 Linux 的 libc 內，這時候需要自已寫出來 #define_GNU_SOURCE /* See feature_test_macros(7) */ #include &lt;unistd.h&gt; #include &lt;sys/syscall.h&gt; /* For SYS_xxx definitions */ long syscall(long number, ...); gettid() - libc 未實現的 System call 在 Linux 中: Process 都有一個 pit_t 可以透過 getpid() 獲得 POSIX Thread(pthread) 也有 pthread_t 可以透過 pthread_self() 獲得， 但是如果我想要 P1 的 thread2 與 P2 的 thread1 通訊，我們就需要一個真實的 Thread ID(TID)，這時候就要透過 System call 來獲得 tid，使用 syscall(SYS_gettid) #define_GNU_SOURCE #include &lt;unistd.h&gt; #include &lt;sys/syscall.h&gt; #include &lt;sys/types.h&gt; #include &lt;signal.h&gt; int main(int argc, char *argv[]) { pid_t tid; /* gettid() returns ths caller's thread ID(TID). There is no glibc wrapper for this system call. */ tid = syscall(SYS_gettid); /* int tgkill(int tgid, int tid, int sig); send a signal to a thread. */ syscall(SYS_tgkill, getpid(), tid, SIGHUP); } Call System Call Method(From assembly language) Call System call 的方式如下(Calling convention): arch/ABI syscall# arg1 arg2 arg3 arg4 arg5 arg6 ret. val. arm64 x8 x0 x1 x2 x3 x4 x5 x0 x86-64 rax rdi rsi rdx r10 r8 r9 rax syscall# System call 編號 ret. val. System call return value Call System call 的組合語言如下: ARM: svc #0, x86-64: syscall movq $60, %rax; // Call NO.60 System call, exit() movq $2, %rdi; // arg1 = 2, means exit(2) syscall; // Change to kernel mode, call System call 延伸閱讀: The Linux Kernel Module Programming Guide: System call 2.4 Special cases of system calls 首先要討論 System call overhead 這是為什麼把某些 Module 放在 Kernel 的速度會提升許多的原因 System call 主要的 Overhead 來自於: CPU 進行 Mode change 的時候，此時 CPU 有同時數個指令在執行，切換時或許需要 flush 所有執行到一半的指令 Kernel 需要將 User space 的所有暫存器存在 Kernel stack（每一個 Task，於 Kernel 中有自己的 Stack，注意，不是 User mode stack） 檢查權限，在 System call 之前還要檢查 Task 是否有權限執行該 System call 依照 Kernel 內部的 Calling convention，呼叫實現該 System call 的 Function，例如：sys_read() =&gt; do_read() 因為這些 Overhead 使得在 User space 執行的程式，速度會比在 Kernel space 執行的程式慢許多 vDSO 因此 Linux 的設計者會希望盡可能地降低 Overhead，vDSO(Virtual Dynamic Shared Object) 是可以將 Kernel space 的資訊，直接映射到 User space 如果該 System call 並沒有牽涉「安全性」，那就直接把 Kernel space 中的資訊寫入 User space，讓程式可以透過 Function call 的方式取得該資料 會時常變動，但又沒有機密性的資訊: __vdso_clock_gettime __vdso_getcpu __vdso_gettimeofday __vdso_time 不會變動，但也沒有機密性的資訊: 第一次呼叫時，真的產生 System call，libc 記錄下該 Function 的值 第二次呼叫時，由 libc 直接回傳，例如：getpid() /proc/pid/maps /*...*/ 7ffe6b98e000-7ffe6b9af000 rw-p 00000000 00:00 0 [stack] 7ffe6b9fa000-7ffe6b9fd000 r--p 00000000 00:00 0 [vvar] 7ffe6b9fd000-7ffe6b9ff000 r-xp 00000000 00:00 0 [vdso] ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0 [vsyscall] 這裡每行都由以下內容組成: address、perms、offset、dev、inode、pathname vsyscall: 功能等同於 vdso，但是較為古老，並有安全性問題(No support ASLR) vdso: 存放可呼叫的 vDSO Function，例如: clock_gettime() vvar: 存放 Kernel space mapping 到 User space 的資料，例如: clock_gettime() 的 cur_time 延伸閱讀: Understanding Linux /proc/pid/maps，ASLR If not using vDSO 下圖左是沒有 vDSO clock_gettime() 想要取得時間的流程，要去呼叫 timekeeping_update() 更新 cur_time，因此需要 Mode change 進入 Kernel mode。 而圖右就將這個資料結構直接映射到 User space，clock_gettime() 呼叫 timekeeping_update() 一樣會去更新 cur_time，但直接去讀 vDSO 中的資料，這樣的話速度就跟 Function call 一樣快了。 vDSO Problem 資料存放在 vvar 不一定就是 User 要的資料格式，例如: vvar 中放的是從開機到現在經過多少個 Machine cycles，但是 gettimeofday() 的回傳值是自 1970/1/1 至今經過多少秒，所以這裡是有座資料轉換的 vDSO 內部的程式碼會做適當的資料轉換 OS Structure 2.5 Monolithic system 許多著名的 OS 都是 Monolithic system，例如: Linux, FreeBSD, Solaris 目前這些作業系統都支援動態載入 Kernel module 的功能 Linux 的 lsmod 可以列出目前已經載入到 Kernel 的 module 這裡列出 Linux Kernel 中與 File system 相關的 module $ lsmod | grep fs autofs4 45056 2 btrfs 1294336 2 xor 24576 1 btrfs raid6_pq 114688 1 btrfs libcrc32c 16384 1 btrfs 2.6 In Linux Object Linux 雖然是使用 C 撰寫的，但是在 Kernel 中充滿了 Object-oriented(OO) 的概念，Object-oriented analysis and design(OOAD)物件導向分析與設計 下面是一個 Linux Kernel 中常見的 OO 概念，並且使用 container_of 來取得這個 Linked list 的起始 address(Linked list head) struct parport_driver { const char *name; /*property*/ void (*attach) (struct parport *); /*method*/ void (*detach) (struct parport *); /*method*/ struct list_head list; /*inherit list_head*/ }; struct list_head { struct list_head *next, *prev; }; #define list_entry(ptr, type, member) container_of(ptr, type, member) container_of /**  * container_of - cast a member of a structure out to the containing structure  * @ptr:        the pointer to the member.  * @type:       the type of the container struct this is embedded in.  * @member:     the name of the member within the struct.  * */ #define container_of(ptr, type, member) ({              \\ const typeof( ((type *)0)-&gt;member ) *__mptr = (ptr);    \\ (type *)( (char *)__mptr - offsetof(type,member) );}) container_of 主要是透過成員來獲取該 struct 的起始位置，詳細可以看 Linux Kernel Macro container_of 跟延伸閱讀 延伸閱讀: Linux 核心原始程式碼巨集: container_of Linux kernel 雖然是使用 C 語言寫的，但在裡面充斥著 OO 的概念，當然有部分要跟底層溝通所有沒有完全 OO 2.7 Layered approach Layered approach 在 OS 的缺點是，並不一定能切出 Layer，跟 Network 不太一樣 將系統分成 N 層 第 N 層可以使用第 N-1 層的功能，不可以使用 N+1 層的功能 例如 I/O memagement 需要 Buffer 因此需要 Memory management，Memory management 有時也需要將 Memory 寫到 Disk，因此需要 I/O management，這樣就很難分層 2.8 Hardware Abstraction Layer 常見的 Andriod OS 與 Windows 架構如下: Andriod: 可以看到 Libraries 被放置在中間層，是因為為了能給各家廠商商業化，而最上方是 Apach License 就是隨意給人更改的部分， 可以看到 Hardware Abstraction Layer(HAL) 被放置在中間層，照常理來說應該放在 Hardware 與 Software 之間，放在這裡或許是想要把 Kernel 有替換的的彈性。 Windows: Windows 的 HAL 就被放置在 Kernel 與 Hardware 之間，抽象層的目標是，例如: 希望 Kernel 中沒有 Assembly，不要太跟 Device 相關。 Kernel 之上包含著 Virtual Memory Manager(把硬體相關的部分抽出，另外一個目錄) Last Edit 10-10-2023 23:21"
  },"/jekyll/2023-09-23-software_testing_introduction.html": {
    "title": "Testing | Software Testing Introduction",
    "keywords": "software software_qualitiy Jekyll",
    "url": "/jekyll/2023-09-23-software_testing_introduction.html",
    "body": "Software testing course notes from CCU, lecturer Nai-Wei Lin. 軟體測試是確保軟體品質的重要過程，這個過程確保軟體產品符合預期的需求，並確保軟體產品無缺陷，這裡介紹軟測的基礎概論。 1.1 What Is Software Testing 測試是確表品質的方法之一，Software quality assurance(軟體品質保證)涉及 Validation(確效)/Verification(驗證)軟體 Validation: 確效客戶的 Requirements 與設計出的 Specification 一致 Do we build the right software? Verification: 驗證開發的 Implementation 與設計出的 Specification 一致 Do we build the software right? 而軟體測試主要著重在 Verification 這部分，Validation 是設計端要處理的問題 延伸閱讀 Wiki: Verification and validation 1.1.1 Software Verification Verification 也分為 Statically(靜態)與 Dynamically(動態) Statically: 靜態驗證並不執行軟體下進行，它包含 review, inspection, walkthrough, analysis 等技術。 靜態驗證主要關注預防缺陷，通常需要有一定的開發經驗的測試人員來進行 Dynamically: 動態驗證會執行軟體，它包含各種測試技術 動態驗證主要關注找出和修復缺陷，動態測試系統的功能行為，Memory/CPU 使用情況以及系統的整體性能 而在 Software testing 這門課中大部分關注的是 Dynamically 這部分的實作 延伸閱讀 Static Testing vs. Dynamic Testing 1.1.2 Software testing 要注意的是軟體測試並不能證明軟體是完全正確的，軟體測試僅能從體中找到盡可能多的錯誤。因為軟體測試只是識別軟體中潛在的錯誤，而不是證明軟體是正確的。 Error, Fault, Failure, and Incident Error(錯誤): 是人為所犯的錯誤 Fault(故障): 是文件或程序中的 Error 的結果 Failure(失敗): 當 Fault 被執行時就會發生 Failure，Fault 的執行導致程式無法執行預期的功能或結果 Incident(事件): 當 Failure 發生時，用戶可能不會馬上發現，一個 Incident 提醒用戶 Failure 的發生 延伸閱讀 Software Testing – Bug vs Defect vs Error vs Fault vs Failure Test Case Software testing 是執行一組測試案例(Test Case) 的行為，以便能夠找出程式中的 Fault。 一組 Test case 包含一個測試輸入列表和一個相應的預期輸出列表 每個 Test case 都設計來檢查程序的某種特定功能或行為 軟體測試的生命週期，代表了各個步驟所產生的錯誤與錯誤追蹤 Why Do We Need Software Testing Software prevails in our living environment. Quality of software significantly influences our quality of life. Software faults in critical software systems may cause dramatic damages on our lives and finance. Carefully made programs have 5 faults per 1000 lines of code (LOC). Windows XP has 45M LOC, so it may have 225000 faults. 1.2 How Do We Do Software Testing 但是在進行 Testing 前應該要先了解 Testing 到底在測試什麼? Test case 理想的狀況下應該是 Specification ∪ Implementation 的範圍，這樣就能找出所有不合規範的 Fault。 Faults of comission(錯誤的委任): 實際的軟體開發往往都會有超出規格的部分，可能是需求變更或者是在實現功能時遇到了未預見的挑戰。 Faults of omission(錯誤的遺漏): 同樣的開發中也有可能會有規格被遺漏的情況，可能是規格上的錯誤、技術挑戰、時間壓力等原因造成。 1.2.1 Test case Test Case 涉及兩個主要問題，如何 Test case generation(產生測試案例)、如何 Test case execution(執行測試案例) Test case execution: 輸入 Input 至 Software 後得到 Expected output 與 Output 進行比對來決定是 Incident/Correct Excution 目前幾乎都依賴於測試框架來幫助執行，這點之後會再介紹 Test case generation: 要確認測試案例有兩種方式 Black-box testing(Function testing): 軟體被視為一個黑盒子，從規格中描述的功能確定測試案例 White-box testing(Stucture testing): 軟體被視為一個白盒子，從實施的程式的結構確定測試案例 Fuctional Testing vs Structure Testing Black-box 從 Specification 的角度來設計 Test case 因而較難覆蓋到未被規定的行為(Faults of comission) White-box 從 Implementation 的角度來設計 Test case 因而較難覆蓋到未被實現的行為(Faults of omission) 因此兩種方法都不足夠，只有兩種方法都使用才能盡可能的覆蓋 Specification ∪ Implementation 試想在未學習軟體測試前是怎麼去寫 Testing? 我幾乎都是從結構去出發，已現有的程式去開發測試案例，因為壓根就沒設計完整的規格。 1.2.2 Tracking of incidents Incident tracking system(事件追蹤系統)負責追蹤所有需要修復的 Incidents(事件)，確保所有事件都得到妥善解決 需要知道事件的相關人員，應在事件報告後不久得知 這意味著系統應該能夠迅速地通知相關人員有關新的事件，確保所有相關人員都能及時獲得最新的信息，並可以立即開始處理事件 不會有事件因為被遺忘而未修復 系統會持續追蹤每一個事件，直到它被修復，防止任何事件被忽視或遺忘 不會因單一程序員的一時興起而未修復某個事件 修復事件的決定不應該只取決於一個人的主觀意願，而應該基於對事件的客觀評估和團隊的共識 減少因為溝通不良而未修復的事件 這表示系統應該促進良好的溝通，以防止因為溝通問題導致事件未能被修復 1.2.3 Regression testing Regression testing(回歸測試) 重複使用測試案例來測試更改後的軟體，確保之前正常運行的部分沒有被影響造成新的錯誤，既有功能應繼續如常運行。 回歸測試可以在不同的測試階段應用，例如整合測試或系統測試，具體取決於測試案例的細分程度和需求。通常它們被放置在整合測試和系統測試中。 Regression testing 有以下特性，使其在軟體測試中有重要地位: 確保穩定性: 回歸測試確保新的軟體變更不會對現有的功能造成負面影響，確保軟體的整體穩定性和品質 節省時間和成本: 自動化回歸測試可以節省大量的測試時間，特別是對於長期的軟體開發專案或需要頻繁進行版本更新的情況。因為不需要手動執行重複性的測試案例，有助於降低測試成本 快速反饋: 回歸測試可以在每次軟體變更之後迅速運行，提供關於變更對軟體的影響的即時反饋，有助於快速識別並解決問題，從而提高開發效率 Regression testing 也具有一些挑戰: 初期自動化成本: 為了實現自動化回歸測試，需要將測試案例轉化為自動化程式，會造成相當大的工作量和成本 維護成本高: 維護回歸測試套件需要時間和資源。當軟體變更頻繁時，測試套件更新會產生相當的維護成本 執行時間: 如果回歸測試的測試案例變得過多，可能需要較長的時間才能完全執行，可能會對開發流程產生延遲，需要仔細計劃和管理回歸測試的執行時間 延伸閱讀 【D13】測試類型介紹:回歸測試 1.2.4 Levels of testing Levels of testing(測試的各個階段)主要包括以下幾個: Unit Test(單元測試): 這是最基本的測試階段，主要針對最小單元進行測試，確保每個獨立的部分都能正常運作 Integration Testing(整合測試): 此階段針對跨物件或模組進行測試，以確保各個模組之間的交互作用能夠正常運作 System Testing(系統測試):系統測試是一種風險測試，目的是確定整個系統是否滿足特定的功能性和非功能性需求，測試環境需盡可能和正式上線的環境一致 Acceptance Testing(驗收測試): 也被稱為 UAT(使用者接受度測試)，這是最後一個測試階段，會模擬真實使用者情境來驗證軟體是否符合使用者的需求和期望 每一個階段都有其特定的目標和重點，且需要根據具體情況來選擇最適合的策略和方法2。 延伸閱讀 【D11】 實例簡述:測試四階段與測試方法 1.3 Costs of Software Quality 軟體測試的成本可以分為兩種，Control Costs(控制成本)，Failure of Control Costs(失敗控制成本) Control Costs: Prevention costs(預防成本): 包括投資於品質基礎設施和品質活動的費用，這些投資並未針對特定的項目或系統，而是對整個組織通用 Appraisal costs(評估成本): 包括為特定項目或系統執行的活動的費用，目的是為了檢測軟體錯誤 Failure of Control Costs: Internal failure costs(內部失敗成本): 包括修正設計審查、軟體測試和驗收測試中檢測到的錯誤的成本，在軟體安裝到客戶端之前完成 External failure costs(外部失敗成本): 包括修正客戶或維護團隊在軟體系統安裝後檢測到的所有失敗的成本 應該保持在 Optimal software quality level 這個標準之上，Control costs 減少不會讓軟體品質的總成本下降 Test coverage criteria(測試覆蓋率標準)，這是一種衡量軟體測試深度的指標，用於確定已經測試了軟體的哪些部分，以及還有哪些部分尚未進行測試，它可以幫助我們確定何時可以停止軟體測試 軟體品質成本影響軟體品質水平，投入確保軟體品質的資源會直接影響軟體的最終品質 例如: 如果我們投入更多的資源進行測試，那麼可能會發現更多的錯誤，從而提高軟體的質量 根據可用的軟體品質資源來確定何時停止軟體測試， 例如: 如果我們的資源有限，那麼我們可能需要在達到一定的測試覆蓋率後就停止測試 NOTE 本篇只是講述軟體測試的概論，後續會再討論各個章節的細節 Last edit 09-24-2023 15:50"
  },"/jekylls/2023-09-21-lexical_analysis.html": {
    "title": "Compiler | Lexical Analysis Notes",
    "keywords": "Compiler Jekylls",
    "url": "/jekylls/2023-09-21-lexical_analysis.html",
    "body": "Compilers course notes from CCU, lecturer Nai-Wei Lin. Lexical analysis(語彙分析) 將文本轉換為有意義的語彙標記(Token)，這通常是 Compiler 步驟的第一步。 Compilers: Principles, Techniques, and Tools 介紹使用 Regular Expression(RE, 正規表達式)描述 Lexemes 的方法，並透過一個 Lexical-analyzer generator(語彙分析器生成工具)來進行代碼生成， 使我們可以專注在如何描述 Lexemes。 因此會先學習 RE 的使用方法，RE 能被轉換為 Nondeterministic Finite Automata(NFA, 非確定有限狀態自動機)問題在轉換為 Deterministic Finite Automata(DFA, 確定有限狀態自動機)問題， 之後就能用程式碼模擬自動機運作。 3.1 The Role of the Lexical Analyzer Lexical analyzer(語彙分析器)主要任務就是讀取 Source code 的輸入字符(characters)，並將其組成為 Lexeme，並輸出一個 Token 序列，並在識別到 Identifier 時要將其添加到 Symbol table 中。 下圖顯示一個 Syntax analyzer(語法分析器)與 Lexical analyzer 互動的過程，呼叫 getNextToken 來使語彙分析器不斷讀取字符，直到識別出下一個 Token 將其返回給語法分析器。 語彙分析器可以被劃分為兩個骨牌效應的過程: 掃描不需要轉變為 Token 的部分的過程 例如: 過濾 Comments, Whitespace (blank, newline, tab …) 實際的 Lexical analysis，從掃描的輸入中產生 Token 語彙分析器還可以將 Compiler 的錯誤訊息與 Source code 的發生位置聯繫起來，例如: 紀錄換行符號的行數，以便在出錯時給予一個行數 某些編譯器中會將 Source code 複製一份，並將錯誤訊息插入該位置 3.1.1 Lexical Analysis Versus Parsing 把 Lexical analysis(Scanning) 與 Syntax analysis(Parsing) 分開有三個原因: 簡化編譯器設計，分離可以更好的專注在不同任務上 如果我們正在設計一種新的語言，將詞法和語法問題分開也可以使整體語言設計更加清晰 提高編譯器的效率 Lexical analyzer 獨立後我們就可以去更方便的優化 I/O 的處理 提高編譯器的可移植性，輸入設備特定的特性可以限制在詞法分析器中 例如: Windows 的換行符是 \\r\\n，Linux 上的是 \\n 延伸閱讀 Input Buffering in Compiler Design 3.1.2 Tokens, Patterns, and Lexemes 在討論 Lexical analyzer，這裡有三個需要了解的術語: token(language): a set of strings if, identifier, relop Pattern(grammar): a rule defining a token if: if identifier: letter followed by letters and digits relop: &lt; or &lt;= or = or &lt;&gt; or &gt;= or &gt; Lexemes(sentence): a string matched by the parrern of a token if, Pi, count, &lt;, &lt;= 假設有以下 Clang code，依照 Figure 3.2 print 與 score 是 Token id 所匹配的 Lexeme，\"Total = %d\\n\" 則是與 literal 匹配的 Lexeme。 printf(\"Total = %d\\n\", score); 在很多程式語言設計中，大部分 Token 被分成以下幾類: Reserved words(保留字)都有一個 Token，保留字的 Pattern 與保留字相同 Operators 的 Token，可以表示單個運算符，也有像 comparison 有多個同類別的運算符 Identifier 只用一種 Token 表示 Constants 有一個或多個 Token，例如 number、literal Punctuation symbol 都有各自的 Token，例如 (, ), ,, ; 3.1.3 Attributes for Tokens Attributes 是用來區分 Token 中的不同 Lexeme，例如 0, 1 都能跟 Token number 匹配，因為 Lexcial analyzer 很多時候不能僅返回給 Syntax analyzer 一個 Token name， Token name 影響 Syntax analyzer，而 Attributes 會影響 Parsing 之後的 Semantic analyzer。 &lt; if, &gt; &lt; identifier, pointer to symbol table entry &gt; &lt; relop, = &gt; &lt; number, value &gt; 3.3 Specification of Tokens Token 的一種重要的表示方式(規格)就是 Regular expression，RE 可以高效的描述處理 Token 時要用到的 Pattern。 3.3.3 Regular Expression Regular Expression(RE, 正規表達式)是由較小的 RE 按照以下規則遞迴建構，下面的規則定義了某個 Alphabet ∑ 的 RE: ε 是一個 RE，L(ε) = {ε}，也就是該語言只包含空字串 如果 a 是 ∑ 中的符號，那麼 a 也是一個 RE 代表 L(a) = {a}，也就是說這個語言僅包含長度為 1 的字串 a。 Suppose r and s are RE denoting L(r) and L(s) (r) (s) is a RE denoting L(r) ∪ L(s) (r)(s) is a RE denoting L(r)L(s) (r)* is a RE denoting (L(r))* (r) is a RE denoting L(r) Example: a | b {a, b} (a | b)(a | b) {aa, ab, ba, bb} a* {ε, a, aa, aaa, ...} (a | b)* the set of all strings of a's and b's a | a*b the set containing the string a and all strings consisting of zero or more a's followed by a b Order of operations: Priority Symbol Highest \\ High (), (?:), (?=), [] Middle *, +, ?, {n}, {n,}, {n,m} Low ^, $ Second lowest concatenation Lowest | Algebraic laws: 3.3.4 Regular Definitions 為了方便表示，我們可能會給某些 RE 別名，並在之後的 RE 中使用符號一樣使用這些別名，例如: Name for regular expression $d_1 \\rightarrow r_1$ $d_2 \\rightarrow r_2$ $…$ $d_n \\rightarrow r_n$ $where\\;r_i\\;over\\;alphabet\\cup ( d_1, d_2, …, d_{i-1} )$ Examples: $letter \\rightarrow A | B | … | Z | a | b | … | z$ $digit \\rightarrow 0 | 1 | … | 9$ $identifier \\rightarrow letter(letter | digit)*$ 上面的 Examples 定義了一個僅能由 letter 開頭但的 identifier 3.3.5 Extensions of Regular Expressions RE 後續有其他的擴展，用來增強 RE 表達字串的能力，這裡會介紹最常被使用的幾種擴展 One or more instances (r)+ denoting (L(r))+ r* = r+ | ε r+ = rr* Zero or one instance r? = r | ε Character classes [abc] = a | b | c [a-z] = a | b | … | z [^a-z] = any character except [a-z] Examples: $digit \\rightarrow 0 | 1 | … | 9$ $digits \\rightarrow digit^+$ $number \\rightarrow digits(.digits)?(E[+-]?digits)?$ 上面的 Examples 定義了從 digit 到 digits 最後到 number 的過程 3.6 Finite Automata 這裡 3.6/3.7 章不會依照課本順序，而是依照課程進度。 NFA 的 Transition function 可以指向多個 State，DFA 的 Transition function 只能指向一個 State 會先介紹相對簡單的 DFA 再介紹 NFA，這樣可以更容易理解 NFA 的運作 要注意自動機的幾個特性: 自動機是 Recongnizer(識別器)，他們只能對輸入的字串進行判斷 “Yes” or “No” Finite automata 分為兩類 Nondeterministic finite automata (NFA, 非確定有限狀態自動機) A symbol can label several edges out of the same state, the empty string(ε) is a possible label. Deterministic finite automata (DFA, 確定有限狀態自動機) For each state, and for each symbol of its input exactly one edge with that symbol leaving that state. 3.6.1 Nondeterministic Finite Automata An NFA consists of: A finite set of states A finite set of input symbols, default empty string is not in the set. A transition function (or transition table ) that maps (state, symbol) pairs to sets of states A state distinguished as start state A set of states distinguished as final states 上圖左是 NFA’s transition graph 在狀態 0 有 a, b 兩種狀態轉移，圖右是他對應的範例 3.6.2 Transition Tables NFA 可以表示為一張 Transition table(轉換表)，例如: 轉換表可以更容易看出 NFA 的狀態轉移，缺點是當 NFA 狀態(Alphabet)很多時，轉換表會變得很大佔用空間 3.6.3 Acceptance of Input Strings by Automata NFA accept 輸入字串 s，如果從 Start state 開始，有一條路徑可以走到 Final state，這條路徑的轉移符合這個 Automata 所定義的語言 3.6.4 Deterministic Finite Automata 這裡會先談一個 DFA 怎麼用程式碼模擬，因為相較於 DFA 簡單許多 Deterministic finite automata (DFA, 確定有限狀態自動機) 是 NFA 中的一種特例，其中: There are no moves on input ε For each state s and input symbol a, there is exactly one edge out of s labeled a. Algorithm 3.18 : Simulating a DFA. from Compiler: Principles, Techniques, and Tools p.150 Input: An input string ended with eof and a DFA with start state s 0 and final states F. Output: The answer “yes” if accepts, “no” otherwise. begin s := s0; c := nextchar; while (c != EOF) do begin s := move(s, c); c := nextchar; end; if (s ∈ F) then return \"yes\"; else return \"no\"; end; 3.6.5 Simulation of an NFA NFA 與 DFA 在模擬上的演算法幾乎一樣，最大的區別在於 ε-closure() 的建構，因為 NFA 在給定輸入的狀況下可以存在多個 State， 因此在模擬上需要處理 State set。課本中會在 3.6.4 提前介紹 Algorithm 3.18 : Simulating a DFA. - p.151 Algorithm 3.22 : Simulating a NFA. from Compiler: Principles, Techniques, and Tools p.156 Input: An input string ended with eof and an NFA with start state s 0 and final states F Output: The answer “yes” if accepts, “no” otherwise. begin S := ε-closure({S0}); c := nextchar(); while (c != EOF) do begin S := ε-closure(move(S, c)); c := nextchar(); end; if (S ∩ F != ∅) then return \"yes\"; else return \"no\"; end; 上面的 Pseudocode 模擬 NFA 的運作，其中: move(s, c): 從 state s 輸入 c 可以到達的 NFA state set move(S, c): 從 state s set S 輸入 c 可以到達的 NFA state set ε-closure(s): 沒有輸入字元，從 state s 僅通過 ε-transitions 可以到達的 NFA state set ε-closure(S): 沒有輸入字元，從 state s set S 僅通過 ε-transitions 可以到達的 NFA state set nextchar(): 回傳下一個輸入字元 注意上面的 S 是 NFA state set，而 s 是 NFA state 上圖左邊的最後的 S 與 Final state {3} 有交集，因此回傳 “yes”，右邊的則沒有交集，回傳 “no” 注意上圖的 NFA 並沒有加入 ε-closure() 因為沒有任何 ε State，因此可以只透過 move() 來模擬 NFA 運作 3.6.6 Computation of ε-closure 從上面的例子可以說明 move() 是如何運作，接下來這裡會講解 ε-closure() 是如何運作，用一個 DFS 來找出所有可以到達的 ε-State，返回一個 T set Computing ε-closure(T) Input: An NFA and a set of NFA states S. Output: T = ε-closure(S). begin push all states in S onto stack; T := S; while stack is not empty do begin pop t, the top element, off stack; for each state u with an edge from t to u labeled ε do begin if u is not in T then begin add u to T; push u onto stack; end; end; return T; end; 上面的例子看似複雜，其實只是組合了 move() 和 ε-closure() 的運作 3.7 From Regular Expressions to Automata 從 RE 轉換為 NFA，再從 NFA 轉換為 DFA，這裡會用這樣的順序來介紹 3.7.1 Construction of an NFA from a Regular Expression 使用 McNaughton-Yamada-Thompson construction algorithm，可以將 RE 轉換為 NFA。 以上說明了 (ε), (a), (s|t), (st), (s), 的轉換過程，跟使用 (a|b)abb 作為例子來一步步轉換 在 Compilers: Principles, Techniques, and Tools p.161 - Example 3.24 有類似的轉換過程 3.7.2 Conversion of an NFA to a DFA 使用 Subset construction algorithm，可以將 NFA 轉換為 DFA。 Subset construction 的概念是 DFA 的每個 State 都對應 NFA 的一組 State，也就是 DFA 的每個 State 都代表 NFA 在讀取相同輸入後可能存在的所有狀態。 但是這樣的話 DFA 的 State 數量會變得非常多，因此 Subset construction 會將相同的 NFA State set 合併成一個 DFA State。 a DFA state ≡ a set of NFA states Find the inital state in the DFA Find all the states in the DFA Construct the transition table Find the final state of the DFA 例如一個 NFA 有 3 個 State，那麼他的 DFA 最多會有 23 = 8 個 State 才能表示所有的 NFA State set， 但是在實際的語言處理中通常不會看到這種指數增長，並非所有的 NFA State 組合都會出現在實際的輸入序列中。 Algorithm 3.20 : The subset construction of a DFA from an NFA. from Compiler: Principles, Techniques, and Tools p.153 Input: An NFA N. Output: A DFA D with states Dstates and trasition table Dtran begin add ε-closure(s0) as an unmarked state to Dstates; while there is an unmarked state T in Dstates do begin mark T; for each input symbol a do begin U := ε-closure(move(T, a)); if U is not in Dstates then add U as an unmarked state to Dstates; Dtran[T, a] := U; end; end; 上面是一個將 NFA 轉換為 DFA 的例子 透過 ε-closure(), move($state, $symbols) 找出所有的 NFA State set 將相同的 NFA State set 合併成一個 DFA State 這樣就能透過 DFA State 來繪製出一張 DFA 3.7.3 Tiem Space Tradeoffs RE to NFA, simulate NFA time: O(|r| * |x|), space O(|r|) RE to NFA, NFA to DFA, simula time: O(|x|), space: O(2|r|) Lazy transition evaluation transitions are computed as needed at run time; computed transitions are stored in cache for later use. Lazy evaluation(惰性求值)，目的是要最小化計算機要做的工作。可以在空間複雜度上得到極大的優化，從而可以輕易構造一個無限大的數據類型。 Last Edit 10-02-2023 17:50"
  },"/jekyll/2023-09-20-compiler_introduction.html": {
    "title": "Compiler | Compilers Introduction",
    "keywords": "Compiler OS Jekyll",
    "url": "/jekyll/2023-09-20-compiler_introduction.html",
    "body": "Compilers course notes from CCU, lecturer Nai-Wei Lin. 編譯器這門課可以讓人更深入的了解 Programming language，如果能知道編譯器如何將 High level language 轉換為 Machine code 與背後的工作原理， 就能更有效的去編寫程式。在修 OS 的時候更有感覺，有些是針對編譯器與平台的優化去更改寫法，有些小小的改動就能減少數行的指令去提升效能。 linux/lib/rbtree.c 在 6.4 版做了一個非常簡單的 commit，將 bitwise | 換成 +，這個替換使 x86 平台上可以使用 lea Assemble， 將兩道指令變成一道指令。正是了解 Compiler Optimization 才能知道這樣修改有什麼用。 Human use nature languages to communicate with each other Human use programming language to communicate with computers 1.1 Language Processors 廣義的說 Compiler 就是一個可以將一個 Language 翻譯成另一個 Language 的工具，同時 Compiler 的另一個重要功能是發現翻譯過程中 Original language 的錯誤。 上圖展示了一個 Compiler 與 Interpreter 的差異，另外 Java language process 結合了兩者的過程，既有 Target code 也有用於執行程序的 Interpreter。 但是一個程式語言從 Compile 到 Execute 除了 Compiler 還有很多其他的處理程序，如: Preprocessor、Assembler、Linker、Loader。但這裡專注於 Compiler 的部分， 在 1.2 再詳細說明 Compiler 的結構。 1.2 The Structure of a Compiler 首先我們可以把 Compiler 分為 Frontend/Backend 兩個部分: Analysis(Front-End): 將 Source code 分解成多個組成要素，並在這些要素之上加入語法結構。使用這個結構來建立 Intermediate code，並且可以檢查原始程式是否符合正確的語法與語意，並且提供資訊給使用者修改。 並且把 Source code 的資訊收集為 Symbol table，之後將 Intermediate code 與 Symbol table 一起送給後端。 Synthesis(Back-End): 根據 Intermediate code 與 Symbol table 來建立目標程式 上圖都是 Compiler 的結構，右圖表述了每個步驟之間的更多細節 有些編譯器在前端與後端之間會有 Machine-independent optimization(機器無關的最佳化)步驟，這個最佳化的目的是在 Intermediate code 之間進行轉換。 1.2.1 Lexical analysis Lexical analysis(語彙分析)也被稱做 Scanning(掃描)，是編譯器的第一個步驟，進行讀取原始程式的字元串流，並依據 Lexeme(詞素)來產生 Token(詞彙單位)作為輸出。 Lexeme: 是 Source code 中具有相同意義的字符序列，如 int, return, = 都是 Lexeme。 Token: 是 Lexical analysis 後的結果，它的形式可能像 &lt;token-name, attribute-value&gt; 例如 Position = initial + rate * 60 在經過 Lexical Analysis 後會變成: &lt;id, 1&gt; &lt;=&gt; &lt;id, 2&gt; &lt;+&gt; &lt;id, 3&gt; &lt;*&gt; &lt;60&gt; 這樣的 Token 其中 Position 對應 &lt;id, 1&gt;，id 代表 identifier，而 1 指向 Symbol table 中所對應的條目 1.2.2 Syntax analysis Syntax analysis(語法分析)也被稱做 Parsing(解析)，使用 Lexical analysis 產生的 Token 來建立 Syntax tree。之後會介紹 Context free grammar 來描述程式語言的語法結構， 並自動為某些類型的語法建構高效率語法分析器的演算法。 1.2.3 Semantic analysis Semantic analysis(語意分析) 使用 Syntax tree 和 Symbol table 中的資訊來檢查原始程式是否符合程式語言的規則，並且在這裡收集型別的資訊。 Type checking: 這是 Semantic analysis 的重要部分，檢查每個運算子是否具有一致的運算元。例如: Array 的 Index 應該要為 int，若有 float 就應該回報錯誤。 Coercion: 程式語言也可以做型別轉換，例如 Position = initial + rate * 60，而所有變數都已經宣告為 float，此時就能將 60 轉換為 60.0。 1.2.4 Intermediate code generation 在 Source code 變成 Target code 的過程中可能會產生一個到多個的 Intermediate representation(IR, 中間表述)也可以稱作為 Intermediate code(中間碼)， Syntax tree 也可以算做是一種 IR，這些中間表述應該要有兩個重要的性質: Easy to produce(易於生產), Easy to translate(易於轉譯為 Machine language) 例如使用類似 Assembly language 的一種三位址碼作為 Intermediate code: t1 = inttofloat(60) t2 = id3 * t1 t3 = id2 + t2 id1 = t3 使用 Intermediate code 還能使我們更好的分離前端與後端，並且也增加了移植性與優化的可能性 使用多層的 IR 可以使每層都專注在不同的目標上，這樣可以使編譯過程分隔後更易於模塊化 如果不使用 Intermediate code，我們可能要去應對多種對應不同平台的轉換 1.2.5 Code optimization Code optimization 的目的在於將程式碼變得更「好」，這裡指的並不只是效能上的提升，例如更短或者占用資源更少的目的碼。 分為 Machine-independent(機器無關) 和 Machine-dependent(機器相關)的最佳化: Machine-independent: 發生在 Compiler 的中間階段，也就是生成 Intermediate code 的時候可以進行優化。這種優化並不依賴於特定的平台，因此可以在不同的硬體平台上重用。 Machine-dependent: 發生在 Compiler 的最後階段，也就是將 Intermediate code 轉化為 Target code 的時候進行優化，此時就要考慮不同的機器有不同的 CPU 架構與指令集， 此時就能利用平台的特性來幫助優化。 例如 1.2.4 展示的三位址碼，我們可以對其進行平台無關的優化，直接將 60 轉為 60.0 替代整數就可以消除 inttofloat 運算，並可以少去 t3 = id2 + t2 的運算， 把值直接傳給 id1，這樣就能得到一個更短的 Intermediate code。 t1 = id3 * 60.0 id1 = id2 + t1 Compiler Optimization 通常會另外開一門課特別講述，目前越來越強大的現代編譯器所做的程式碼最佳化已超出許多人預料。延伸閱讀: 你所不知道的 C 語言：編譯器和最佳化原理篇 1.2.6 Code generation Code generator(代碼生成器)將會以 Intermediate code 作為輸入，並將其映射至 Target code，例如 Assembly language。 Target code 若是 Assembly language，就必須為 Intermediate code 的變數分配 Memory address 或 Register A crucial aspect of code generation is the judicious assignment of registers to hold variables 例如 1.2.5 的優化過後的中間碼，這裡進行翻譯成組合語言 LDF R2, id3 // id3 的內容載入 R3 Regiester MULF R2, R2, #60.0 // R2 與 60.0 進行乘法運算 LDF R1, id2 // id2 的內容載入 R2 Regiester ADDF R1, R1, R2 // R1 與 R2 的值相加存到 R1 STF id1, R1 // R1 的內容存入 id1 中 這裡忽略了對於 Identifiers 儲存分配的問題，在後面會討論到 1.2.9 Compiler-construction tools 跟其他軟體開發一樣，開發 Compiler 也可以利用許多現代開發工具，除了通用的軟體開發工具之外也有一些更加針對 Compiler 的工具。 Scanner generators: 可以根據一個語言的 Lexemes 的正規表達式(Regular Expression)描述來生成語彙分析器 Parser generators: 可以根據一個程式語言的語法(Context free grammars)描述自動生成語法分析器 Syntax-directed translation engines: 用於 Traversal syntax tree 並使用 Attribute grammars 生成中間代碼 Code-generator generators: 根據中間語言翻譯成目標機器的機器語言的規則(Tree grammars) 來生成代碼生成器 Data-flow analysis engines: 可以幫助收集 Data-flow(程式中的資料傳遞)，是 Compiler 優化的重要部分 Compiler-construction toolkits: 可用於構造編譯器不同階段的工具 1.3 Formal Language Theory Compilers: Principles, Techniques and Tools 書中 1.3 談論的是程式語言歷史，這裡改為討論語言的定義與自動機。 1.3.1 Language definition 在談論 Formal Language(形式語言)前首先要談的是 Alphabet, String, Language 的不同定義: Alphabet: a finite set of symbols. {0, 1}: binary alphabet String: a finite sequence of symbols from the alphabet. 1011: a string of length 4 ε: the empty string Language: a set of strings on the alphabet. {00, 01, 10, 11}: the set of strings of length 2 ∅: the empty set 對於 String 與 Language 有以下的基本運算: 1.3.2 Grammars &amp; Metalanguage Grammars: The sentences in a language may be defined by a set of rules called a grammar. 例如有語法規則 G: the set of binary strings of length 2 那麼 L : {00, 01, 10, 11} 就是符合該語法規則的句子 Metalanguage : a language used to define another language 如果透過一種語言來定義另一種語言，那麼該語言(Metalanguage) 必須是有明確的規則才能清楚作出清楚的定義，這樣才有可能實作下個階段的 Automata 1.3.3 Automata 我們能在 Compiler 中需要實作的就是 Automata，Automata 往往與 Formal language 密切關聯，自動機被用作可能是無限的形式語言的有限表示。 因此可以在實作上透過 Automata 使語言輸入並通過(Accept) 與 (Transform)轉換。 Acceptor(接受器): 一種自動機，用 Grammar 確定輸入的字符串是否為該語言的句子 Transducer(轉換器): 一種自動機，依照 Grammar 的定義來轉換輸入的字符串成為另一種語言。 狀態機透過 State, Event, Output, Input 來達成如何精確地描述和處理可能無窮大的信息集合。 1.3.4 Compiler-Compiler 既然 Compiler 是透過 Grammars 來進行對一種語言的通過(Accept) 與 (Transform)轉換，這個 Grammars 必定是一種精確的規格(Specification)， 這就讓我們可以透過 Specification 來撰寫 Automata，使我們可以透過 Grammars 來自動生成(Generate automatically) Automata 那麼定義 Grammars 的元語言(Metalanguage) 必然也是有精確的規則存在，那我們當然也可以透過 Matelanguage 來進行 Compiler 的自動生成， 這就是 Compiler-Compiler(編譯器的編譯器) 或 Compiler-Generator(編譯器生成器) 使用不同的 Matelanguage 來定義 Compiler 不同階段的元件，我們就能以此來自動生成這些元件 這是我們在各個階段可以使用的 Matelanguage，以及透過這些 Matelanguage 我們可以怎麼去實作 Automata Lexical syntax: Regular expression: finite automata, lexical analyzer Syntax: Context free grammars: pushdown automata, parser Semantics: Attribute grammars: attribute evaluators, type checker Intermediate code generation: Attribute grammars: intermediate code generator Code generation: Tree grammars: finite tree automata, code generator NOTE 這篇是 Compiler 的第一篇筆記，透過本篇快速了解 Compiler 架構後再深入討論各部分的細節。 Last edit 09-23-2023 13:32"
  },"/jekyll/2023-09-12-operating_system_introduction.html": {
    "title": "OS | Operating System Introduction",
    "keywords": "OS Jekyll",
    "url": "/jekyll/2023-09-12-operating_system_introduction.html",
    "body": "Operating System: Design and Implementation course notes from CCU, lecturer Shiwu-Lo. Introduction 1.1 Why need OS 1.3 User mode/Kernel mode 1.5 User space/Kernel space 1.6 Memory management 1.7 Change mode &amp; System call 1.8 Signal &amp; Systemcall 1.9 Monolithic kernel 1.10 Kernel module 1.1 Why need OS 作業系統使電腦更易於使用 磁碟是由 Block(通常為4K) 所組成，OS 將磁碟劃分為 File，再將檔案歸類為 Folder 才易於使用。 可程式化(Programmable) 變得更容易，OS 能執行執行檔，CPU 執行不同程式碼就會有不同功能。 OS 使程式碼抽象為執行檔，能夠從各個地方載入可執行的程式碼，並且賦予邏輯上的支援。 硬體抽象化(Hardware abstraction) 如滑鼠、觸控板被 OS 抽象化為一個指標裝置，使使用者能統一操作。 OS 上不會只運行一個程式，因此必須有應用程式之間的通訊，如: Copy &amp; Paste。 使電腦的硬體使用更有效率(資源分配) 一台電腦可能有多個硬體存在，OS 可以使這些硬體一起工作。 例如在足夠記憶體的情況下可以同時載入多個執行檔並執行，並使用硬碟堆放暫時用不到的記憶體，以空出記憶體給真正需要的程式。 透過 CPU Scheduler，使 I/O、CPU 都能維持在高使用率。 1.3 User mode/Kernel mode 大部分的作業系統以雙系統(Dual-Mode)(Linux, Windows)，可分為 User mode 與 Kernel mode: Dual mode operation User mode: CPU 所提供的執行模式，只能存取有限的硬體資源，如: 普通運算所需的暫存器、部分記憶體內容 Various applications: libreoffice, gnuplot, pdf viewer GUI: X11, Gnome, KDE System manager: bash, vi, ls, mount, passwd Development tools: gcc, gdb System service: sftpd, sshd Basic inetrnet communication software: Browser, ftp Other library: courses, math Standard function library: Parts defined in POSIX like, libC, pthread Kernel mode: CPU 所提供的執行模式，可以對硬體做任何的變更，在 Kernel mode 能額外控制的部分如下: 控制暫存器(Control register)，例如控制 MMU(Memory management unit) 的相關暫存器、所有記憶體 Memory management Schedule and thread management Inter-Process communication Virtual memory Network communication Scheduler File system Safety, Authority management I/O Subsystem 這種模式下 Kernel mode 才能完全的掌控硬體，今天如果 User mode 上的程式想要存取硬碟則需要透過 System call 來進行操作。在 Linux 的設計原則是速度第一，當然程式越靠近硬體就會更快。 但如果 User mode 想要操作硬體要透過 System call 來進行也就是改變模式(Change mode)，但這樣會產生一定的消耗。而在 Kernel mode 中進行操作硬體就只等於 Function call 的消耗而已。 User mode 想要進行切換就可能需要保存當前狀態以回復、清除 Pipeline、清除 TLB 和 Cache 這些額外消耗。 Dual mode 通常需要硬體額外支援，例如提供一個 Mode bit 的暫存器來決定現在是哪一種 Mode。 例如一個網頁，可以將靜態頁面放在 Kernel mode，動態頁面在 User mode。 但不是將所有程式都放在 Kernel mode，因為只要是程式就會有 Bug，在 Kernel mode 中發生了 Bug 很可能導致整個系統的崩潰。 1.5 User space/Kernel space 虛擬記憶體(Virtual memory)也分為 User/Kernel space，這主要是為了保護 Memory 與 Hardware。 CPU 在切分記憶體時每個單位會附加一些屬性，其中一個重要的屬性就是指出該單位為 User/Kernel space。 Task 之間不能讀取各自的 User space。 Kernel 才能改變權限，I/O，並且擁有所有的存取權。 可否存取 Kernel space User space Privilege instructions Kernel mode ✓ ✓ ✓ User mode   ✓   1.6 Memory management Virtual memory 的管理單位可以分為兩種，分頁(Paging)，分段(Segmentation): Paging: 將連續的記憶體在邏輯上變成 4K 大小的 Page 方便軟、硬體對記憶體進行管理 這是目前最常見的做法，在管理上可以較好的分配記憶體 作業系統會盡量使用 Huge page(大分頁)，一個 Huge page 可以有 2M 到 1G 的大小，因為這樣需要的 Page 數量較少， 在硬體管理上會希望 Page 盡量大一點。 但是 Linux 在 User space 幾乎沒有使用大分頁，除非特別去設定要使用 Huge page，因為在軟體上管理 Page 反而 4K 可以減少記憶體浪費。 Segmentation: 將連續的記憶體在邏輯上變成各個大小不一的 Segment，每個 Segment 對應到程式的特定用途 x86 在 32 位元模式支援 segmentation Segment 在配置上比較困難，但在嵌入式系統中因為沒有什麼動態配置的需求因此較常用 以上的方法都需要硬體支援，是因為 CPU 與硬體的處理速度因此需要硬體支援才能使速度提升。 1.7 Change mode &amp; System call 從 User mode 切換到 Kernel mode，是透過 syscall 這個組語來進行: OS init 時會告訴 CPU 當使用者呼叫 syscall 的時候，指令指標(%RIP Register)應該設定為何(system call 的進入點)，syscall 做兩件事: 保存當前的程式狀態，以便之後返回 將模式切換為 Kernel mode，例如將 Mode bit 設為 0 準備要被呼叫的 System call，例如在x86-64架構中的 %RAX Register 放入要被呼叫的 System call 編號 切換 Stack: User space stack 一開始只配置 16K，不夠再送 Signal 給 Kernel 一次多要 4K Page 最多成長到 8M Kernel space stack 的大小並不會很大，並且 System call 也不會使用產生堆疊的寫法 User/Kernel mode 的堆疊是分開的，Kernel 不能產生 fault，所以在 Kernel mode 使用的是 Kernel space stack 穩定性: 例如 User mode 已經故意執行了一個 7.8M 堆疊的程式，此時 Change mode 但沒有使用 Kernel space 這樣就會遇到 Segmentation fault 保密性: 同時 User space stack 如果執行完沒有進行清空也有可能洩漏 Kernel 的資料 在 syscall 準備 system call 的時候同時還要準備執行環境，例如執行 write(clang) 就要準備好要使用的 stack 來呼叫 C 函數 如果在沒辦法切換堆疊的系統上，也要盡量表留一個給 Kernel mode 使用的堆疊大小 16K 從 Kernel mode 回到 User mode，需要用到 sysret 指令來進行，此時 OS 會返回地址(接下來執行的 User mode 程式碼)，sysret 做兩件事: 返回 user mode 的程式碼位置，例如 x64 放在 %RCX Register 切換為 user mode，例如將 Mode bit 設為 1 不是所有的 System call 都會進行完整的 Context switch，例如 getpid()，就不需要把當前的程式狀態保存完整。 System call handler 必須確保從 Kernel 返回 User mode 時，程式將來可以繼續執行 Super user 也是使用相同的 System call 進入點，大部分的 System call 會判斷權限但 uid=0 的時候就直接通過，General user 的 uid &gt; 1000。 Linux 定義了約 400 System call(Function)，大部分都透過 syscall 進入 Kernel。 1.8 Signal &amp; Systemcall 當 Kernel 有特別事件需要主動通知 Process，就使用 Signal 機制，Signal 接受兩個重要參數: 事件編號、發生該事件時呼叫該程式所定義的特定函數 事件編號: 例如 SIGINT 的編號是 2，表示鍵盤中斷(例如 Ctrl + C)，每種 Signal 都有唯一的編號，OS 中已被定義 該事件發生時所處理的函數，可以是程式自己定義的函數或是系統默認的函數呼叫 Linux kernel 只允許一個 Process 同時間發出一個 Blocking system call，需要等待 Kernel 完成該工作(System call)才回傳的系統呼叫。 當 Process 發出 Blocking system call 後，該 System call 還未結束前如果發生 signal(例如 Ctrl + C)，Kernel 該如何處理? 不理會該 Signal，繼續完成 System call 處理該 Signal，該 System call 變成失敗，通常作業系統會重新起始(Redo)該 System call 延伸閱讀 Linux Signals、Interruption of system calls when a signal is caught 1.9 Monolithic Kernel 假如一個人一天可以讀 1000 行程式碼，Linux kernel 的成長速度可能是一天超過 3000 行。 Monolithic kernel 大部分的系統功能都設計在 Kernel mode 中，這樣的好處是執行效率，各個模組間的溝通僅為 Function call， 但同樣的 Kernel 也變得越來越複雜，也容易產生錯誤。 Micro kernel 盡可能的將 OS 的系統服務執行於 User mode，讓系統變的較為穩定， 但是 User mode 的 Process 通訊需要觸發 Context switch 與 Mode change，效能較為低落。 設計模式 系統程式 效能 核心大小 通訊消耗 OS Monolithic 大部分在 Kernel mode 高 大 Function call 的消耗 Linux, BSD Micro 大部分在 User mode 低 小 Context switch 的消耗 Minix, L4, Android Linux 在安全性思考上可以思考 root 的權限是否太大了，root 有權看到所有的資訊，在安全性上可以透過加密來做到。 Context switch &amp; Mode change 這兩個要分清楚: Context switch: 原本在執行 Process A，現在要換成 Process B Mode change: Process A 原本執行在 User mode，因為要執行 System call 現在要切換到 Kernel mode 1.10 Kernel Module Kernel moduel 在意義上就是核心的插件，可以擴充核心的功能，最直觀的插件就是驅動程式。 Monolithic 設計下的 Kernel module 運行在 Kernel mode，Micro kernel 則相反。 Kernel module 在需要的時候再載入，例如 USB 如果是是一個 ext4 file system， 插入電腦後 Linux Kernel 認出後就能載入 ext4 module 來讀取該 USB lsmod 列出目前的 Kernel module，並且 Kernel module 之間會有相依性，例如如果 Network 是一個寫好的 Kernel Module， 那它就會依賴於 Network card 的 Kernel module。 Main Memory 1.11 Main memory usage 1.12 Memory and storage consistency 1.13 Linux base file system management 1.11 Main memory usage Linux 將主記憶體分為三種主要用途: Cache memory(Page cache): 將 Disk 或 SSD 等儲存裝置上的內容暫存於記憶體中，以提高存取速度 檔案系統的 Metadata!? Buffer memory: 與 I/O 之間的的資料交換，DMA 主要是 CPU 的速度高於周邊速度，格式的轉換等等(如網路卡) Program memory: 將記憶體分配給程式使用，如: 程式可以透過 malloc(背後的 System call 常常是 brk)、nmap 等函數索取記憶體 執行檔必須載入主記憶體後才能執行 Linux 原則上會盡可能的使用掉所有記憶體以加速 I/O，當記憶體不足時 Linux 會釋放 Cache memory 和 Buffer memory。 1.12 Memory and storage consistency 主記憶體採用 DRAM 斷電後失去內容，因此需要非揮發性的第二層儲存裝置(Secondary storage，Disk, SSD)。 而電腦必須將第二層儲存裝置的內容載入記憶體後才可以供 CPU 運算 可以透過明確的程式碼存取資料，如: open, read, write 也可以透過 mmap 的方式將檔案 Maping 到應用程式的記憶體空間加以處理 程式與 OS 都必須定期的將資料回存到下層裝置 OS 與 I/O 函數庫都可能透過 Buffering 的機制，以批次的方式寫出資料以增加效率 應用程式可以呼叫函數強制將資料寫出，如: sync, fsync, fdatasyc 效能上的考量 read &gt; write，read 不能延遲，延遲將導致程式無法執行。 結果上的考量 write &gt; read，當使用者使用 Ctrl+S 進行儲存時，若在中途當機資料並沒有真的寫入 Disk，使用者將無法接受。 write 往下寫入時不一定馬上把資料寫入 Disk，有可能只是先暫時存在 Memory/Buffer 中，同時裝置上可能也會有 Buffer 例如 SSD。 這裡有例如 Write-through，Write-back 等不同方式的寫入是 OS 能進行操作的。 Write-through: 寫入 Main memory 時同時寫入 Cache 這樣可以保證資料的一致性 Write-back: 寫入數據時先寫入 Cache，並將資料標記為 dirty(已修改但未寫回主記憶體)，然後在稍後的時間點將資料寫回記憶體，例如: Cache 需要新的空間來儲存新的數據 深入思考，如果裝置上能有電池的話就能保證寫入時部份的安全性，如果已經寫入裝置上的 Buffer 此時電源出現意外也能短時間內進行儲存 延伸閱讀: Write-through vs Write-back 1.13 Linux base file system management 九字檔案權限管理，分為檔案與資料夾，詳情可看鳥哥的介紹 第七章、Linux 磁碟與檔案系統管理 Linux 的檔案系統支援 ACL(Access control list) ACL 可以對各個使用者或各個群組分別設定權限 ACL 依賴底層的檔案系統支援，如: EXT4, BTRFS 等都支援 ACL 可以使用指令 setfval 與 getfacl 分別設定及讀取檔案或目錄的權限 但是有時後 Normal user 也需要更改權限來執行某些程式，例如: passwd, 他會在執行中使用 setuid 來暫時改變使用者權限， 直到 passwd 執行結束(或者是該程式放棄 root 權限) Computer world 中的權限往往與現實世界的權限不相等 Linux 中 root 擁有最高權限，root 可以對檔案系統、應用程式(記憶體)進行各式樣的操作 root 可以存取所有使用者的檔案(甚至是機密檔案)，這與真實的權限不符合(老闆 = Normal，系統管理者 = Super) 目前大部分的 Linux 提供資料夾加密的功能，可以部分改善問題 I/O Subsystem 1.14 I/O Subsystem &amp; Control 1.15 I/O Subsystem transfers data 1.16 CPU and DMA compete for memory access 1.14 I/O Subsystem &amp; Control 周邊裝置可能有不同儲存資料的方式，例如滑鼠鍵盤可能僅需要內建暫存器，而網路卡、硬碟可能有自己的內部記憶體，儲存的資料與周邊的晶片來運作裝置。 I/O Subsystem 是 OS 的一個重要部分，負責管理程式的 I/O 請求。 I/O Subsystem 的控制流程通常如下: 向周邊下達命令 於記憶體及周邊之間做資料傳輸 通知處理器「工作已完成」 Memory mapped I/O 目前主流使用的 I/O 方式 將周邊的控制「暫存器、記憶體」映射到 CPU 的「記憶體映射空間(Memory space)」 例如使用指令: MOV CX, 0xFFFFFFFF; 假設 0xFFFFFFFF 是裝置記憶體，將 CX register 的值放到位置 0xFFFFFFFF 就等於向下儲存資料 上圖模擬一個可能的 MMIO，DRAM 與不同的 Device 分別被映射到不同的記憶體區段。裝置有自己的控制暫存器、 去設定讀取的指令來在裝置的晶片上執行，在裝置暫存器讀寫的程式就被稱作(Device driver)驅動程式 Port mapped I/O 目前在一些嵌入式處理器上使用，因為 x86 是較古老的架構因此也有支援 PMIO 使用特別的指令，將資料傳輸到特定的「Port」，注意: Port 和 Memory space 是分開的定址空間 x86-32 的 I/O Port 的定址空間只有 0~65535 x86-32 的記憶體定址空間只有 0~4G 使用的指令形式如下: out 0x255, AX; 將 AX register 寫到 0x255 Port，對裝置寫入資料 in AX, 0x100 從 0x100 Port 將資料寫到 AX register，將裝置資料取回 Device、Memory 分別用不同的定址方式，I/O Bus 為 64K 即最多 65536，Memory 則可以到最大 4G，這種架構下指定的速度通常比較慢，因為 MMIO 可以更簡單與直接的進行 I/O。 延伸閱讀 I/O對應的方式 1.15 I/O Subsystem transfers data 傳輸資料上，一般來說不會使用 CPU 進行，因為 CPU 要做更重要的事。DMA(Direct memory access) 是相對簡單的硬體， 專門用來做主記憶體對主記憶體的傳輸或裝置記憶體對主記憶體的傳輸。 簡單的 DMA 只要計數器，被搬移資料的開始位置，要搬入資料的開始位置，這樣三個 Register 就完成一個能搬移連續資料的 DMA DMA 可以屬於 Bus 的一部分，如: ISA，或者是裝置的一部分，如: PCI (DMA and Cache)Coherency problem 只要有兩種介面存取同一個儲存裝置就一定會有如何同步的問題 DMA 直接存取記憶體，但 CPU 透過 Cache 存取記憶體，這造成資料不一致(Cache 的資料一定比 Main memory 新) 從記憶體寫出資料到裝置時，必須將 cache 的資料 flush 到記憶體(寫入主記憶體) 從裝置讀取資料到記憶體時，必須先 invalid 相對應的 cache line Alignment DMA 傳輸的資料的開始及結束位置，通常要和 Cache(Cache line) 和 Memory 的寬度進行對齊 這部分的限制可能來自於 DMA Controller 直接將資料以「固定的大小」更新到 Cache。例如: x86 是 64 個 Byte，那傳輸資料就跟 64 Byte 對齊。硬體在這裡沒有特別做處理，使得非對齊的資料也可以部份更新 Disk 與 DRAM 之間的交換也要使用 buffer 來進行交換，才能避免低速讀寫去占用寶貴的 Bus 資源。當 bufdisk 將資料傳給 bufRAM 後此時要處理的就是 bufcache 與 bufRAM 之間的一致性 Cache 與 DMA 的資料不一致性解決之道 (DEV =&gt; CPU) 使用硬體解決，硬體自動會將 DMA 的傳輸更新到 Cache 內(Cache coherence algorithm) 某些處理器，例如早期的 ARM 處理器，這部分需要特別的指令設定該段記憶體的「屬性」 例如直接將該段資料直接從 cache 上完整移除(flush)，這樣就能確保 CPU 讀取記憶體時從 Main memory 讀取 用硬體來進行處理的話可以分段去處理，這樣就能在分段中偷偷傳輸資料，總有一些 Cycle 沒有被使用 (CPU =&gt; DEV) 設定讓 CPU 在該記憶體區段進行寫入時，使用 Write through 或 Noncacheable，直達裝置上的記憶體 Noncacheable: 直接將資料寫入該段記憶體而不透過 Buffer，這樣能確保 DMA 的資料是最新的，但會降低效能。 延伸閱讀 Cache和DMA一致性 1.16 CPU and DMA compete for memory access 如果 CPU 發生 Last-level-cache(LLC) miss 時，CPU 可能會合 DMA 爭奪存取權: 如果 CPU 訪問 LLC 時，如果發現沒有所需要的數據，CPU 可能會嘗試直接存取 Main memory，若此時 DMA 也正在進行存取， 就會產生爭奪存取權。 DMA 每次都只傳輸小量資料，那就可以很快的禮讓控制權給 CPU，但這樣的傳輸模式很沒效率 DMA 做大量傳輸可以提升 I/O 的效能，但可能會造成 CPU 等待 DMA 完成傳輸而閒置 延伸閱讀 Burst mode 目前在 PCI 上每個 Device 都有自己的 DMA Arbiter 用來分配不同的 Device 的存取權，通常是速度越快的裝置優先權越高 DMA 的其他議題 DMA 的定址空間 部分 DMA 的定址空間可能只有 32bit，OS 必須盡可能的將 DMA 能使用的記憶體保留給 DMA 使用 I/O MMU 主要讓 DMA 存取實體位置不連續的記憶體 避免惡意的裝置或驅動程式 DDIO (Data Direct I/O) 在某些 Intel 平台上，DMA 的傳輸可以跳過 DRAM 直接傳輸到 cache，例如: Xeon, DDIO 例如 ARM 上的 ACP(Access to Shared Caches)，即使用 DMA 對這個裝置進行操作， 其內容也會被同步到 cache memory 裡面，包括 L1 和 L2 cache Access to Shared Caches vs. Traditional methods I/O Subsystem notify the CPU 1.17 Interrupt hardware concept 1.20 Interrupt vector table 1.21 Interrupt Service Routine 1.22 Bottom half 1.23 Bottom half and Top half 1.24 Polling 1.25 Buffering OS 交付工作給周邊裝置後，於工作完成後通知 CPU 的方法可以使用: Interrupt Polling Interrupt + Polling 1.17 Interrupt hardware concept Interrupt 是一種改變程式正常執行流程的機制，可以由 Device 或者 CPU 本身產生 Legacy Interrupt 由實體線路構成，每個裝置連接到實體的中斷線，中斷線連接到 Programmable interrupt controller(PIC, 可程式化中斷控制器)，PCI 再向 CPU 的 INT 腳位發出中斷訊號 PC 中斷線也就共 15 條，但是 Device 通常不只 15 個，因此必須數個裝置共用一條中斷線 Message Signaled Interrupts 所有 Devices 共用一組中斷線路，裝置在中斷線路上寫入自己的中斷編號，就會觸發 CPU 中斷 這樣就類似在一條線上傳輸編碼，經過解碼器後推向 CPU，讓 CPU 對自己送出中斷，例如: PCI 的 MSI-X 支援 2048 個中斷編號 CPU 會設計好 IVT 的位置，由 OS 放入適當的 ISR 這部分也是驅動程式(Device Drver) 的一部分 1.20 Interrupt vector table Interrupt 處理流程: Interrupt Request: 當中斷請求發生時，將所有中斷 Disable，將 CPU 切換到 Kernel mode Store State: 暫停目前的 Process 並保存此 Process 的執行狀況 Interrupt Vector Table: OS 根據 Interrupt ID 查詢 IVT，並取得 Interrupt Service Routine 的開始位置 Interrupt Service Routine: 執行 ISR Restore State: 恢復之前 Process 的執行狀況 這時候不一定恢復原本的 Process，因為 System call 可能改變 Process 的狀態，由 Scheduler 來決定下一個執行的 Process(不一定是原本的 Process) IVT 放置的是 ISR 的開始位置 ISR 開頭都是用組語寫的，如果 C 的執行環境設定好也可以用 C 1.21 Interrupt Service Routine 發生 Interrupt 時是 Disable Interrupt，但在 ISR 的時候可以視情況決定是否要 Enable Interrupt，要允許哪寫 Interrupt，如果再 ISR 中 Enable interrupt 表示允許巢狀中斷(Nested Interrupt) Nested Interrupt: 「一個中斷，被另一個中斷給中斷」 Linux 中，ISR 只處理必須立即處理的部分，剩餘的部分交由 Kernel thread 處理。例如: ksoftirqd ISR 中不能呼叫任何會造成「wait」的函數，例如: semaphore 中的 wait() 從設計上 wait() 的主體是 task (can context swtich)，ISR 只是一個有自己堆疊的函數，不是 task 從邏輯上 ISR 是處理 I/O 中的「必要部分」(緊急性)，因此不應該 wait() 如果程式邏輯上必須要 wait()，就要考慮是否把這部分留給 Bottom half 解決 1.22 Bottom half Bottom half 可以分為三種 softirq, tasklet, work-queue Softirq 可以在多個 CPU 上平行運行，必須在編譯時靜態註冊 Tasklet 是建立在 softirq 之上的一種機制，tasklet 可以動態註冊和銷毀，相同類型的 tasklet 不能在多個 CPU 上同時運行 Work-queue 是一種完全不同的機制，work-queue 可以確保同一種類型的 driver 只會在同一個 CPU 上運行 從效能高低上是從左往右排序，從易寫程度上是從右往左排序 理論上這三個都應該由 Kernel thread 來呼叫 如果是 Kernel thread(task) 那就可以 wait() 實際上 softirq, tasklet 在 Linux kernel 可以由 Linux kernel 提供的一小段程式碼在 ISR 結束時呼叫 這樣的話他是執行在 ISR 中，這樣是不能 wait() 會設計成 ISR 也可以呼叫的原因是，如果這次 ISR Loading 並不重的時候就乾脆全部的工作都在 ISR 完成，這樣的消耗會比呼叫 Kernel thread 更少 在 Driver Architecture 篇章會更詳細的說明 ksoftirqd 最多寫 32 個驅動程式在裡面，只有高速裝置會掛在 ksoftirqd 例如: Network Card 延伸閱讀: Difference between SoftIRQs and Tasklets, tasklet, taskqueue, work-queue – which to use? 1.23 Bottom half and Top half Bottom half 的 softirq 每個 Core 就只有一個 ps -e | grep softirq 在這裡 Top half, Bottom half 分別指的是: Top half: 是指來立刻響應的 Interrupt 時處理的中斷函數，在這個階段執行快速且必要的硬體操作，如: 保存狀態，和呼叫 Bottom half Bottom half: 跟 Top half 的區別是執行期間 Interrupt 是啟用的 這裡進入 Bottom half 的工作會被包裝成一個 Struct 兩個 Pointer，包含 Function, Data，然後將這個 Struct 加入一個 Linked list， 之後等待 CPU 有空閒時 softirq 會從中取出 Struct 來執行 Bottom half。 Function pointer: 該函數定義了 Bottom half 實際的執行工作，包含: 處理資料，啟動另一個 I/O 等等 Data pointer: 指向工作相關的資料，硬體的資料，要計算的參數，需要修改的 Memory 等等 在 Linux 中，當 top half 決定將一些工作推遲到 bottom half 時，這些工作會被包裝成一個結構，該結構包含兩個指標：一個函數指標和一個資料指標¹。 1.24 Polling 如果系統的 Loading 很輕，並且系統請求的時間比較沒規則時 Interrupt 會比較好，但如果負載高 Interrupt 被不斷的送出， 這樣可能會導致 CPU 不斷的去處理 Interrupt，此時 Polling 會比較好 與 Interrupt 不同，Polling 是 OS 每隔一段時間主動去探詢裝置的狀態 如果數個 Device 共用同一條 Interrupt 那麼當 Interrupt 發生時，OS 必須 某些裝置同時支援 Interrupt 和 Polling，例如: Network Card，可以在負載量高/低時做切換 像滑鼠跟鍵盤就通常是採用 Polling，除非有特殊需求，例如: 電競滑鼠 1.25 Buffering and Kernel bypass read(fd, buf, 200) 會用掉四個 Register read(): 本身就是參數(No. 3 Interrupt, $AX 要設定為 3) fd: 從哪裡讀資料 buf: buffer 的起始位置，200 Buffer size read 呼叫後 Kernel 會配置 krl_buf，DMA 傳輸會將資料從 dsk_buf 搬移到 krl_buk 最後由 Kernel 將資料 Copy 到 Userspace Kernel bypass: 是指不需要透過 Linux kernel 的功能，使用自己實現的相同功能的程式碼直接將 Device 的資料 Copy 到 Userspace 這可以幫助解決在高 concurrent 下由於 Interrupt Handling, Memory Copy, Context switch, Locality miss, CPU Affinity, Memory Management 所造成的性能瓶頸 代表的技術有 DPDK, eBPF 等等 延伸閱讀: kernel-bypass 内核旁路技术介绍 Scheduler and File System 1.26 Process and Thread of Linux 在 Linux 提供下列 System call fork(), vfork() 產生 Process clone() 產生 Task(Process, Thread) execve() 將一個執行檔內的程式載入該 Task 中 對 Linux 來講 Process, Thread 都是 Task Linux 使用 Task struct 來描訴 Process, Thread Process, Thread 的差異只是「共享資源的多寡」，尤其是記憶體是否共用 fork, vfork, clone 都是呼叫 Kernel 中的 do_fork 有一些 Thread 只執行於 Kernel mode，Linux 稱為 Kernel thread 1.27 Scheduler 如果只說 Scheduler 通常指的是 CPU Scheduler 傳統上 Scheduler 希望達成以下目標 依照優先權賦予優先權的公平性 所有的 Task 都可以在合理的時間內，再次獲得 CPU 使用權 優化 I/O 效能，例如: 處理 I/O 的設備可以先執行，接下來工作交給 I/O 設備 Linux 更進一步的達到以下目標 Multi-core 上能做到 Load balance Scheduler 本身不至於造成 Multi-core 的效能瓶頸 對多媒體、遊戲有更好的支援，CFS Linux 還未達到的目標 Real-time system 的支援 Linux 在手機上的 Scheduler 比 iOS 的 Scheduler 更耗電(iOS 並不是真正的多工 OS) 1.28 File system 在檔案系統要注意到這些: 新技術如： SSD、管理的問題(大檔案、零碎檔案)、存取行為(循序/隨機存取)、檔案的重複性問題、混合硬碟(SSD\\HDD) Linux 使用 Virtual file system(VFS), 兼容多種檔案系統，大部分這些檔案系統都使用「i-node」的概念描述檔案 i-node: 用於描述檔案或目錄，裡面儲存資料的屬性和位置，例如: 所有者、許可權、大小、最後修改時間等 VFS: 透過統一的介面，使無論底層的檔案系統是什麼，都能透過介面處理，例如: open(), read(), write() File system: 用於管理底層裝置資料存取的機制，例如: ext4, NTFS, FAT32 … Linux 官方的 File system 是 ext4’ ext4： 是 Journaling file system，因此當發生意外，檔案系統不至於完全損毀，並且能快速恢復(fsck.ext4) Linux 支援 btrfs，btrfs 借用了 zfs 的很多概念，主要包括: snapshot, copy-no-write, hot plugging HDD/SSD, difference disk load balance, backup support Hardware progress 1.29 SMP and CMP 1.30 Single-ISA heterogeneous multi-core 1.31 UMA and NUMA 目前已經很難提升 CPU 的 Clock 相同架構下，提升 Clock 是最直接方式來的提升 Performance 提高 Clock 會遇到大量的熱，也是提升效能的瓶頸 Processor, Menory, Storage 等等藉由不斷的「複製，貼上」產生平行運作 平行運作往往需要軟硬體結合 很多時候，硬體提供「多種選擇」給軟體進行優化 寫平行化程式，程式碼每年可以有 23% 的效能提升，否則只有 4.6% 平行處理架構指的是「同時使用多個 Process(Core)」例如: PC 常見的 Multi-Core Process 他的優點: 提高產能: 在工作可以平行化時，產能將以倍數提升 成本考量: 相較於高時脈的 Processor，工作平行化後，數個時脈低的 Processor 能得到一樣的效果 增加可靠度: 高階伺服器可以提供 Processor, Memory 熱插拔的功能，例如: Linux, 可以在不停機的情況下更換 CPU 1.29 SMP and CMP Symmetirc multiprocessor(SMP, 對稱多處理) 每個 Processor 的地位是等價的，應用程式可以在這些處理器上做轉移(migration) 在這個架構上所有 Processor 都共享一個共同的 Main memory，有可能會導致記憶體存取衝突而影響效能 Chip multiprocessor(CMP, 單晶片多處理) 也稱作 Multi-core 將多顆 (Core)Processor 集成至一顆晶片 每個 Core 都有自己的 Cache 可以減少對共用 Memory 的存取需求 共享最下層的 Last level cache(LLC)，因此不同 Core 之間的轉移比較快速 Simultaneous multithreading(SMT, 同步多執行緒) 在一顆 Processor 上用硬體模擬出 N 顆 Process，硬體的主要成本是 Logical register 數量增加 N 倍 能更有效的利用 Processor 內部的 Function unit，如: 加法器，乘法器等 Intel 宣稱他們實現的 SMT(Hyper-threading) 增加 5% 的晶片面積，可以獲得 15% ~ 30% 的效能提升 AMD 於 2017 推出的 Zen CPU 也實現了 SMT 上方右圖有兩個 Instruction flow(Register set) 去競爭資源，例如: Floating point unit, Adder, Loader, Storer SMT 不是去增加系統的速度，是增加系統的使用率，前提是有足夠的 Task 跟進行的運算可以 Loop unrolling， 例如: Fibonacci 因為每次都必須算出前一個數字才能繼續後面數字的運算 延伸閱讀: Algorithm Efficiency - Is partially unrolling a loop effective if it requires more comparisons? 1.30 Single-ISA heterogeneous multi-core 在學術上是多個處理器，這些處理器使用同樣的指令集，但是處理器的內部設計(Micro-Architecture)不同 例如: Clock，Pipeline depth，Funciont unit number 有些程式指令平行度高，適合 Pipeline、Superscalar 有些程式指令平行度低，適合 In-order issue、High clock processor 因 Instruction set 相同，OS 可以幫合適的 Task 挑選適合的 Processor ARM 上實現的 Big-Little 架構是上述的一個實現 雖然 Processor 運算速度不同，但其 Instruction set 相容 OS 可以依照需求使用高效能 Processor(Big) 或省電型 Processor(Little) 在 Big.Little 中可以做 Task migration，這部分是 OS 跟 Programmer 需要去考慮的 SMT 是由 DM Tullsen, SJ Eggers, HM Levy 所提出 Simultaneous multithreading: Maximizing on-chip parallelism, ISCA, 1995. Intel 於 2002 實現這個構想，並將它稱之為 hyperthreading Big.LITTLE 的概念由 R Kumar, KI Farkas, NP Jouppi, P Ranganathan, DM Tullsen 提出 Single-ISA heterogeneous multi-core architectures: The potential for processor power reduction, MICRO, 2003. 更厲害的是：這二個架構的創想來自於同一個實驗室 https://cseweb.ucsd.edu/~tullsen/ 1.32 UMA and NUMA 目前為止(2018)所使用的 Processor memory architecture 大部分為 Uniform memory access(UMA) 大致上可以說: 每個 Processor 存取任何位置的 Memory 的速度都是相等的 UMA 架構使用一套記憶體插槽，也就是共享 Memory bus 對於 UMA Processor 而言，當 Processor 增加時，記憶體頻寬是效能瓶頸所在(Intel core i9 是有 18C36T 的 UMA Processor) Non-Uniform memory access(NUMA) 傳統上是插兩個以上的 CPU，如部分機架式伺服器: HP DL380 Gen7 AMD 的 threadripper 將兩顆 CPU 封裝在一起，threadripper 上可以看到兩個 DRAM 插槽 對 NUMA 來說記憶體分為 Local, Remote，存取 Local 時的速度會較快 這樣的做法兩邊都會有獨立控制的 Memory bus，避免了部分的記憶體頻寬的效能瓶頸 Driver Architecture Driver 中可延遲處理(Bottom half) 的形式就分成三種，這部分在 Bottom half 簡單提過: softirq(軟中斷) softirq 支援 SMP，同一個 softirq 可以在不同的 CPU 上同時運行，softirq 必須是 Reentrancy(可重入的) softirq 是在編譯期間靜態註冊，不像 tasklet 那樣能被動態註冊或去除 HI_SOFTIRQ, TIMER_SOFTIRQ, NET_TX_SOFTIRQ, NET_RX_SOFTIRQ, SCSI_SOFTIRQ, TASKLET_SOFTIRQ 基本原則是使用在高速裝置或該裝置不能被延遲，如: Network RX/TX, Timer inputerret, Disk, tasklet softirq 在 Kernel 編譯是就已經定義、註冊好，通常是不會去做改寫。會使用 softirq 的原因主要是因為發現 I/O 的效能瓶頸是在 CPU， 前提是要有足夠的 Processor。 tasklet tasklet 不允許兩個相同類型的 tasklet 同時執行，即使在兩個 work-queue 由 Kernel theard 來實現，所以可以被 context switch(前兩種只能被 ISR 打斷) 適合需要長時間執行，或需要 seelp 默認可以被 Interrupt，不持有任何 Locked 延伸閱讀: V-Softirq in Linux Device Driver – Linux Device Driver Tutorial, Linux softirq, tasklet, workqueue 下面是 Interrupt 離開時觸發 softirq 的流程與程式碼: ksoftirq 是在 Kernel thread 會去呼叫 Loop，這個 Loop 會不斷去拿工作來做，這個 Loop 可以被 ISR 或 ksoftirqd 呼叫， 如果是由 ksoftirqd 呼叫那就可以 sleep，但如果是由 ISR 呼叫 Loop 則是執行在 Interrupt context 那就不能 sleep。 會設計 ISR 可以呼叫 Loop 的原因是 Linux 為了優化，如果 Interrupt 所觸發的工作並不多，就乾脆在 ISR 中處理完 若是由 ksoftirq 呼叫就會讓 Interrupt 先結束，後續讓 Scheduler 來安排 Task 進行工作 invoke_softirq() 會去 Loop 中拿取工作來執行 force_irqthreads 用這個變數來判別是 Interrupt context 呼叫還是 Kernel thread __do_softirq(), do_softirq_own_stack() 都是去執行 softirq，差異在 IRQ STACK 詳細可見延伸閱讀 wakeup_softirqd() 則是叫醒 ksoftirqd 把剩下的工作交給 ksoftirqd 來排程 延伸閱讀: Linux kernel的中断子系统 softirq 相較於 softirq, work-queue 的流程單純很多，不會運行在 Interrupt context: General rules for driver writing 共用的資料跟誰共用，雙方是否會同時執行: 會: 就要使用 spinlock(Mulit-Processor)、semaphore(Signle-Processor) 不會，那要注意是否會 Preempt: 誰會 Preemmpt 誰 如果單一方向如 A Preempt B，B 去 Disable A 就不會有 Rest condition，例如: Scheduler, Local IRQ, Bottom half 如果是雙向的 Preempt 那就是會同時執行 要很清楚程式中隱藏的意思 例如: malloc 是否會造成 Context switch, write 會做 I/O 動作會不會 Context switch Start the OS 1.33 Start the OS 為什麼不能直接從 Disk 啟動 OS，這是因為 Disk 也需要 Driver 來啟動 CPU 能直接控制 DARM, ROM 是因為這兩者都是 Byte address CPU 只要在 Address bus 上放入要讀取的資料的 Address 就能從 Data bus 上讀取想要的資料 Disk 屬於 Block device 需要下達命令告訴 Disk 需要第幾個 Block，之後 Disk 再講 Block 寫到軟體指定的位置，如： (ATA-8, ATAPI) 如果沒有軟體驅動的情況下 CPU 無法直接讀取 Disk，因此需要在 PC 架構中在 Boot rom 中放入「BIOS」， BIOS 的重要目的就是讀取 Disk 上的 Boot sector。 Bootstrap BIOS(ROM) 讀取 Boot sector(通常是 Disk 上的第 0 個 Block) BIOS 會帶起來的是 GRUB(Boot loader)，現在也可以從 BIOS 使用 UEFI(BIOS 也認得 OS) 如果帶起的 OS 是 Linux 那麼就必須把開機相關的檔案放在 /boot 下，並且 GRUB 認得該目錄使用的檔案系統 Linux kernel 先掃描裝置狀態，根據裝置狀態配置記憶體(Virtual memory layout)，之後再啟動 Cache 先設定 Virtual memory 是因為這裡必須將映射到 I/O 的部分設定為 Non-cached Linux kernel 啟動後，啟動第一個 User space 的程式，傳統上是 init，也有許多 Linux 改用 systemd，他們的 pid 都是 1， 負責 Linux 後續的初始化 這裡是因為對應 I/O 的區段(例如: DMA)，不希望這些操作被 Cache，如果被 Cache 可能會導致資料不一致，因此要先設定 Non-cached BIOS limitations BIOS 必須要認得 Disk 上的開機 Block，如果 BIOS 不支援該 Disk，將無法啟動 OS(例如: 容量超過 BIOS 的定址範圍) BIOS 內含多種驅動程式，例如要支援 USB 大部分 BIOS 不支援藍芽裝置，因此開機時的藍芽滑鼠，鍵盤等等都不能與 BIOS 互動 Last Edit 10-09-2023 18:27"
  },"/jekyll/2023-09-07-test_case_generation_based_on_constraint_logic_graph.html": {
    "title": "Paper | Test Case Generation Based on Constraint Logic Graph (Unfinished)",
    "keywords": "software software_qualitiy generate_test_case Jekyll",
    "url": "/jekyll/2023-09-07-test_case_generation_based_on_constraint_logic_graph.html",
    "body": "Chiao-Yi Huang, “Test Case Generation Based on Constraint Logic Graph”, 2015. 本論文描述一種基於限制邏輯圖所進行的限制式案例產生技術的黑箱測試，並將該測試案例產生器實作成一個 Eclipse 的外掛套件。 1. Introduction 1.1 Motivation 根據 Standish 團隊的 2015 CHAOS 報告指出目前開發高品質的軟體系統十分困難，確保軟體品質的主要方法即是軟體測試。 這裡指出了幾個測試流程: Unit testing(單元測試) Intergration testing(整合測試) System testing(系統測試) Acceptance testing(驗收測試) 而 Tase case 的產生可以分為兩種方法: Black-box testing(黑箱測試) 在測試前先依照規格慘生測試案例，是本論文使用的方式，透過 UML Class diagram 搭配 OCL 來描述規格 White-box testing(白箱測試) 其中針對單元測試的 Tase case 可以分成兩種情況: Vaild test case(符合前置條件的測試案例) 符合程式預期輸入與輸出的測試案例，需要先得知測試前後的系統狀態(system pre-state/post-state)，參數(argument)，回傳值(return value) Invaild test case(不符合前置條件行為測試案例) 可對程式產生錯誤的測試案例，也就是在 Java 中所發生的例外狀況(exception)。 1.2 Method 限制式測試案例產生(constraint-based test case generation)技術是一種重要的測試案例自動產生技術， 將測試案例產生問題制定為限制滿足問題(Constraint Satisfaction Problem)，以此有四個主要問題需要解決: 軟體行為規格的描述 軟體等價行為的分割 軟體測試覆蓋標準的滿足 軟體等價行為所對應的限制滿足問題的敘述 第一個問題，本論文將物件限制語言運算式(Object constraint language expression)轉換為限制邏輯圖(CLG)，以 CLG 來表現受測函數的程式行為。 第二個問題，本論文定義一個完整的限制邏輯圖路徑就代表一個完整的程式行為，即為一個等價類(Equivalence class)， 透由 CLG，原本是無限組合的析取正規式(DNF)的受測函式程式行為，變成可數的受測函式程式行為，將這些程式行為分割成一個可以被管理的等價類集合， 等價類內的全部測試案例都被當作找錯誤的能力都相同，只要從每個等價類中挑出一組測試案例，即可產生出必要的測試案例。 第三個問題，這裡分為兩個部分來討論： 第一為規格覆蓋標準，由選擇的規格覆蓋標準評估規格覆蓋度需要到甚麼程度，我們提供了三種覆蓋標準。 Decision coverage (DC) Decision condition coverage (DCC) Multiple condition coverage (MCC) 第二部分則是針對已經產生的限制邏輯圖是否產生足夠數量的可視完整路徑，稱之為限制邏輯圖覆蓋標準。 第四個問題，將可實行路徑上的限制式收集，並將這些限制式轉換成限制邏輯程式， 就可以使用限制邏輯語言找解器(Constraint logic programming solver)(ECLiPSeclp) 求出測試資料(測試資料包含測試輸入與預期輸出與系統狀態)， 最後將測試資料轉換成需要的平台的測試案例，而在本篇論文中可以針對 Java 的平台轉換成 JUnit 測試案例。 圖二為依照這四個問題所建構的測試工具整體架構，以下說明各個架構的功能 限制邏輯圖轉換器: 描述如何根據我們得到的受測函式的 物件限制語言(OCL) 產生他相對應的 限制邏輯圖(CLG) 路徑條列器: 從 限制邏輯圖(CLG) 產生 可實行路徑(feasible path) 的方法，一條完整的路徑也不代表這條路徑可以產生測試案例， 必須能分辨它是否為可實行路徑 限制邏輯程式產生器: 我們需要的資料不僅是受測函式相關資料，還需要產生執行此受測函式時相對應的執行前與執行後的環境， 我們根據 UML 的關聯中對於物件的限制找到適合的系統狀態，並且每個物件都會滿足自身定義的恆定條件。 而在待測函式的路線中，可能會呼叫其他的函式，為了讓函式呼叫能正常的運作並且符合應有的限制式，我們還會在測試案例中補上其他函式的模擬。 測試資料解析器 得到測試資料後，由於測試資料只是純文字，透過此解析器得到測試資料的詳細資訊。 測試腳本產生器 這裡的測試資料是與平台無關的，需要透過測試腳本產生器使測試資料實體化成為測試案例，這裡使用 JUnit。 2. Related Technology Research 2.1 - 2.7 為使用的工具與技術介紹，2.8 介紹了相關的研究。 2.1 Unified Modeling Language(UML) 關於 UML 這裡有介紹，這裡不再贅述。 2.2 Object constraint language(OCL) OCL 可以更嚴謹的描述 UML 中有關系統規格的所有資訊，是 UML 的擴展。OCL 使用三種限制式(Constraint)描述類別行為: Class invariant 此類別在整個生命週期中都應該滿足的條件 Method pre-condition Method 執行前應該滿足的條件 Method post-condition Method 執行後應該滿足的條件 2.5 Test quality assessment 這裡使用 Mutation testing 來評估測試案例的品質，Mutation testing 是一種測試案例的品質評估方法， 將待測程式改變幾個 Operation 來測試 Test case 能否找出這些改變。 延伸閱讀: Paper An Analysis and Survey of the Development of Mutation Testing. 2.3 Constraint Logic Programming(CLP), 2.4 Coverage Criteria, 2.6 JUnit, 2.7 GraphViz 介紹請參考原論文 2.8 Related research 2.8.1 Test Case Generation Based on UML/OCL 在 [17] 他們擴大了HOL 為基底的測試框架，[HOL-TestGen] [20]，可以支援 UML/OCL 的規格。他們其中一個主要的貢獻， 是擴充以規格為基底的測試案例產生器推向物件導向的規格。 [17] A . D. Brucker, P. K. Matthias, L. Delphine, W. Burkhart, “A Specification-Based Test Case Generation Method for UML/OCL,” Models in Software Engineering, vol. 6627, pp. 334-348, 2011. [20] A . D. Brucker, W.Burkhart, “Interactive Testing with HOL-TestGen,” in Proceedings of the 5th International Conference on Formal Approaches to Software Testing, 2006. 在 [18]中，他們展示了TOTEM(Testing Object-orienTed systEms with the unified Modeling language)，一個實用的測試方法。測試需求從早期的開發文件中取得， 如用例圖(use case diagram)、用例說明(use case description)、與每個用例與類別相關的交互關係圖(interaction diagram)， 他們在活動圖(activity diagram)中捕捉在用例之間的連續關係，因此允許用例序列的規格被測試。 [18] L . Briand, L. Yvan, “A UML-Based Approach to System Testing,” in Proceedings of the 4th International Conference on The Unified Modeling Language, Modeling Languages, Concepts, and Tools, 2001. 在 [19]中提出屬性為基底的測試(property-based testing)，結合了軟體模型(UML) 與限制屬性(OCL) 來討論，他們斷定了系統元件的兩種不同的屬性， 例如無狀態與狀態相關，可以產生完整屬性為基底的測試套件，產生的測試套件可以表達成 QuickCheck[21] 的形式。 [19] M . A. Francisco, M. C. Laura, “Automatic Generation of Test Models and Properties form UML Models with OCL Constraints,” in Proceedings of the ACM 12th Workshop on OCL and Textual Modeling, 2012. 2.8.2 Test Case Generation Based on Constraint [22] 是將基於限制式的研究用在測試上的先驅，他們提出了透過基於限制式測試，自動產生測試輸入用在基於錯誤的測試(fault-based testing)。 [22] R . A. DeMillo and A. J. Offutt, “Constraint-Based Automatic Test Data Generation,” IEEE Transcations on Software Engineering, vol. 17, no. 9, pp. 900-910, 1991. [23] 提出了第一個從C 程式轉換成靜態單賦值形式(static single assignment form)，使所有變數都只會被賦予最多一次的值， 接著可以透過這個方法有系統地取得控制流程圖中每一條不同執行路徑的限制式，進行符號執行(symbolic execution)。最後， 透過限制找解器(constraint solvers) 自動的產生所有可實行路徑的測試輸入。 [23] A . Gotlieb, B. Botella and M. Rueher, “Automatic Test Data Generation Using Constraint Solving Techniques,” in Proceedings of the 1998 ACM Symposium on Software Testing and Analysis, 1998. [24] 使用符號執行來收集在Ada 程式中不同路徑的限制式。他使用限制邏輯程式(constraint logic programming) 來自動的產生針對所有可實行路徑的測試輸入。 [24] C . Meudec, “ATGen : Automatic Test Data Generation Constraint Logic Programming and Symbolic Execution,” Journal of Software Testing, Verification and Reliability, vol. 11, no. 2, pp. 81-96, May, 2011. [25] 提出了可以從VDM的規格中自動產生測試案例，他們將待測程式的 VDM 規格中的符號轉換成一階邏輯演算(first-order logiccalculus) 的析取範式(disjunctive normal form)。 每一個合取(conjunctive) 的演算都是等價類(equivalence class)，而他們也有考慮關於產生一系列函式呼叫時要讓整個程式處在一個適當的系統環境中做測試。 [25] J . Dick and A. Faivre, “Automating The Generation and Sequencing of Test Cases from Model-Based Specifications,” in Proceedings of the 1st International Symposium on Formal Methods Eurpoe, 1993. 3. Constraint Logic Graph Generator 這裡介紹如何將 Method 的 OCL 轉為 CLG，架構圖如下: 主要流程如下: 使用 DresdenOCL Parse OCL 轉為抽象語法樹(AST) AST 經過 Preprocessing(AST 重構器) 依照不同的 Coverage criteria 來產生測試案例 3.1 OCL Syntactic analysis OCL 有三種限制式(invariant, pre, post) 這樣每種情境就要建立一個 Abstract syntax tree(AST)， 這裡會透過 Dresden OCL 來分析 OCL，其中每一個 Operator 都會產生一個 Subtree。 3.1.1 Structure of Abstract syntax tree AST 的每一個 Node 都代表一個 OCL 的運算式，以下是作者所設計的 Node: IfExp 的抽象語法樹如圖，根節點為IfExp conditionExp：ASTNode 第一個子樹，為condition 的運算式 thenExp：ASTNode 第二個子樹，為then 的運算式 elseExp：ASTNode 第三個子樹，為else 的運算式 這裡只舉 IfExp 為例子，全部的 Node 請參考論文 3.1.2 Example Triangle 以下是一個 Triangle 的例子，這裡有三個限制式(pre, post, post)要傳換成 AST: package tcgen context Triangle::Triangle(sa : Integer, sb : Integer, sc : Integer): OclVoid pre EdgeErrorException: sa + sb &gt; sc and sb + sc &gt; sa and sa + sc &gt; sb and sa &gt; 0 and sb &gt; 0 and sc &gt; 0 post: sideA = sa and sideB = sb and sideC = sc context Triangle::category() : String post: result =if sideA@pre = sideB@pre then if sideB@pre = sideC@pre then 'Equilateral' else 'Isosceles' endif else if sideA@pre = sideC@pre then 'Isosceles' else if sideB@pre=sideC@pre then 'Isosceles' else 'Scalene' endif endif endif 上圖是 Triangle 的 Post 被轉化為 AST 的結果，其他的轉換可以參考論文 NOTE Last edit 11-2-2023 16:36"
  },"/jekyll/2023-09-07-Introduction_OCL.html": {
    "title": "Note | Object Constraint Language Concepts (Unfinished)",
    "keywords": "software tool Jekyll",
    "url": "/jekyll/2023-09-07-Introduction_OCL.html",
    "body": "Object Constraint Language(OCL) 物件限制語言。 1. Introduction 因 UML 類別圖中無法包含一些細節資訊，若以自然語言描述，常造成開發者與使用者間認知差異，所以使用物件限制語言嚴謹的描述 UML 類別圖中有關系統規格的所有資訊，為 UML 標準的擴充機制。 物件限制語言使用三種限制式(constraint)來描述類別的行為: 類別恆定條件(Class invariant) 針對一個類別而言，此類別的任何物件在整個生命週期皆須滿足自身定義的恆定條件。 函式前置條件(Method pre-condition) 針對一個函式而言，在此函式被呼叫之前須滿足前置條件，才能確保動作正確。 函式後置條件(Method post-condition) 針對一個函式而言，若在此函式被呼叫之前滿足前置條件，則此函式在被呼叫後，一定滿足後置條件。 2. Characteristic 物件限制語言由 IBM 於 1997 年開發，他扮演以下角色: NOTE Last edit 09-07-2023 09:25"
  },"/jekyll/2023-08-06-gdb_introduction.html": {
    "title": "Note | GNU Debugger Quick Notes",
    "keywords": "software tool Jekyll",
    "url": "/jekyll/2023-08-06-gdb_introduction.html",
    "body": "記錄如何使用 GDB 進行開發與除錯，以前都是用直覺、測試的方式來進行除錯，也很少用 debug mode 不是一件好事也很沒效率， 藉此建立 Debug 的好習慣。「實際上在我職涯中 95% 的 Bug 都能透過 debug mode 解掉」－PTT鄉民 Reference: GDB: The GNU Project Debugger, GDB User Manual jasonblog: 通過 GDB 學習 C 語言 Jserv: 你所不知道的 C 語言: 開發工具和規格標準 1. GNU Debugger(GDB) Introduction GDB 是 GUN 系統下的標準除錯工具，使我們能查看程式在運行中內部發生了什麼，或是崩潰時正在做什麼。 此外 GDB 經過移攜需求的調修與重新編譯，現在許多的 UNIX Like 系統上都可以使用 GDB。 GDB 最主要的四項功能有: Start your program, specifying anything that might affect its behavior. Make your program stop on specified conditions. Examine what has happened, when your program has stopped. Change things in your program, so you can experiment with correcting the effects of one bug and go on to learn about another. GDB 目前所能支援的語言: Ada Assembly C C++ D Fortran Go Objective-C OpenCL Modula-2 Pascal Rust 2. Using GDB to development 2.1 Debuging Program 2.2 Setting Breakpoints 2.3 Check status 「一旦你已經習慣於在 REPL 環境下進行探索性的編程，必須進行「編寫-編譯-運行」這樣循環實在有點令人生厭。」—jasonblog: 通過 GDB 學習 C 語言 REPL(Read-Eval-Print Loop) 環境可以讓我們方便的了解當下在做什麼，如果透過類似 REPL 的方式來進行對需要編譯後運行的程式進行開發、 追蹤代碼、除錯都非常有幫助。 2.1 Debuging Program 使用 GDB 就需要 debugging information 給 GDB 使用，這裡 gcc 要帶入參數 -g，gcc Option for Debugging， 然後就可以啟動 gdb 進行 debug，之後輸入 run 指令就可以運行程式。如果程式需要帶入參數的話， 就直接在 run 後面加入參數就好。 -g Produce debugging information in the operating system’s native format (stabs, COFF, XCOFF, or DWARF). GDB can work with this debugging information. gcc -g main.c -o main gdb main # Reading symbols from main... (gdb) run # Program output. (gdb) run ${argv} # Program output. 如果想對已經運行中的程式進行 Debug 就要使用 attach，並且要知道該 Process pid， 但注意對運行中的程式進行 Debug 有可能干擾正在運行的程式，有更多的細節可以查看 Debugging an Already-running Process。 ps -ef | grep ${program_name} gbd ${pid} 2.2 Setting Breakpoints 使用 info breakpoints 可以查看已經設置的中斷點，與中斷點的 Type, Address, What。中斷點有多種形式， 這裡主要講幾種常用的中斷點，更多內容可以看 Setting Breakpoints: Breakpoint and Continue 使用 break 或 b 設置，可以設置在目標的行數或是函數名稱， 當然如果遇到斷點後想要繼續程式，使用 continue 就可以了: # set breakpoint at line 23 (gdb) break main.c:23 # set breakpoint at function main (gdb) break main Breakpoint with condition 也可以設定當條件出現時才會中斷，例如懷疑是程式中出現非期望的值，就可以在這裡設置斷點觀察。並且也可以透過 condition 修改斷點的條件。 (gdb) break test.c:23 if b==0 # if this break point number is 1, change condition. (gdb) condition 1 b==1 Breakpoint with rule 依照規則來設定斷點，例如函數名稱，檔案，等等… # break all function (gdb) rbreak . # break all prefix is printNum* function (gdb) rbreak printNum* # break all function in test.c (gdb) rbreak test.c:. # break all function in test and prefix is print (gdb) rbreak test.c:^print Skip breakpoints multiple times 我們也可以設置跳過某的斷點幾次，例如一個函數前 10 次都沒出現問題要跳過前 30 次的中段，之後可以透過 info breakpoints 看到設置。 (gbd) ignore 1 30 Watchpoint 觀察點是設置當某個變數或類型產生變化時進行觀察，有 wathc, rwatch, awatch， # break if a changes (gbd) watch a # break when a is read (gbd) rwatch a # break when a is write (gbd) awatch a Clean and disable/enable breakpoint Disable/Enable # disable all point (gbd) disable (gbd) disable ${break_num} # enable all point (gbd) enable (gbd) enable ${break_num} (gbd) enable delete ${break_num} Clear/Delete # clean all point clear clear ${function_name} clear ${file_name}:${function_name} clear ${line} clear ${file_name}:${line} # delete all point delete delete ${break_num} 2.3 Check status 在 GDB 中有多種查看變數、記憶體區塊、記憶體內容的方法，這裡我們可以使用 print 印出變數的內容。 (gdb) print 1 + 1 # $1 = 2 # $1 is a temp variable, only live in this debug session. 例如如果有以下程式，然後去設置中斷點觀察變數。 int main() { int x = 10; return 0; } (gdb) break main (gdb) run (gdb) print x # $1 = 0 (gdb) next (gdb) print x # $2 = 10 (gdb) set x = 20 (gdb) print x # $3 = 20 查看變數在記憶體的地址，區塊大小，記憶體內容，在 GDB 中一個數字的低位元在前高位元在後，所以要從左往右讀， x 是從一個位置開始讀取 Memory，4b 代表 4 byte。 (gdb) print &amp;x # $4 = (int *) 0x7fffffffe37c (gdb) print sizeof(x) # $5 = 4 (gdb) print sizeof(double) # $6 = 8 查看記憶體的內容，格式為 x/[n][f][u] addr，其中 n 為顯示的單元數，f 是要顯示的格式，u 是單元長度。 (gdb) x/4xb &amp;x # 0x7fffffffe37c: 0x6f 0x00 0x00 0x00 (gdb) set x = 0x12345678 (gdb) x/4xb &amp;x # 0x7fffffffe37c: 0x78 0x56 0x34 0x12 (gdb) x/4tb &amp;x # 0x7fffffffe37c: 01111000 01010110 00110100 00010010 可以用 ptype 來檢查給定變數或類型的詳細類型定義。 (gdb) ptype x # type = int (gdb) ptype &amp;x # type = int * (gdb) ptype main # type = int (void) Note 以上大概就是常會用到的主要指令，還有更多細節可以看 GDB 手冊，GDB User Manual。"
  },"/jekyll/2023-08-05-linux_kernel_complie.html": {
    "title": "OS | Linux Kernel Compilation",
    "keywords": "OS linux Jekyll",
    "url": "/jekyll/2023-08-05-linux_kernel_complie.html",
    "body": "記錄一下如何編譯與更換 Linux kernel 版本，以用來進行開發測試 Linux kernel module。 Reference: Jserv: Linux 核心模組運作原理, 鳥哥私房菜: Linux 核心編譯與管理 如果想要開發 Linux kernel module，就可能會碰到要更新 Kernel 的情況，這裡紀錄一下如何進行 Kernel 的編譯與安裝。 1.取得 Source Code 有以下三種方法可以使用: 使用 Distribution 提供的核心原始碼檔案。 取得 www.kernel.org 上所提供的核心原始碼。 保留原本設定：利用 Patch 升級核心原始碼。 其中使用 Patch 的話需要將間隔中的每個 patch 都進行 patch，想要由 3.10.85 升級到 3.10.89 的話， 那麼就得要下載 patch-3.10.86, patch-3.10.87, patch-3.10.88, patch-3.10.89 等檔案。 這裡使用 www.kernel.org 所提供的原始碼，其中: mainline: 最新的、積極開發的版本，因此有較高的變化與更新頻率。 stable: 穩定版本，這些版本會包含 Mainline 的一些修復和改進，但不是全部都會收入。 longterm: 長期支持的版本，可以在生產環境內長時間穩定運行。 下載後解壓縮放置，這裡選擇放在 /usr/src: tar -Jxvf ${linux_kernel} -C /usr/src/ 2.前處理與配置核心功能 開始配置前先記得刪除檔案中可能有的 Object file(.o) 和 Config，mrproper 會清除過去曾經配置的核心配置文件。 cd /usr/src/${linux_kernel} make mrproper make clean 詳細配置與說明看 鳥哥私房菜: Linux 核心編譯與管理，這裡直接複製原來的 Kernel config，這個 .config 就是核心的配置檔案。 也可以使用 make menuconfig 來進入文字圖形介面來進行配置，但是我們這裡使用原本的 Kernel config。 cp /boot/config-${old_linux_kernel} /usr/src/${linux_kernel} 3.編譯核心檔案 這裡使用多核心數去進行編譯，因為編譯 Kernel 是一個很長時間的工作，這幾個核心可以同時進行編譯的行為，這樣在編譯時速度會比較快。 最後製作出來的資料是被放置在 /usr/src/${linux_kernel} 這個目錄下，之後才會進行安裝。 make -j ${core_number} clean bzImage modules bzImage: 編譯核心 modules: 編譯模組 Tip: 在這一步我遇到幾次編譯錯誤，要回頭去修改 .config 等設定。記錄一下最後的解決方法: 主要是一些系統簽章檢查需要解決，參考中有正確配置的方法，還有編譯時的依賴項沒有安裝，遇到就安裝就好。 4.實際安裝核心 4.1 安裝模組與核心 首先安裝 modules，會放置在 /lib/modules/$(uname -r) 目錄下，直接使用以下指令就好: make modules_install # check modules ll /lib/modules/ 核心則會放置在 /boot 下，並且檔名為 vmlinuz 開頭，這裡可以去看 vmlinuz 的歷史。這裡鳥哥有講如何配置多個內核模塊， 下面是不進行配置多模塊直接安裝的方法: cp arch/x86/boot/bzImage /boot/vmlinuz-${linux_kernel_version} chmod a+x /boot/vmlinuz-${linux_kernel_version} # Backup config file cp .config /boot/config-${linux_kernel_version} cp System.map /boot/System.map-${linux_kernel_version} gzip -c Module.symvers &gt; /boot/symvers-${linux_kernel_version} restorecon -Rv /boot 4.2 編輯開機選單 (grub) grub2-mkconfig 是用來生成 grub 文件的，因為預設較新版本的 Kernel 會放在最前面作為預設的開機選單項目， 所以這裡應該會看到剛剛安裝的核心放在第一位出現才對，否則等等可能會用舊核心開機。 # CentOS grub2-mkconfig -o /boot/grub2/grub.cfg # Ubuntu sudo update-grub # Generating grub configuration file ... # Found linux image: /boot/vmlinuz-${linux_kernel_version} # Found initrd image: /boot/initramfs-${linux_kernel_version} 最後就是重新開機然後查看 Kernel 是否有成功更新，可以使用 uname -a 或 uname -r。 Note Last edit 08-05-2023 22:20，如果使用 VM 編譯前多開核心給機器，我是單核心編譯花了大約三小時。"
  },"/jekyll/2023-07-28-UML_structure_diagrams.html": {
    "title": "Note | UML Structure Diagrams Introduction",
    "keywords": "software software_development Jekyll",
    "url": "/jekyll/2023-07-28-UML_structure_diagrams.html",
    "body": "本篇主要介紹 UML 的分類中的結構圖(Structure Diagrams) 1. Structure diagrams 1.1 Class diagram 1.2 Component diagram 1.3 Deployment diagram 1.4 Object diagram 1.5 Package diagram 1.6 Composite structure diagram 1.1 Class Diagram Class diagrams(類圖)是使用最廣泛的 UML 圖，他是所有 Object-Oriented Software Systems 的基礎。 透過顯示系統的 Class(類)、Mthods(方法)、Properties(屬性)來描述系統的靜態結構。 從下圖我們可以看出: Abstract Class: 看到 Shape 是一個 Abstract Class 他以斜體顯示。 Class diagram relationships: Generalization: 空心箭頭，同時 Shape 也是一個 Superclass，Circle、Rectangle、 Polygon 都是由 Shape 所衍生，也就是說 Circle 是一個 Shape，這是一種 generalization(一般化)/inheritance(繼承) 的關係。 Association: Class 間的連線，DialogBox 和 DataController 之間有一個關聯。 Aggregation: 空心菱形箭頭，Shape 和 Window 是一種聚合關係，Shape 可以存在而不依賴 Windows。 Composition: 實心菱形箭頭，Point 是 Circle 是一種組合關係，沒有 Circle 就不能存在 Point。 Dependency: 空心箭頭，Window 依賴於 Event，但 Event 不依賴於 Window。 Attributes: Circle 的屬性是 radius、center 後面是他的型別，這是一個 Entity class。 Methods: Circle 的方法是 area()、circum()、setCenter()、setRadius()。 Parameter: Circle 中的 area(in radius: flot) 代表參數是一個名為 radius 型別為 float 的傳入參數。 Return: Circle 中的 area(): double，代表返回一個 double 的值。 Hidden: Rectangle 的 Attributes，Mehtods 是隱藏的，圖中的其他一些 Class 也隱藏了他們的 Attributes，Mehtods。 1.2 Component diagram Component diagram(元件圖)描述一個軟體系統時，將軟體系統裡的元素給予模組化(Modularity)，即成為一個元件。將元件與元件間的關係做描述時， 對於軟體系統的運作可以比描述類別關係更加得清楚。 Component 通常比 Class 有更高的抽象層級，可能由一個或多個 Class 組成，可能是包、可執行檔案、資料庫等。 每個元件通常封裝特定的功能並公開一個明確定義的介面，元件與類最大的差別在於元件強調的是介面的溝通。 下圖是一個 Composite Component，也就是元件中包含著元件=的範例，Composite Commponent 中的主要元素有: Component(元件): 以一個長方形所顯示，右上角繪製一個 1.x UML 版本的元件圖(非必須)。 Provided interface(提供接口): 以一個圓形顯示，代表為提供給 Client 端所使用的接口。 Request interface(所需接口): 以一個半圓顯示，代表元件所需求的介面。 Port(端口): 以一個正方形表示，以表示元件公開的端口。 Relationship: Dependency: 空心箭頭，表示一個元件依賴其他元件或接口才能實現。 1.3 Deployment diagram Deployment diagram(部屬圖)是顯示運行時處理節點的配置，用於物件導向系統的物理方面進行建模， 通常用於對系統的靜態部署視圖(硬件拓撲)進行建模。 拓撲(Topology): 在系統架構中用於描述不同組件或模塊之間的關係和連接方式。 與 Component diagram(元見圖)的不同點在於，部屬圖主要用於展示一個系統或軟體是如何被部署在不同的硬體和運行環境中， 他著重於系統的物理組成、硬體資源的配置、節點之間的通訊通道。 下圖是一個部署圖的範例，有這些主要元素: Node: 3D 矩形，代表一個節點，無論是硬體或是軟體。 可以使用 &lt;&lt;stereotype&gt;&gt; 來註明節點，以區分節點的類型。 Node 內可以包含另一個 Node。 Association: Node 間的連線。 可以使用空心箭頭來代表之間的依賴性。 TCP/IP Client / Server Example: 1.4 Object diagram Object Diagram(物件圖)用於展示系統或軟體在特定時間點內物件實例(Object instance)，還有物件彼此間的關聯。 它也被稱作記憶體的快照(memory snapshot)。 Object(物件): 物件是特定 Class 的實例，物件顯示的是實例與屬性。 通常物件圖用於開發的後期階段，用來展示特定時間點內的物件實例與相關的關係，有助於理解系統在特定時間內的狀態， 確保物件間的關係符合設計需求。 當 Class diagram 非常複雜時，Object diagram 對於解釋系統的細節部分很有用， 說明 Object diagram 的最佳方式是透過相應的 Class diagram 對照產生的 Object diagram。 下圖說明了一個大學系所的可以有很多其他的延伸系所，將 Class diagram 實例化後的 Object diagram: 一個訂單管理系統的 Class diagram 與其 Object diagram: Object diagram 主要的元素有以下這些: Object: 矩形方框，提供了 Object Name : Class，並以下劃線註記。 Anonymous Object: 匿名物件，僅使用 Method 而不建立實例的物件。 Object attributes: 與 Class 相似，但 Object attributes 必須分配具體的 Value。 Links: Object 之間的關聯，可以使用 Class diagram 相同的箭頭來表示關係。 1.5 Package diagram Package diagram(封裝圖)用於建模高層級系統元素，Package 用於組織包含圖表、文件和其他關鍵的大型系統。 When to use Package diagram? Package diagram 可以用來簡化複雜的 Class diagram，可以將 Class 分到 Package 中。 Package 是邏輯上相關的 UML 元素的集合。 Package 被描繪為文件夾，可以在任何 UML 中使用。 一個 Package diagram 具有以下元素，下圖是一個訂單子系統的範例: Subsystem: 註明了這個子系統的名稱。 Package: 一個矩形，右上角帶有選項卡。Package name 位於矩形內或選項卡上。 Concrete package: 具有實現功能的包，其中有具體的程式碼，可以被執行、編譯或部署。 Abstract package: 沒有實際的程式碼實現，通常是為了邏輯上的分類，用於組織和分類包。 Dependency on external package: 不在系統內部直接實現或編寫的依賴包。 Dependency: 代表 Package 之間的依賴關係。 Example: 如果一個類想要在一個不同的包中使用一個類，它就必須為該包提供一個依賴。 Generalization: 一個包可以包含多個子包，每個子包都可以包含一系列元素。 1.6 Composite structure diagram Composite structure diagram(組合結構圖)是 UML 2.0 中添加的新圖形，其中包含 Class, Port, Package。 組合結構圖的作用與 Class diagram 類似，但是允許更詳細的描述多個 Class 的內部結構並顯示他們之間的交互。 Note Last edit 08-01-2023 00:13, Reference"
  },"/jekyll/2023-07-28-UML_behavior_diagrams.html": {
    "title": "Note | UML Behavior Diagrams Introduction (Unfinished)",
    "keywords": "software software_development Jekyll",
    "url": "/jekyll/2023-07-28-UML_behavior_diagrams.html",
    "body": "本篇主要介紹 UML 的分類中的行為圖(Behavior Diagrams)，與其子集交互圖(Interaction diagrams)。以此為分賴再依照廣泛使用程度介紹。 1. Behavior diagrams 1.1 Activity diagram 1.2 Use case diagram 1.3 State diagram 1.1 Activity diagram Activity diagram(活動圖)是 UML 中第二被廣泛使用的圖形，用於描述系統的動態方面，活動圖本質上是流程圖的進階版本， 它對從一個活動到另一個活動的流程進行建模。 When to Use Activity diagram 通過檢查業務工作流程(Business workflows)來確定候選用例(Use case)。 確定 Use Case 的前置與後置條件(Context)。 對於 Use Case 之間/內部的 Workflows 建模。 對於 Object 的複雜操作流程進行建模。 使用不同層級的活動圖對複雜的活動建模。 下圖分別解釋一個基本的活動圖，與一個訂單流程的範例: Pre/Post-condition: Black circle: 代表該 Workflow 的開始(init node)。 Encircled black circle: 代表該 Workflow 的結束(final node)。 Stadia: 代表動作(actions)。 Diamonds: 代表決策(decisions)。 Bars: 代表並行(Concurrent)活動的開始(split) 或結束(join)。 1.2 Use case diagram Use case diagram(用例圖)是第四使用廣泛度的圖形，表示 Actor 與系統交互的最簡表示形式，展現了 Actor 和與他相關的 Use case 之間的關係。 下圖是一個基本的 Use case diagram，Use case diagram 主要由以下元素所組成: Actor: 與系統進行互動的各種參與者，可以是使用者或外部實體。 Use case: 系統如何反應外界請求的描述，描述了一個特定的操作或任務。 Associate: 以虛線連接 Actor 與 Use case，表示 Actor 與 Use case之間的互動。 include: 包含關係，使用該用例時一定會執行的相關用例。 extend: 擴展關係，使用該用例時不一定會執行的相關用例。 Boundary: 以一個方框定義 System boundary，並在最上方寫出系統名稱。 下面是一個汽車銷售系統的 Use case diagram，可以發現即使是一個汽車銷售系統的用例也不超過十個: 1.3 State diagram State diagram (狀態圖)與用例圖並列第四廣泛使用，顯示實體的不同狀態，狀態圖還可以顯示實體如何通過從一種狀態更改為另一種狀態來響應各種事件。 When to use State diagram? 用於描述系統的狀態轉換，系統在不同時間點處於不同的狀態，以及在特定條件下如何從一個狀態轉換為另一個。 用於建模具有多種狀態的實體，實體如何根據事件改變狀態，如物件的生命週期、狀態機、事件驅動的系統等。 下圖用來說明狀態圖的符號: Initial Pseudo State/Final State: 黑色圓點，開始/結束節點。 State: 圓角矩形，內部標有狀態名稱，是一個實體所處的一個具體狀態。 Transition: 以剪頭指向下一個狀態，在上方可以標明指定觸發轉換的條件或事件。 下圖是一個具有 Substate(子狀態)的加熱器狀態圖，有子狀態的情況也可稱作 Nested state(嵌套狀態)/Compound state(複合狀態)。 Substate 可以有自己的進入狀態、結束狀態、以及在子狀態之間的 Transition。 History States: 除非有特別說明，不然進入一個子狀態都是以初始狀態重新開始。有註明 History state 就代表進入子狀態是以之前活動的最後一個子狀態開始。 2. Interaction diagrams 2.1 Sequence diagram 2.2 Communication diagram 2.1 Sequence diagram Sequence diagram(時序圖)是第三被廣泛使用的圖形，描述物件在時間序列中的交叉作用。序列圖會描繪在此情境下有關的物件， 以及此物件和其他物件交換訊息的順序。 下圖解釋了一個酒店預約的時序圖，從一個窗口(window) 開始啟動。 一個時序圖應該要注意的點有這些: Object/Actors: 方框，物件/參與者。 Lifeline: 垂直線，代表一個物件的開始與結束。 Activation bar: 發送和接收訊息的開始與結束。 Messages: 水平箭頭，上方寫有被調用的 Mehtod 與 Parameter、Return。 Self Message: 呼叫同一個物件的方法，例如一些 Private method。 Solid arrowheads: 實心箭頭，代表同步(Synchronous)訊息，發送方必須等待訊息完成。 Open arrowheads: 空心箭頭，代表異步(Asynchronous)訊息，發送方無須等待訊息完成。 Dashed lines: 代表回覆，可以是實心(同步)/空心(異步)箭頭上方帶有回覆的 Method。 Lost/Find: 使用一個圓點作為結束/開始，收件人未知/已知，發見人已知/未知。 Creat: 指向一個物件創造一條生命線。 Delete: 終止一條生命線。 Combined Fragment(組合片段): 大方框，用來標記複雜互動。 opt: 相當於 if 當條件為 true 就執行，false 不執行。 alt: 相當於 if else，條件為 true 執行否則執行 else。 loop: 條件為 true 就重複執行，可以使用 loop(n) 指明執行次數。 ref：參考其他的 Squence diagram，用於簡化圖表。 par: 併行(parallel)執行的片段。 2.2 Communication diagram Communication diagram(通訊圖)與 Seqence diagram 一樣是顯示對象如何傳輸信息，他們在語意上是等價的，也就是呈現相同的資訊。 Communication diagram / Seqence diagram 之間可以互相轉換，最主要的差別是通訊圖以空間進行排列元素，序列圖以時間排列元素。 如何在兩種圖型之間轉換的範例: 下圖是一個酒店預約系統的通訊圖，它的主要元素有: Object: 方框，代表物件或實體。 Links: Object 之間的連線，代表通訊通道。 Message: 實心/空心箭頭，各自代表同步/異步通訊，方向代表送出端與接收端，並且訊息帶有編號。 Note Last edit 07-30-2023 13:42, Reference"
  },"/jekyll/2023-07-26-unified_modeling_language.html": {
    "title": "Note | Unified Modeling Language Concepts",
    "keywords": "software software_development Jekyll",
    "url": "/jekyll/2023-07-26-unified_modeling_language.html",
    "body": "Unified Modeling Language(UML) 統一塑模語言。 雖然敏捷開發中不再投入過多時間在靜態建模上，但是 UML 還是有其價值，尤其是在大型複雜系統的設計，或在開發團隊需要更深入的技術和設計細節時。 1. Intorduction UML 是為了大型軟體系統的結構與行為的架構、設計、和實現建立 通用的可視化建模語言。它提供了用於傳達設計決策和系統架構的通用語言和符號。 它包括許多類型的圖，例如 Case diagram、Class diagram、Sequence diagram。他也支援一些 Advanced concepts 像是 Stereotypes(型別標記)、 Profiles(設計資料集)、Constraints(約束條件)、Packages(包)，由此可以對軟體系統進行更精確的定製建模。UML 是為了幫助改善溝通、協作和軟體系統的整體品質。 1.1 History UML 由 OMG(Object Management Group) 負責管理，2005年被 ISO 發布為認可的 ISO 標準，之後該標準定期修訂涵蓋 UML 的最新修訂版。 目前最新的版本是 UML 2.5.1 在 2017 年發布。 1.2 Why use UML in software development? Standardization: 用於描述軟體系統的標準可視化語言。使不同的利益相關者更容易交流設計決策與理解系統架構。 Clarity: 通過提供清晰、簡潔的表示來幫助減少軟體系統的歧義，防止軟體開發過程中的誤解和錯誤。 Collaboration: 促進不同利益相關者(如開發人員、架構師和項目經理)的溝通和協作。確保每個人都朝相同的目標努力。 Effciency: 提供軟體系統的可視化表示，可用於儘早識別潛在問題和設計缺陷，從而簡化軟體開發過程。 Reusability: 用於記錄軟件系統和設計模式，可以在未來的項目中重複使用。在軟件開發過程中節省時間和資源。 1.3 Key Object-Oriented Concepts in UML UML 已經取代了傳統的 Object-oriented (OO) 分析方法。 An object is made up of data and methods that control it. The data represents the object’s current status. A class is a type of object that has a hierarchy that can be used to mimic real-world systems. The hierarchy is expressed by inheritance, and classes can be linked in a variety of ways depending on the needs. Object 是我們周圍存在的現實世界實體，UML 能表示像抽象、封裝、繼承和多型這樣的基本原則，能表示物件導向分析和設計中的所有概念。 因為 UML 圖表中僅表示物件導向的概念。在開始學習之前，充分理解物件導向概念非常重要。 2. UML Hierarchy 根據 UML 提出的層次結構如下圖，分為結構圖(Structure diagrams)與行為圖(Behavior diagrams): Structure diagrams: 用於描述系統的靜態特徵或結構，由於代表結構，所以它們更廣泛的用於紀錄軟體系統的軟體架構。 如 Component diagrams 代表了如何描述軟體系統被拆分為 Components 並顯示這些 Components 之間的 dependencies。 Behavior diagrams: 描述了系統的動態特徵和行為，由於說明系統行為，因此主要用來描述系統的功能。如 Activities diagrams 用來描述系統中組件的業務與逐步操作的活動。 Interaction diagrams(交互圖): Interaction diagrams 是行為圖的 subset，強調被塑模系統中事物之間的控制流程與資料流程(flow of control and data)。 如 Sequence diagram 顯示對象如何在彼此之間就一系列訊息進行通訊。 2.1 UML Survey* States Grady Booch, one of the most important developer of UML, stated that “For 80% of all software only 20% of UML is needed”. UML 一共有 14 張圖表，但在一個軟體開發中並不是每個 Diagram 都會被使用，下圖表示了使用該 Diagram 的廣泛程度: 之後會再另外兩篇以結構圖、行為圖分類，再以使用廣泛度來依序介紹。 Note Last edit 07-24-2023 2201, Reference: Unified Modeling Language (UML) Introduction"
  },"/jekyll/2023-07-22-property_based_testing_entropy_guided_backbox_REST_API-_fuzzer.html": {
    "title": "Paper | BenFuzz: A Property Based Testing and Entropy Guided Blackbox REST API Fuzzer",
    "keywords": "software software_qualitiy Jekyll",
    "url": "/jekyll/2023-07-22-property_based_testing_entropy_guided_backbox_REST_API-_fuzzer.html",
    "body": "Benjamin Chen, “BenFuzz: A Property Based Testing and Entropy Guided Blackbox REST API Fuzzer”, 2022. 陳睿瑜, 基於特性測試與資訊熵之黑箱 REST API 模糊測試, 2022. 1. Intorduction REST API 為大多數前端後端與伺服器溝通型態，REST API 有著相當大的使用群體但其安全性或品質， 還是需要經由軟體測試，但背後實作的方式各有不同，所以對於 REST API 有蠻多工具可以去做測試。 論文提出以 REST API 回應之訊息熵作為變異參考依據，以及 Schemathesis[17] 中提到的基於特性的測試方法做結合， 檢測出相關的弱點，讓黑箱測試有了具有方向性的變異策略，使其能有更好的測試覆蓋率與弱點偵測， 去找到規格上與實作出的服務內容不符合的點及伺服器對於請求的處理是否能正確處理，得以找到 500 伺服器崩潰或錯誤問題， 論文也提供完整的前後端讓測試者能操作網路頁面就能做測試，達到開箱即用，也將其容器化方便做成 CI/CD 測試的一環。 2. Background 2.1 REST API REST API（Representational State Transfer Application Programming Interface）是一種基於 HTTP 協定的設計風格， 用於設計和開發網路應用程式的接口，支援資源的狀態和操作的表達，促進了不同系統之間的資訊交換和通訊。 2.2 OPEN API and Swagger Swagger（現在稱為OpenAPI）是一種用於OpenAPI 是用於描述 API 資訊的文件，包括 API 的端點、參數、輸出入格式、說明、認證等， 本質上它是一個 Json 或 Yaml 文件，而文件內的 Schema 則是由 OpenAPI 定義。它允許開發人員、團隊和企業在設計、 開發和使用 API 時更加方便和有效地進行溝通、理解和測試。 openapi: 3.0.0 info: version: 1.0.0 title: Sample API description: A sample API to illustrate OpenAPI concepts paths: /list: get: description: Returns a list of stuff responses: '200': description: Successful response 以上 OpenAPI Yaml 描述了一個名為 “Sample API” 的 API，該 API 具有一個 /list 的路徑可使用 get 來獲取回應。 2.3 Fuzz Testing 模糊測試 (Fuzz Testing) 是基於產生隨機且非預期的輸入，進而觸發目標程式非預期錯誤的一種自動化軟體測試技術。 模糊測試在多個領域都有相應的實作項目，能夠有效地發現程式異常、邏輯錯誤、開發人員設計的瑕疵及非預期的記憶體錯誤， 進而提高程式可靠度及軟體品質。模糊測試目前分為三大類白箱、灰箱、黑箱，依是否能獲得原始碼來分類。 2.4 Property Based Testing 基於範例的測試(Example Based Testing)，基於範例的測試通常要人工寫出測試範例，這樣就會有局限性， 因為要人工產生的範例會受限於思考範例的盲區跟上限。 基於特性測試(Property Based Testing)，我們可以基於要測試的函式，對其特性或運作邏輯，去做特性測試。以下將舉例加法函式在傳統測試與 特性測試的差異性。 Example，假設測試一個加法函數: 傳統測試: 給定測資跟解答，才能驗證是否可行，如 1+1=2 為一個測試點。 特性測試: 用交換律 A+B=B+A、結合律(A+B)+C=A+(B+C)來做到邏輯上的驗證，這些特性是已知的數學性質， 如果函數是正確實現的，它們應該始終成立。測資的部分透過隨機產生，這樣不但測試資料更加多元， 也能減少降低人工產生測試資料的時間成本，從而使得測試資料更具多樣性和覆蓋性。 特性測試包含了三個架構: Arbitrary 亂數產生器 是一種亂數產生的策略，當我們指定資料型別時，我們可以定義符合這個資料型別的亂數產生方式 Generator 測試產生器 測試時依據亂數產生器產生出測試資料的值，這時候我們可以拿到值去帶入函數做測試 Shrinker 誤區識別器 當測試結果不符合預期的時候，我們可以透過他找到錯誤的邊界 2.4.1 Hypothesis Hypothesis[7] 是基於特性測試在 Python 上實作的函式庫，開發者可以設計自己的特性測試，其中提供了各類型的 隨機產生器(Strategies)，如 Int, Float, String，也可以由開發者能加入自己的隨機產生器， 也可以由 Hypothesis-jsonschema，將 jsonschema 轉換成隨機產生器，通過解析型別與內建的隨機產生器組織再一起。 [7] DRMacIver. “Hypothesis”. URL: https://github.com/HypothesisWorks/hypothesis 2.5 Entropy Entropy(資訊熵)，是用來計算資訊量的一個方法，可以根據其計算判斷出其資訊量或亂度的一個量衡，使開發者便於以其作為依據， 去判別一段文字或是位元組所代表的資訊量。 $Entropy (H(X)) = - \\sum_{x} P(x) \\log_{b} P(x)$ 如果有一個系統 S 內存在多個事件 S={E1,…,En}，每個事件的機率分布 P={p1, …, pn}，則每個事件本身的資訊本體為: $I_{e} = -\\log_{2}{p_{i}}$ (對數以2為底，單位是 bit) 如英語有 26 個字母，假如每個字母在文章中出現次數平均的話，每個字母的訊息量為: $I_{e}=-\\log_{2}{1 \\over 26}=4.7$ 以日文五十音平假名為相對範例，假設每個平假名在文章中出現的機率相等，每個平假名日語文字可攜帶的資訊量為: $I_{e}=-\\log_{2}{1 \\over 50}=5.64$ 每個平假名所能攜帶的資訊量比英文字母更大，因為它有更多的字符選擇。這也意味著相比於英文字母， 使用平假名需要更多的 bit 來表示，因為它的字符集更無序。 3. Methodology and Implementation 3.2 Entropy 這裡作者提出一個假設: 「當經過 API 處理後的資訊熵提升代表其背後處理運算是更加複雜的，所以說資訊熵在此假設下與實際覆蓋度是有正相關的。」 因此作者可以以此指標來進行評估當前變異的策略，以此提高程式的覆蓋度，讓模糊測器可以測試到更深成的程式邏輯， 進而提高找到弱點的所在或是觸發錯誤。 3.3 Property Based Testing 作者挑選了 表.3 的四條準則，因為這四條可以通過最少的運算去檢核出來，在不犧牲模糊測試效率的情況下去實作。 利用 Hypothesis 這個 Python 編寫的函式庫，在本篇論文中作為變異（Mutation）及模糊測試的主要架構，通過實時變更函式庫的設定值， 讓其依照資訊熵的變化調整參數或是去更新其種子。使用 表.3 的規範方式作為特性測試之邏輯條件，進而調整變異方式及偵測 API 的弱點。 3.4 Parallel Request Sending 這裡作者使用 Async 進行發送請求與處理回應，來增加同一時間段內發送測試請求的效率與進行的測試數量。 使用 Python Library Aiohttp，是基於 Async 發送請求機制的 Library。 每個請求的生成機制為: 使用 Hypothesis 測試產生器所產生出的測試實例，URL 要通過 yarl 進行 hex 編碼後符合 RFC3986[12]。 若該 API 需要 Token 授權，將其放入 OpenAPI 所指定的授權位置以及其授權格式(bearer、JWT 或其他)。 依照 OpenAPI 所定義的請求格式送出測試請求，透過 Async 方式接受回應與計算熵(Entropy)與後續的調整變異。 3.5 - 3.7 Technology 3.5, 3.6 主要講述作者建立一個前後端系統可用來進行對目標的測試, 可以在前端上傳 OpenAPI 規格與相關授權 Token 後進行測試。 3.7 則是 Docker image 建立實作，這裡不再贅述。 4. Results Evaluation 後續作者以 RQ1 - RQ3，分別去驗證 Entropy(資訊熵)與 Coverage(覆蓋率)之間的關係，常用服務的 API 測試， 以及非自行架設的 API 進行測試，詳細步驟可以見論文 Section 4。 Other Section Section 5 為相關研究, 6 為結論, 7 為未來發展這裡不再說明。 NOTE 這篇論文主要是針對使用 REST API 服務的框架進行測試，以找出框架中不符合 REST API 規範的回應，或會對伺服器產生 500 Status 的錯誤， 其中關於 Property Based Testing, Fuzz Testing 的部分可以作為參考。 Last edit 07-27 14:07"
  },"/jekyll/2023-07-19-MVVM_modeling_methodology_user_interface.html": {
    "title": "Paper | A MVVM Modeling Methodology for Information Systems User Interface Design",
    "keywords": "software web_development web_framework Jekyll",
    "url": "/jekyll/2023-07-19-MVVM_modeling_methodology_user_interface.html",
    "body": "Yuan-Kai Hou, “A MVVM Modeling Methodology for Information Systems User Interface Design”, 2019. 侯元凱, MVVM 模式資訊系統使用者介面塑模方法論, 2019. Lab meeting study: 2 Review frontend framework, Design pattern(MVC, …), UML, PAC, 3-5 Method, 6 Conclusion. Section 2. 文獻回顧的部分放到其他筆記中講，這裡主要看作者的研究方法與方式，提出了一個基於 PAC 模式所擴展的 Enhanced-PAC 模式， 可用來表達 MVVM 模式下的 Frontend Component 的邏輯運作與轉換關係。 1. Introduction 1.1 Research Background and Motivation 傳統網頁大部分都是依照 MPA(Multi-Page Application) 模式開發，這裡作者點出幾個傳統網頁的問題: 並沒有規定一定要將 View, Business logic, DB logic, 分開撰寫，只要方法之間能互相通訊、執行即可。 因此在一份專案中能看到多種語法參雜並且高度耦合(coupling)，導致程式的維護性降低。 傳統網頁中有以 MDA(Model-driven architecture) 配合 CASE Tool 生成代碼的開發方法， 但對於程式邏輯與訊息傳遞上沒有可供依循的參考文件(reference document)，因此在開發過程中難以維護或理解功能對應程式碼的區段。 Model Driven Architecture(MDA) 模型驅動開發: 一種軟設計方法(Software design approach)該方法強調要在軟體開發中的每個步驟均須建構出模型，且最好應表達為電腦可理解的正規模式(Formal Model)。 MDA 將重點放在正向工程(forward engineering)上，從抽象的、人工詳細的建模圖生成代碼。 1.2 Research Objective 使用 DSRM(Design Science Research Methodology) 研究方法，以 Angular2 為前端框架開發一個名為 「便當王系統」， 並提出MVVM 模式資訊系統使用者介面塑模方法論(MVVM Modeling Methodology for Information Systems User Interface)。主要方法有: 使用 MVVM 開發模式，開發前端系統架構。 因為 MDA 開發中只在程式文件中有方法名稱，但並沒有對程式邏輯進行詳細的塑模。因此撰寫可使用於 MVVM 模式的塑模文件， 以提升程式設計師開發與維護時對於功能面的了解。 用 Angular2, PHP, MySQL 進行設計系統。但主要討論的是前端 Angular2 的部分，後端不在研究範圍中。 這裡所說的 「便當王系統」 請參考: 吳仁和,物件導向系統分析與設計―結合 MDA 與 UML, 5thEdition, 台北市: 智勝文化, February 2017, ch5 2. Literature Review 文獻探討章節講述: SPA(Single Page Application) 單一頁面程式: 詳情可看 Vue, React, Angular2 進行了解，主要取代過往 MPA 需要多個 HTML 進行建置網頁，當跳轉頁面時需要再次發出 Request 取回整個 HTML 造成的問題。 Software architectural pattern 軟體開發架構: 可參考 Note | Architectural Patterns Compare MVP, MVC, MVVM UML(Unified Modeling Language) 統一塑模語言: 是由 OMG(Object Management Group, OMG) 物件管理組織歷經多年的版本演化擴充，提出的物件導向塑模工具。 PAC(Presentation–abstraction–control) 表示-抽象-控制模式: 一種 Software architectural pattern，是常見的介面(interface) 結構表達工具，將使用者介面分為多個子介面，每個子介面可視為一個物件。 並有 Net-PAC 等擴展成網狀結構使其能表達 Web-base 的系統。 Shuen-Jen Tsai, Modeling the User Interfaces:A Component-based Interface Research for Integrating the Net-PAC Model and UML, 2002. 3. Research Method 3.1 Design Science Research Methodology 這裡使用該研究方法論步驟來進行論文之研究，其內容為下: Peffers, K., Tuunanen, T., Rothenberger, M. A., and Chatterjee, S., A Design Science Research Methodology for Information Systems Research 3.2 Research Method and Step Angula2 是已經強制以 MVVM 進行開發，而對於程式邏輯未有明確的塑模文件規範。作者使用 UML 的溝通突來建構一份符合 Angular2 框架的系統分析與設計的開發文件。 確認問題與動機: 透過文獻研究來了解當前傳統網頁所存在的問題，以及 MDA 系統開發方法下對於程式邏輯的描述文件不足。 定義解決方法的目標: 解決研究背景中傳統網頁(非 SPA、MVVM)的程式無法將使用者介面、程式邏輯、資料庫邏輯等語法分開撰寫，與不易分割進行分工的問題。 MDA 系統開發方法為 PSM 轉換為傳統網頁程式碼的開發方式，未涉及程式邏輯的塑模與轉換，本研究將以 UML 對其程式邏輯塑模，並產出一份可與 MVVM 模式對應之 UML 文件。 設計與發展: 由於 Angular2 已經強制使用 MVVM 進行開發，因此這裡會以生產率(Productivity)、可攜性(Portability)、互通性(Interoperability)、耦合力(Coupling)作為此系統開發框架的績效指標。 在 MDA 中進行塑模的部分則使用 Enhanced-PAC 建構溝通圖塑模系統的程式邏輯，與資訊傳遞，並以維護與文件(Maintenance and Documentation )做為此塑模方法論的衡量指標。 展示: 「便當王系統」中有一個新增項目活動圖做為來源，分別找出 Model、View、ViewModel，以及對這三個部分以資料詞彙做更詳細的說明，並建立出代表系統介面結構的 Enhanced-PAC 模型， 再以 Enhanced-PAC 模型, View model 資料詞彙作為來源，建構 UML 溝通圖(Communication Diagram)，這樣「便當王系統」就能透過 UML 來使用 Angular2 框架進行開發。 評估: 使用 Angular2 完成 SPA 的「便當王系統」後就能使用生產率(Productivity)、可攜性(Portability)、互通性(Interoperability)、耦合力(Coupling)作為系統評估此四項指標的問題， 維護與文件(Maintenance and Documentation)則以 Enhanced-PAC 模型與溝通圖的塑模方法論來評估。 6. Conclusion 作者提出一個新的 Enhanced-PAC pattern 用於表達 MVVM 架構下 Forntend Model，並以此 Model 進行開發與評估， 是否達到以 Enhanced-PAC 使開發者可以依循的參考文件。 NOTE 剩下的部分為論文的 Section 4-5. 為 Enhanced-PAC 建立方法，與使用 Enhanced-PAC 建立 Communication Diagram 與程式碼對應。並使用作者提出的指標來進行評估。 Section 6. 為結論與未來發展。 Last edit 07-19-2023 19:07"
  },"/jekyll/2023-07-18-software_arch_pattern.html": {
    "title": "Note | Architectural Patterns Compare MVP, MVC, MVVM",
    "keywords": "software software_development Jekyll",
    "url": "/jekyll/2023-07-18-software_arch_pattern.html",
    "body": "Design pattern compare for MVP, MVC, MVMM. 這是三種最常用的軟體架構模式，從這篇來了解這三種架構的差異與比較。 這三種 Architectural Patterns 的目的都是為了將 Business logic(業務邏輯)與 View(視圖)實現代碼分離，使一個程式能有不同的表現形式。 Architectural Patterns vs Design Patterns Architectural Patterns 是一種通用可重複使用的解決方案，用於解決特定 context 中的軟體架構中的常見問題。架構模式是處理系統中的主要組件如何協同工作， 訊息(message) 與資料(data) 如何在系統中流動以及其他結構性的考量因素。架構模式使用一些組件類型，每種組件會由更小的模塊所組成。 Design Patterns 則是常見問題的推薦解決方案與實踐，關注於如何建構應用程式中的組件。 Example: MVC 是一種 Architectural Pattren 他將程式分為三個主要部分, Model, View, Controller, 這部分之間的資訊交換有嚴格的規則，以實現更好的代碼組織與可維護性。 Observer Pattern(觀察者模式) 是一種 Design Pattren，定義了對象之間的一對多依賴關係，以便當一個對象改變狀態時，所有依賴於他的對象都會收到通知。 Model View Controller(MVC) MVC 最早來源於一篇論文，該論文對於 Model-View-Controller 三個模塊以其他們之間的通訊都講述了一些設計細節。 Steve Burbeck, Ph.D., Applications Programming in Smalltalk-80 (TM): How to use Model-View-Controller (MVC), 1979. MVC 將程式分為三種組件，Model, Viewm Controller, 三者有各自的用途和職責: Model: Model = data + business logic 也就是說 Model 既負責了資料的儲存也負責處理開資料的邏輯，因此處理業務邏輯是 Model 的責任而不是 Controller。所以從資料來看， 還可以分為資料的獲取、儲存、資料結構，因此在設計時 Model 會再次細分為更多 layer 如業務邏輯、網路、存儲等… View: View 負責顯示 Model 的資料，並負責最終如何在用戶介面中顯示數據以及終端用戶之間交互。View 是以網格、表格、圖表等等類似可以顯示數據的可視化表現。 Controller: Controller 負責 Model-View 之間的橋樑，用於控制程式的流程。所以 Controller 負責接收來自用戶的輸入、驗證輸入數據，解析用戶輸入後並交由對應的 Model 去處理。 所以理論上 Controller 是很輕的。 MVC Diagram, Reference to here. MVC and its variants 其實我們能發現最初版本的 MVC View 還是依賴於 Model，實際上降低了 View 的可用性，那變種的 MVC 就將 View 與 Model 完全分開，那就可以提高 View 的可重複性， 因此就有以下這種 MVC: MVC variant Diagram. View 與 Model 就不要進行通訊了，所有的通訊都基於 Controller，Model 將結果告訴 Controller，再由 Controller 更新 View。這種變種最早是由 Apple.Inc 所提出， 很多 Web 框架也是基於這種變種 MVC 所設計，如 SpringMVC。 另外在設計時 Controller 去跟 Model 發出請求時通常會比較耗時，因此一般都是非同步(async) 通知 Controller。 Model View Presenter(MVP) MVP 最早的解說來自於，是針對 MVC 再改良出的 Pattern: Mike Potel, MVP: Model-View-Presenter The Taligent Programming Model for C++ and Java, 1996. 可以看出最早的 MVP 其實與我們現在所看到的 MVP 不太一樣，該 MVP 是從數據管理與用戶介面兩個方向的問題出發，將 Smalltalk 的 MVC 在分解而成， 多了幾個中間組件: Interactor: 定義 View 的交互事件，也就是將使用者的輸入轉為適當的操作。 Commands: 定義對 Model 數據的操作如，儲存或更新資料庫、呼叫 API、進行演算法運算等。 Selections: 定義為從 Model 中篩選資料，並準備好相關的查詢或過濾條件。 MVP Diagram, Reference to here. 因此我們從上圖來看，如果去忽略中間組件，會發現與 MVC variant 幾乎一樣，在論文中就提到。 Presenter 其實就是 Controller，只是為了與 MVC 區分開才稱作 Presenter。在這個 MVP 中三個組件各自的職責: Model: 儲存數據(與資料庫溝通、請求網路資源等)，負責處理業務邏輯。 View: 顯示資料，將使用者的輸入傳給 Presenter。 Persenter: 從 Model 中獲取資料，並決定 View 中顯示什麼。 可以發現其實與 MVC variant 中的依賴是一樣的，只是 MVP 之間要透過介面(interface) 來實現，Model, View, Persenter 各自有各自的 interface， 針對 interface coding，自然就會去 decoupling，提高可重複性，以及容易進行單元測試。 Model-View-ViewModel(MVVM) MVVM 最早由 John Gossman 在他的 Blog 上所發表: John Gossman, Introduction to Model/View/ViewModel pattern for building WPF apps, 2005. View-Model 就如字面所述View-Model = Model of View，也可以看作是 Abstraction of the View，簡單來說在 MVVM 中 View 不負責維護數據， View 負責與 View-Model 同步數據，View-Model 也用於管理 View 的狀態和操作模型的方法與命令， 因此 View-Model 中封裝了 View 的屬性(Property)與命令(Command)。 因此在 MVVM 中最重要的一個特性就是數據綁定(data binding)，通過綁定使兩者之間鬆耦合(Loose coupling)，這樣就不用在 View-Model 中去寫 Update， 這裡綁定有兩種類型: 單向綁定(View-Model -&gt; View): 當 View-Model 發生變化後，View 才會更新。 雙向綁定(View-Model &lt;-&gt; View): 當 View-Mode, View 中任何一方發生變化，另一方都會更新。 一般情況下，只需在 View 中顯示但無須編輯的數據使用單向綁定，反之。同時 View-Model 封裝的是 View 的屬性與命令， 因此綁定也分為 Property Binding, Command Binding。 要實現綁定通常使用 Publish–subscribe pattern，這部分通常各大框架中都有自己的實現，Vue、React 中都實現了數據綁定。 Conclusion MVP, MVVM 都是為了實現 View 與 Business logic 的分離問題，只是兩者使用不同的實現。MVP 透過 interface 實現，缺點就是要編寫大量的 interface， 而 MVVM 則透過 Bind，但就要依賴框架工具來開發。 Last edit 07-21-2023 11:33"
  },"/jekyll/2023-07-18-automated_gen_test_case_using_UML.html": {
    "title": "Paper | Automated-generating test case using UML statechart diagrams (Unfinished)",
    "keywords": "software software_qualitiy generate_test_case UML Jekyll",
    "url": "/jekyll/2023-07-18-automated_gen_test_case_using_UML.html",
    "body": "Supaporn Kansomkeat, Wanchai Rivepiboon, “Automated-generating test case using UML statechart diagrams”, SAICSIT ‘03: Proceedings of the 2003 annual research conference of the South African institute of computer scientists and information technologists on Enablement through technology, September 2003, Pages 296–300. 本篇論文提出一種測試用例產生器基於 UML 狀態圖自動產生 Testing Case 的方法。 作者將 UML 轉為一個中間圖，稱作 TFG(Testing Flow Graph)，TFG 會明確識別 UML 狀態圖的流程，並針對測試的目的來進行增強。 從 TGF 中使用測試標準(Testing Criteria)來生成測試用例，包括覆蓋了 UML 圖中的狀態(State) 與轉換(Transition)。 最後使用突變分析(Mutation Analysis)來評估生成測試用例的錯誤揭示能力。 1. Introduction Specification-based testing(基於規格的測試) 是從規格中獲取的信息來幫助測試和開發軟體。測試活動包含: 設計測試用例(Testing Case)，這些測試用例是一系列的輸入。 執行測試用例和檢查執行結果 測試在開發過程的早期進行，開發人員通常會在規格中找到不一致和模糊之處，進而改進規格，然後再進行程式編寫。 Unified Modeling Language, UML(統一建模語言) BOOCH, G., RUMBAUGH, J., AND JACOBSON, I. 1998. The Unified Modeling Language User Guide. Object Technology Series. Addison Weysley Longman, Inc 是一種可視覺化建模語言，包含九種圖形。目前有許多研究專注於從 UML 規格中生成測試用例，詳細可見論文中 Reference，本論文提出一種從 UML 狀態圖中自動生成的測試用例。 NOTE Last edit 07-19-2023 23:02"
  },"/jekyll/2023-06-23-Intergrated_environment_sdd.html": {
    "title": "Paper | An Integrated Environment for Specification Driven Development (Unfinished)",
    "keywords": "software software_qualitiy software_development Jekyll",
    "url": "/jekyll/2023-06-23-Intergrated_environment_sdd.html",
    "body": "CHANG CHUNG-YEN, “An Integrated Environment for Specification Driven Development”, 2022. 張崇彥, 一個支援規格驅動開發的整合環境, 2022. 透過本論文了解一個整合 Junit, XML Model, Testing case, 的規格驅動開發環境架構。 本論文結合黑箱測試案例自動產生及測試驅動開發流程，提出規格驅動開發流程。在 Eclipse 上結合 XML 模型工具 Papyrus、OCL 處理器、 黑箱測試案例產生工具 CBTCG、JUnit，開發一個支援規格驅動開發的整合環境 CBSDD。 這個整合環境以專案的形式，完整支援軟體規格的制定，根據軟體規格自動產生測試案例，並透過自動執行測試案例，來驅動程式的實作與重構。 1. Intorduction 1.1 Motivation TDD 先編寫測試案例來進行規範，從未能夠通過測試案例的紅燈狀態開始進行程式開發，直到程式能夠通過測試的驗證達到綠燈狀態， 再經由重構。這些 TDD 所提倡的優點可見 TDD Concepts. 其中公認的優點為： 程式上開發與實施所得到的功能間都存在差距，TDD 由小而快的迭代不斷將實施的功能回饋給開發者而縮小了差距。 強調自動的單元化測試，自動測試提供可靠的系統，增強測試品質並且降低測試成本。 TDD 創建了一個完整的回歸測試平台。運行這些自動化測試案例，可以輕鬆確定更改是否破壞了系統中的任何內容。 即使測試驅動開發帶來諸多好處，但 TDD 在開發設計上的層面依然有可以改進的地方。因此提出了 BDD、SDD、APDD 等方法來讓使用者可以建立可執行的規範來進行測試。 過去團隊開發 Test Case Generation System[2] 使使用者能以規格文件來得到 Testing case 但當時需要使用者透過一個文件選擇器來選擇對應的輸入文件， 這樣的方式繁瑣且 Specification file, Output file 的關聯性也不明確。 [2] C.-L. Wang and N.-W. Lin, “, “Supporting Java Array Data Typein ConstraintBased Test Case Generation for Black-Box Method-Level Unit Testing,” in International Computer Symposium , 2018. 因此本論文提出一種透過 Eclipse 插件建立的 SDD 整合環境，來提升使用者的操作體驗。 1.2 Method 本專案設計了一個基於 Eclipse 的整合環境, 並設計出一套專案架構來管理規格文件與產生測試案例, 對於架構的詳情見論文 P3 這裡不詳細敘述，並且開發了兩個 Wizard 來幫助使用者建立專案。 Wizard: In Eclipse, a wizard is commonly used for the creation of new elements, imports or exports. fig 3. 規格驅動開發專案檔案目錄 在規格文件(Specification file)上需要 User 提供一個描述類別圖與精簡狀態圖的 UML 和 OCL file，使用 Eclipse 的 Papyrus 來繪製類別圖與精簡狀態圖， 並使用一個基於 Xtext 所製作的 OCL 編輯器來編輯 OCL。Testing Case 是經由團隊開發的 OCL 語法經由 Antlr 來產生，所以才需要製作一個 OCL 編輯器來進行高亮、語法檢查等功能， 讓使用者能確保語法正確並可以讓 OCL 分析器來進行分析。 fig 17. 規格驅動開發整合環境，其中 CBTCG 是團隊所開發的測試案例產生器。 NOTE Last edit 07-18-2023 12:32 我目前對 Eclipse 與相關環境開發研究到這裡就好，更有興趣的是 OCL 所產生的測試案例，這篇日後再回來讀。"
  },"/jekyll/2023-05-28-characteristics_of_bdd.html": {
    "title": "Paper | A Study of the Characteristics of Behaviour Driven Development",
    "keywords": "software software_qualitiy software_development Jekyll",
    "url": "/jekyll/2023-05-28-characteristics_of_bdd.html",
    "body": "C. Solis and X. Wang, “A study of the characteristics of behaviour driven development”, Software Engineering and Advanced Applications (SEAA) 2011 37th EUROMICRO Conference on, pp. 383-387, 2011. 本論文詳細定義了 BDD 相關文獻與工具而確定的 BDD 特徵，為理解和擴展 BDD 工具包或開發新工具提供了基礎。 Section 2 回顧現有 BDD 研究，3 採用的研究方法，4 介紹了確定的 BDD 概念模型，5 為總結。 1. Intorduction BDD 最初是由 Dan Northp[3]作為對 TDD 中存在的問題的回應而開發的。 [3] D. North, Introducing BDD, 2006. Available at: http://dannorth.net/introducing-bdd [Accessed December 13, 2010]. TDD 的介紹看這裡，Acceptance Test Driven Development (ATDD)(驗收測試驅動開發)[1][2]是 TDD 的一種種類，其中開發過程由代表利益相關者需求的驗收測試驅動。 驗收測試的通常是非開發者也能閱讀的文件，也可以是可執行的自動化測試，以確保利益相關者可以閱讀與理解，做為開發中的驗收標準。 利益相關者: 例如項目負責人、用戶、業務代表等。 但許多開發者在使用 TDD 和 ATDD 時會開始困惑，“程式設計師想知道從哪裡開始，應該測試什麼以內以及不應該測試什麼，一次測試多少，如何命名以測試，以及如何理解測試失敗的原因”[3]， TDD 和 ATDD 也存在一些問題，如他們專注的是系統的狀態而不是系統的期望行為，而且測試代碼與實際系統的實現高度耦合[18][20]。並且這些方法中非結構化且無限制的自然語言描述測試案例， 使它們很難被理解[3]。 BDD 被視為上面兩種方法的演進，BDD 的重點是可以自動化的方式定義目標系統行為的 fine-grained specifications(細粒度規範)， BDD 的主要目標是獲得系統的可執行 specification(規範)[3][20]。因此 BDD 中測試寫得很清楚與易理解，BDD 提供一種特定的共通語言， 有助於利益相關者指定其測試。還有各種支持 BDD 的工具如 JBehave [4]、Cucumber [5]和RSpec [6]。 Specification: 在 BDD 中指的是一種以人類可讀的方式表達系統行為期望的描述，用於指導軟件開發和測試。 2. RELATED WORK Carvalho等人[8][9]認為 BDD 是一種規範技術，“通過將這些需求的文本描述與自動化測試相連接，自動確認所有功能需求在源代碼中得到適當處理”。 他們主要關注於 BDD 中形成一種簡單共通語言，使用預先標記的集合來描述需求和測試，使需求轉化為可執行的測試案例。 Tavares等人[7]將焦點放在 BDD 作為一種更廣泛的設計技術或方法論上，強調將驗證和驗收整合到設計階段中，在進入構成功能的每個部份的設計之前， 要先考慮客戶的驗收標準。它們也認為 BDD 很大程度上基於規範任務和測試的自動化，需要適合的工具支持。 Keogh[10]對 BDD 則有更廣泛的觀點，主張 BDD 在軟體開發生命週期的重要性，利用 Lean thinking(精益思想)的概念如: value stream(價值流), pull(拉動), PDCA (Plan-Do-Check-Adapt) cycle(PDCA循環), 來揭示 BDD 的價值，他有力的證明 BDD 比 TDD 對軟體開發過程有更廣泛的影響。 Lean thinking: 一種管理和生產力提升的方法論，旨在減少浪費、增加價值和改進流程來實現組織和業務的成功。 Lazăr等人[11]也強調 BDD 在業務領域和軟體開發的交互中的價值，聲稱 BDD 使開發人員與領域專家能使用相同的語言。他們指出 BDD 的兩個核心原則: 業務和技術人員應該以相同的方式對待同一系統。 任何系統都應對業務具有確定可驗證的價值。 基於這觀點，他們分析了 BDD 方法並將概念作為 Domain model和 BDD profile (BDD 配置文件)來呈現。 Domain model: 用於表示系統的概念模型，描述系統中的各個實體與其之間的相互關係。 BDD profile : 描述 BDD 概念和規範的結構化文件。通常用於描述系統行為與驗收標準的關鍵字、語法和語意。 3. RESEARCH APPROACH 因為論文發表時的 BDD 文獻如第二節所示非常有限，因此作者以包含 TDD 和 Domain Driven Development(DDD) 的文獻回顧後， 以 TDD 作為基準界定 BDD 的具體特徵，因此作者認為的 BDD 具體特徵是那些沒有被做為 TDD 報告的特徵。 作者根據 BDD Wikipediap[13]列出的 40 個 BDD 工具包中選擇。並諮詢了 BDD mailing lists [23]，最後得出七個常用的工具包來分析: Cucumber [5,18]、Specflow [14]、RSpec [6,18]、JBehave [4]、MSpec [15]、StoryQ [12]和NBehave [16]。 Table 1 簡述了分析的七個工具包與其版本。 文獻回顧和工具包分析將交織再一起進行，回顧研究後確立 BDD feature sets(特徵集)，然後逐一分析工具包。當發現一個不在特徵集中的特徵後，會回到文獻中了解他是否可被視為 BDD 特徵， 直到分析完每個工具包。 4. THE CHARACTERISTICS OF BDD 作者透過以上的研究方法，確定了六個 BDD 的主要特徵。 A. Ubiquitous Language Ubiquitous Language(通用語言)是 BDD 中的一個重要概念，它的結構基於Domain model。它包含了定義系統行為所使用的術語，是產品團隊的所有成員和利益相關者共享的一組明確的詞彙。 在設計和實施階段，開發人員將使用該語言來命名 classes &amp; methods. 一個簡單的範例可見 What is Ubiquitous Language? Examples?。 BDD 本身包含一個預設的簡單 Ubiquitous Language 但與特定領域無關，是為了提供一種統一的方式來描述系統行為，用於結構 User Story(用戶故事)和 Scenario Templates(場景模板)。 User Story: 描述系統的功能需求或用戶期望的行為。 Scenario Templates: 定義具體的測試場景的模板，描述特定用戶故事的具體情境，行動和預期結果。 作者所分析的工具包都不支援為項目創建特定的通用語言。 B. Iterative Decomposition Process Iterative Decomposition Process(迭代分解過程)，在收集需求過程中，開發者往往很難找到與客戶溝通的起點，尤其是客戶所需實現的商業價值，Business value(商業價值)往往難以明確與識別。 因此 BDD 中，分析從識別系統的預期行為開始。系統的行為將從它打算產生的 business outcomes(商業成果)中得出。商業成果進一步細化為 feature sets(特徵集合)， 一個特徵集合將一個商業成果分割成一組抽象的特徵，這些特性指明了為了實現商業成果應該做什麼。 假設正在開發一個購物網站，其中一個商業成果就是用戶能下訂單並購買商品，就會包含幾個抽象特徵集如下 註冊和登錄: 用戶註冊新帳號、登錄現有帳號以及管理個人資料的功能。它是實現訂單和支付的前提。 訂單和支付: 用戶下訂單並完成支付的流程。它包括選擇適當的付款方式、填寫運送地址和付款信息等。 瀏覽和搜索: 用戶可以瀏覽網站上的商品列表，並提供搜索功能來快速尋找特定商品。 購物車管理: 用戶將他們感興趣的商品加入購物車，管理購物車中的商品數量、移除商品或更新數量。 每個特徵集和代表一個高層次的抽象，而其中的特徵則是進一部細分的具體功能與行為。 考慮到商業成果是 BDD 過程的起點，因此客戶需要明確指定商業成果的優先級，以使開發人員知道應首先開發哪些特徵集。 特徵隨後可以通過 User Story(用戶故事)來實現，提供了特徵的上下文。用戶故事是以用戶為導向的，描述用戶與系統之間的互動，其中應該澄清三個問題: 用戶在用戶故事中的角色是什麼? 這有助於明確指定使用者的身份和角色。 用戶希望有哪些特性? 這描述了用戶對系統功能的期望和需求。 如果系統提供了該特性，用戶可以獲得什麼好處? 這闡述了系統功能對用戶帶來的價值和利益。 在不同的情境下，一個用戶故事可能有多個版本，這些具體的實例就被稱作 Scenario(場景)。這些情境與結果通常由客戶提供，BDD 中場景被用作驗收標準， 用於驗證系統是否按造用戶故事的要求正確運作。 這種分解過程應該是 iterative(迭代)的，也就意味著對於每個不同的層級進行初步的分析即可，再隨著開發逐步詳細每個層級的細節，這樣就能使團隊有一個高層級的視圖再開始工作， 這樣可以使團隊更快的開始進行實現工作，同時保留靈活度與可調整性。 同樣以購物網站為例 初步分析：首先進行初步分析，識別出購物網站的高層級特徵集，如商品展示、購物車、付款和訂單管理等。 迭代分解：接下來可以選擇一個特徵集，如商品展示進行分解。識別出更具體的特徵，如分類展示、搜索功能、評論和評分等。 細化特徵：在這個特徵集中可以進一步細化特徵。如搜索，可以定義更具體的需求，如關鍵字、過濾器和排序等。 雖然作者所分析的工具包(2011)當下都不支援迭代分解，但現在已經有一些工具包支援迭代分解中的需求分析與設計。 C. Plain Text Description with User Story and Scenario Templates Plain Text Description with User Story and Scenario Templates(純文本描述的用戶故事與場景模板)， BDD 用簡單的通用語言與模板描述 features, user stories, scenarios, 如 User stories 以下用 Dan North 的模板來說明[3]: [StoryTitle] (One line describing the story) As a [Role], I want a [Feature], So that I can get [Benefit] StoryTitle 與 Role 描述給定角色下用戶執行的活動，Feature 則能確保開發人員知道應該實現哪些特徵與系統行為，為什麼要有這個功能以及該與誰討論與分析該功能。 也能清楚的說明 Feature 能帶給用戶什麼 Benefit，為什麼需要這些 Feature. Scenario 的撰寫模板則如下: Scenario 1: [Scenario Title] Given [Context] And [Some more contexts]…. When [Event] Then [Outcome] And [Some more outcomes]…. Scenario2: [Scenario Title] …. 場景描述了當系統在特定狀態下發生事件時應該如何行動，場景的結果是改變系統狀態或輸出的動作。對於上面兩種模板中括號中的描述應該使用專案中定義的 Ubiquitous Language 來撰寫。 此外要將它們直接映射進專案中，也意味著 Class 的命名和方法也應該使用 Ubiquitous Language 來撰寫。 作者分析的四個工作包使用的模板都與[3]的略有不同，但都定義了 User story 中的 role, feature, benefit。 在當下已經有 BDD 穩定且廣泛應用的通用語言模板格式，詳情可以見 Gherkin，被 Cucumber 所支援。 D. Automated Acceptance Testing with Mapping Rules Automated Acceptance Testing with Mapping Rules (使用映射規則的自動化驗收測試)，BDD 繼承了 ATDD 的自動化驗收的特點。 在 BDD 中驗收測試是一個可執行的規範，驗證對象之間的 interactions (交互)或 behavior(行為)，而不只是狀態[3][20]。 Automated Acceptance testing: 使用自動化測試工具來執行對系統行為的驗證，這些測試通常是從 User story, Scenario 中產生的。 開發者將從一個迭代分解的過程中生成的 Scenario(場景)開始，場景將被轉化為測試驗證實現。場景的每一個步驟是一個表示場景中的抽象元素，這些元素包括: contexts, events, actions。例如在 User story 或 context C 的特定情況下，當 event X 發生，系統地回答應該是 Z。每個步驟都被映射到一個測試方法。 每個步驟都將遵循 TDD 的流程即 “red, green, refactoring” 以使其通過。 Mapping rules(映射規則)則提供了一個場景到 Test code(測試代碼)或 Specification code (規範代碼)的標準映射。作者所研究的工具中映射規則有不同的變化: JBehave: 一個 User story 是一個包喊一組 Scenario 的文件，文件的名稱被映射到 Class 的命名，每個 Scenario 的步驟都被映射到一個 Test Method(測試方法)。 通常測試方法的名稱與 User story 文本相同。包含測試方法的 Class 則不須與場景相同。詳情可見 JBehave Writing Textual Stories。 Cucumber: Cucumber使用正則表達式進行映射，映射方法可見 Cucumber Expressions。 E. Readable Behaviour Oriented Specification Code Readable Behaviour Oriented Specification Code (可讀的行為導向的規範代碼)，BDD 建議代碼應該是系統文檔的一部份，與敏捷的價值觀一致。 代碼應該是可讀的，規範應該是代碼的一部分。因此 Method name 應該指出 Method 應該執行的操作，Class, Method name 都應該以句子形式撰寫。 Mapping rules 有助於生成可讀的行為導向的代碼，它確保 Class, Method name 與 User story 和 Scenario 的標題相同。 目前大部分的 BDD 工具都支持將 Scenario 中的規範轉為代碼的方法。 F. Behaviour Driven at Different Phases Behaviour Driven at Different Phases(不同階段的行為驅動)，這裡討論了行為驅動在軟體開發中的不同階段。 計畫階段: 定義商業成果，描述系統應該實現的期望行為。例如: 用戶能夠完成購物並順利支付訂單。 分析階段: 商業成果被分解為一組特性，這些特性捕捉目標系統的行為。例如: 用戶註冊，商品管理，訂單處理等等.. 這些特性將會被轉化為 User stoies。 實施階段: Automated Acceptance testing 中 Testing Clases 是根據 Scenario 所產生的。 因此 Class name 指明了該 Class 該做什麼或行為是什麼，這使開發者能考慮它們開發中的組件的行為，以及與之交戶的其他對象的角色與責任。 在作者研究的當下還沒有針對定義商業成果也就是計畫階段的支持，大部分的工具包都專注於 User stoies, Scenario 的撰寫與測試自動化。 Table 2 總結了作者分析的七個工具的對於這些特徵的支持情況 Fig 1 是一個以 UML class diagram 來呈現的六個特徵之間的概念與關係模型 V. CONCLUSIONS BDD 是多種方法的結合，如 ubiquitous language, TDD, automated acceptance testing。作者通過文獻回顧與工具包的分析來確認了六個 BDD 的主要特徵。 並透過逐一分析研究表明了這些特徵之間的互相關聯。並提出了一個 BDD 的概念模型 Fig. 1.。 而對於新的研究方向則指出， 2011 的當下工具包都主要關注於軟體開發的實踐階段，對於分析的支持有限，而計劃階段則根本沒有，這是一個可擴展的研究方向。 而另一項則是可以擴展 BDD 的映射規則，2011 現有的工具包都關注於 User story, Scenario 映射到代碼，此外 feature sets(特徵集) 也可以被映射到命名空間中， 在此之下再加入場景的測試[10]。 [10] E. Keogh, BDD: A Lean Toolkit. In Processings of Lean Software &amp; Systems Conference, Atlanta, 2010. NOTE Last edit 06-18-2023 22:56"
  },"/jekyll/2023-05-20-analysis_mutation_testing.html": {
    "title": "Paper | An Analysis and Survey of the Development of Mutation Testing",
    "keywords": "software software_qualitiy mutation_testing Jekyll",
    "url": "/jekyll/2023-05-20-analysis_mutation_testing.html",
    "body": "Yue Jia, Mark Harman, … (2011), An Analysis and Survey of the Development of Mutation Testing. 用這篇論文熟悉什麼是突變測試(Mutation Testing). 突變測試是用來檢測測試集合能否發現故障的能力， 這篇文章全面分析了一系列突變測試的方法、工具、發展和驗證結果，本文引用眾多且詳細，閱讀時要搭配原文的索引閱讀。 Section 2 是突變測試的幾本理論，3 ~ 5 詳細介紹突變技術與應用，6 是總結研究經驗，7 是突變工具的開發工作，8 討論目前的證明，9 則是尚未解決的問題與障礙，10 為總結。 Section 3 以後是詳細技術介紹，如果只想簡單理解什麼是突變測試讀 1、2、10 即可。 1. Intorduction 突變測試(Mutation Testing)是一種基於故障的測試技術，可以提供一個稱為 Mutation adequacy score(突變適應性分數)的測試準則來評估測試集合在檢測故障方面的有效性。 突變測試使用的故障代表程序員常會犯的錯誤，我們也可以模擬任何 Test adequacy criteria(測試適當性準則)。透過簡單的語法變化崁入原始程式中，稱為突變體。這些突變體會執行輸入輸出測試集合，如果一個突變體的結果與原始程式不同就表示檢測到一個故障突變體，亦稱為killed mutant(殺死突變體)。 Mutation adequacy score： 突變測試的測試準則，是檢測到的突變數量與生成突變體的總數的比例，公式為(檢測到的突變/生成突變數量)。 Test adequacy criteria: 一組可用於判斷是否進行了充分測試的規則，也可指導測試數據的選擇，明確的說明如何選擇測試數據。 Mutation score = (number of killed mutants/total number of mutants killed or surviving) x 100 突變測試的概念可以追溯到 1971, 當時 Lipton 在一篇學生論文中提出了這一概念。Mutation testing 可以應用在軟體測試的單元層、集成層和規範層。已經在許多編程語言中得到應用，是一種白盒單元測試技術。同時也可以在設計層次用於測試程式的規範或模型， 如 Mutation Testing已經應用於有限狀態機、Statecharts、Estelle規範、Petri網絡、網絡協議、安全策略和Web服務等領域。 本文作者整理了一系列的突變測試論文，將重要的論文註記於 Table. 1.，及關於增長趨勢的圖表 Fig. 1.。 2. The theory of mutation testing 2.1 Fundamental Hypotheses 突變測試希望能夠有效的識別足夠的測試數據，用於發現真正的故障。[96]但是潛在的故障是巨大的，不可能代表所有的突變體，這是一個針對故障的子集，希望接近模擬所有故障。 這個理論建立於兩個假設 the Competent Programmer Hypothesis(CPH) 和 Coupling Effect(CE)： CPH(合格程序員假設)[3][66]： 假設編程人員是有能力的，他們盡力去更好地開發程序，達到正確可行的結果。因此可能有程式中有錯誤，但只是一些小的語法更改修正的簡單錯誤。 並且在部分論文中也引入了 Program neighborhoods(程序鄰域)的概念[37] CE(耦合效應)[66]： [66]提出後， Offutt 進行了擴展 Coupling Effect Hypothesis， Mutation Coupling Effect Hypothesis[174][175]。 Coupling Effect Hypothesis：測試數據集可以檢測到由簡單錯誤，同時也能隱含地檢測更複雜的錯誤。 Mutation Coupling Effect Hypothesis: 因此複雜突變體與簡單突變體之間也存在著耦合關係。 因此傳統 Mutation testing 中僅僅會使用簡單突變體進行測試。 [3] A.T. Acree, T.A. Budd, R.A. DeMillo, R.J. Lipton, and F.G. Sayward, “Mutation Analysis,” Technical Report GIT-ICS-79/08, Georgia Inst. of Technology, 1979. [66] R.A. DeMillo, R.J. Lipton, and F.G. Sayward, “Hints on Test Data Selection: Help for the Practicing Programmer,” Computer, vol. 11, no. 4, pp. 34-41, Apr. 1978. 關於 CEH 的有效性已經有很多研究驗證[145], [164], [174], [175]。其中證明了從一階突變體生成的測試及對於 kth oredr 的突變體同樣能有效指出錯誤 (k = 2; … ; 4)， 能殺死一階突變體的有效數據同樣也能殺死 99% 以上的二、三階突變體。[242], [243], [244], 提出了一個簡單的理論模型 the q function model，將程式視為一組有限函數。 將測試集用於一階與二階模型，存活比例分別為 $\\frac{1}{n}$ 和 $\\frac{1}{n^2}$ n 是階數。[125]中可以找到關於 the boolean logic faults 的耦合效應的正式證明。 [125] K. Kapoor, “Formal Analysis of Coupling Hypothesis for Logical Faults,” Innovations in Systems and Software Eng., vol. 2, no. 2, pp. 80-87, July 2006. 2.2 The Process of Mutation Analysis Fig. 2. 是突變分析的傳統流程圖，將原始程式進行單一的語法改變，產生有缺陷的程式 P’，稱作 The mutant(突變體)，如 Table. 2. 僅將 &amp;&amp; 改變為 ||。 這種轉換規則稱作 mutation operator(突變運算符)，典型的突變運算符用於替換、插入或刪除運算符來修改變數和表達式。 Table. 3. 是 Fortran 的第一套正式突變運算符， 在 Mothra mutation system 上被實現。 [123] 使用了一種腳本語言 Mutation Operator Constraint Script (MOCS)，提供兩種類型的約束: Direct Substitution Constraint: 允許用戶選擇特定的轉換規則來執行簡單的變更，如將一種運算符轉換為另一種。 Environmental Condition Constraint: 指定適用於突變的特定環境條件，例如突變操作只在特定的作業系統下生效。 [217] 提出一種轉換語言 MUDEL，用於指定突變操作符的描述，可以定義為捕捉某種程式中的語法規則進行修改。更詳細的說明可在 Offutt 等的工作中找到[177] 然後在下一步中，我們要先確保原始程式 p 能通過測試集合 T，以驗證測試集合的正確性。 T 中的每個測試用例運行 p’ 與 p 的結果相同則稱為 survived(存活)，否則則稱為 killed(殺死)。 killed: 代表能夠找出 p’ 的錯誤，因此也代表能找出 p 的錯誤。 survived: 無法檢測出 p’ 的錯誤，代表這個測試用例也無法找出 p 的錯誤。 因此我們會希望一個測試用例能殺死盡可能多的突變體，因為這樣才代表這個測試用例是有效的能檢測出多個錯誤情況。 為了改進 T，測試者可以提供額外的輸入來殺死存活的突變體。但有些突變體是無法被殺死的，他們稱為 Equivalent Mutants(等效突變體)， 它們在語法上有所不同但功能等同於原始程式。自動檢測是不可能的[35]，[187]，因 program equivalence 是無法判定的， 因此這是阻礙突變測試應用的障礙之一。 關於突變分析的最終目的就是 Adequacy Score(適應性分數)，即是 Mutation Score(突變分數)，他表示輸入測試集的品質。 突變分析的目標是將分數提高到 1，表示測試集合 T 足以檢測到突變體表示的所有故障。 2.3 The Problems of Mutation Analysis 阻礙突變測試成為實用測試技術的第一個問題是對測試集執行大量突變體的高計算成本。其他問題則與使用突變測試投入的人力成本有關， 如 Human oracle problem(人類預期問題)[247]和 Equivalent mutants(等效突變體問題)[35]。 Human oracle problem: 是指每個測試用例需要人類來驗證測試結果的問題，花費時間來檢查結果是否符合預期。 Equivalent mutants: 由於不可判定性，往往需要額外的人力投入。 現有的突變測試進展，雖然還未完全解決這些問題，但突變測試的過程已經可以自動化，並且運行時可以實現合理的擴展性。 3. Cost Reduction Techniques 傳統的 Mothra 中所有的突變體都要被考慮在內，為了使 Mutation testing 成為實用的測試技術，許多成本降低技術被提出，[191]的調查中分為三類: “do fewer”, “do faster”, “do smarter”. 在本文中將技術整理為兩類，並在 3.1 與 3.2 各自介紹: reduction of the generated mutants: 減少生成的突變體對應 “do fewer” reduction of the execution cost: 減少運算成本對應 “do faster”, “do smarter” Fig. 3. 是已發表關於降低成本的想法的時間發展與情況 作者整理的當下 Selective Mutation(選擇性突變), Weak Mutation(弱突變)是最廣泛使用的成本降低技術，見論文 Fig. 4. 3.1 Mutant Reduction Techniques 再不嚴重影響測試效果的情況下減少產生的突變體數量是一個熱門的研究問題。對於一組給定的突變體 M 和測試數據集 T，$MS_T(M)$ 表示 T 應用於 M 的突變分數。 突變體減少可以定義為在 M 中找到一個子集 M’ 而 $MS_T(M) = MS_T(M’)$。 3.1.1 Mutant Sampling 突變體抽樣是一種簡單的方法，從整個集合中隨機選擇一小部分突變體，最早由[2][34]提出。首先像傳統的突變測試一樣生成可能的突變體，然後從這些突變體中隨機選擇 x% 進行分析， 其餘的則丟棄。 在[159][248]中這種方法進行了驗證，從 10% 到 40% 之間，結果顯示 10% 與全選相比效果僅下較 16%，表明 x &gt; 10 時，抽樣是有效的，在 [64][131] 中也得到了驗證。 除了固定抽樣率，[207]提出一種基於 the Bayesian sequential probability ratio test(SPRT)(貝葉斯序列概率比檢驗) 的抽樣方法，突變體是隨機選擇直到達到統計學上的合適樣本量為止， 這種方法比固定抽樣更敏感，因為他們是基於可用的測試集自我調整的。 [207] M. Sahinoglu and E.H. Spafford, “A Bayes Sequential Statistical Procedure for Approving Software Products,” Proc. IFIP Conf. Approving Software Products, pp. 43-56, Sept. 1990. 3.1.2 Mutant Clustering 突變體聚類最早在[116]提出，使用 clustering algorithms(聚類演算法)選擇一個突變體子集。先生成突變體，然後應用聚類演算法，根据可殺死的測試案例將一階突變體分類到不同的聚類中。 同一集群中的每個突變體都保證被一組類似的測試用例殺死，然後在每個集群中選擇少量的突變體用於測試，其餘的丟棄。 [116]中使用兩種聚類算法 K-means 和 Agglomerative clustering，並將結果與隨機和貪婪選擇策略做比較，結果表明聚類能選擇更少突變體並保持突變分數。後續發展可在[120]中找到， 使用了一個 domain reduction technique(領域縮減技術) 來避免執行所有的突變體。 3.1.3 Selective Mutation 選擇性突變透過減少應用的突變運算符來實現減少突變體數量。試圖找到一小部分突變運算符來產生可能突變體中的子集，而不會對測試效果產生重大損失。 最早可見於[156]提出的 “constrained mutation”，[190]隨後擴展了這個想法，稱為選擇性突變。 突變運算符生成的突變體數量各不相同，如在 Mothra 中，ASR 和 SVR 兩個運算符生成了約 30 ~ 40% 的突變體[131]。[156]建議省略這些產生大部分突變的運算子 ASR、SVR。 之後 Offutt[190] 將其擴展至四個和六個，在他們的研究中: 2-selective mutation: 99.99 的平均突變分數，減少 24% 的突變體。 4-selective mutation: 99.84 的平均突變分數，減少 41% 的突變體。 6-selective mutation: 88.71 的平均突變分數，減少 60% 的突變體。 [190] A.J. Offutt, G. Rothermel, and C. Zapf, “An Experimental Evaluation of Selective Mutation,” Proc. 15th Int’l Conf. Software Eng., pp. 100-107, May 1993. [248][252]則基於測試效果的選擇，被稱為 constraint mutation(約束性突變)，僅採用兩個操作符進行突變 ABS、RAR 因為殺死 ABS 需要 input domain(輸入域)的不同部分測試用例， 而殺死 RAR 需要檢查 mutated predicate(突變謂詞)的測試用例。結果表明可以將突變體數量減少 80%，而僅對突變分數減少 5%。 [252] W.E. Wong and A.P. Mathur, “Reducing the Cost of Mutation Testing: An Empirical Study,” J. Systems and Software, vol. 31, no. 3, pp. 185-196, Dec. 1995. [182] Offutt等人以此進一步擴展了它們的 6-selective mutation，將 Mothra 運算符分為三類：statements, operands, expressions 之後依次省略每一類的運算符， 最後發現來自 operands, expressions 兩類的 ABS, UOI, LCR, AOR, ROR 這些關鍵的運算符取得了 99.5 的變異分數。 基於之前的經驗，Barbosa 等人[19]定義了一個選擇足夠操作符的指南，它們將這個指南應用於 Proteum 的 77 個 C mutation operators [6]，得到一組 10 個選定的突變操作符， 其平均突變分數為 99.6% 並且減少了 65.02% 的突變體。 並與 Offutt 和 Wong 做比較得到最高的突變分數。 [19] E.F. Barbosa, J.C. Maldonado, and A.M.R. Vincenzi, “Toward the Determination of Sufficient Mutant Operators for C,” Software Testing, Verification, and Reliability, vol. 11, no. 2, pp. 113-136, May 2001. 而最新研究是 Namin 和 Anderws 進行[168][169][170]，將選擇性突變問題定義為統計問題，使用線性統計從 109 個 C mutation operators 中識別出 28 個操作符的子集， 目前他們減少了 92% 的突變體，是論文(2011)當下最高的減少率。 3.1.4 Higher Order Mutation 高階突變由 Jia 和 Harman (2008)提出[122]，基本動機是尋找那些罕見但有價值的高階突變，first order mutants (FOMs) 和 higher order mutants (HOMs)， HOMs 是通過多次應用突變操作符來生成的。 使用了 subsuming HOMs 的概念，一個 subsuming HOMs 比建構她的 FOMs 更難被殺死。因此使用單一的 HOM 來取代 FOM 以減少突變體的數量。 除此之外他們還使用了 strongly subsuming HOM(SSHOM) 的概念，他只被能夠殺死構成他的 FOM 的測試用例的交集的子集才能夠殺死他。 Polo等人[199]部分證明了這個想法，他們提出了不同的算法將一階段組合成二階突變。應用二階突變可以減少 50% 的測試工作量，而測試效果幾乎沒有損失。 Langdon等人[136][137]應用 multi-object genetic programming(多目標遺傳編程方法) 生成高階突變體， 他們發現了比任何一階突變體更難殺死的 realistic higher order mutants(現實高階突變體)。 multi-object genetic programming(MOGP): 一種進化計算技術，結合 Genetic Programming(遺傳編程)，Multi-Objective Optimization(多目標優化)的概念與方法。 realistic higher order mutants: 這些高階突變體可以更好地模擬真實世界中的軟件錯誤，並提供更有挑戰性和現實性的測試用例。 3.2 Execution Cost Reduction Techniques 本節介紹三種優化執行過程的技術類型 3.2.1 Strong, Weak, and Firm Mutation 根據分析突變體在執行過程中是否被殺死的方式，突變測試技術可分為三種類型: Strong(強突變)、Weak(弱突變)和 Frim(穩固突變) 強突變通常被稱為傳統的突變測試。最初由DeMillo等人提出[66]。對於給定的程序 p，如果突變體 m 與原始程序 p 的輸出不同，則認為突變體 m 被殺死。 NOTE Last edit 05-26-2023 20:52 本篇論文先閱讀完基本的突變測試，之後再來補齊"
  },"/jekyll/2023-04-21-tdd_concepts.html": {
    "title": "Paper | Test-driven development concepts, taxonomy, and future direction",
    "keywords": "software software_qualitiy software_development Jekyll",
    "url": "/jekyll/2023-04-21-tdd_concepts.html",
    "body": "John Estdale &amp; Elli Georgiadou, (2005) Test-driven development concepts, taxonomy, and future direction. 這篇論文可以用來快速了解什麼是 TDD(Test-driven development) 測試驅動開發 Intorduction 測試驅動開發策略要求在小型、快速的迭代(Small, rapid iterations)中先編寫自動測試，然後再開發功能代碼。這種開發策略作為極限編程(XP, Extreme programming)核心實踐之一而持續受到關注。 XP, Extreme programming 是敏捷軟體開發(Agile software development)的一種方法，強調非常短的迭代進行軟體開發。 小型快速的迭代(Small, rapid iterations)是一種敏捷開發方法論，將軟體開發過程劃分為一系列小模塊，每個模塊都有各自的開發與測試。 例如: 一個團隊開發一個線上商店，可將功能分為各個小的模塊: 用戶註冊、商品搜索、購物車管理、訂單處理等等，然後透過迭代週期來完成和測試各個模塊。 The test aspect 除了 High-level 的測試之外，TDD要求編寫單元的自動化測試。 在軟體中什麼是確切的單元有一些爭議，即使在 OOP 中 Classes 和 Method 都被建議作為合適的單元。 無論如何 Method 和 Procedure 都是最小的可測試單元組件。 開發者需要實現測試驅動(Test drivers)與模擬函數(function stubs)，可以經由自動化(JUnit, …)或手動化測試。 Test drivers: 一個可以執行單元測試的程式，已確定代碼是否正確通過測試。 Function stubs: 一個虛擬的函數，通常只有命名、輸入與輸出參數。 因此在TDD中開發者需要先寫好單元測試，然後代碼完成後就可以立即執行測試。 The driven aspect TDD是一種測試策略，強調測試先行，通過測試來引導軟體開發中的分析、設計、和編寫決策。 在 XP 中客戶也被視為開發者的一員，提供更清楚的需求，以此來更清楚的撰寫測試，測試就是決定程式應該做什麼的第一步。 為了促使測試成為分析和設計的一部分，需要使用重構(refactoring)的作法。 就是不斷改變現有程式碼的結構，但依然要通過測試，使程式碼得到改進。 因此TDD更多著重的是分析和設計，而不是測試，測試是用來幫助開發者決定程式或程式介面應該是什麼樣子。 The development aspect TDD旨在協助構建軟件開發，但它不是一種軟件開發方法論或過程模型。相反，它是一種實踐方法，可以與其他方法相結合。 如結合其他開發方式，在 DevOps 中 TDD, BDD 都被強調為測試過程的重要方法，可以參考[1]。 同時測試不是為了做出設計決定後就被拋棄的，而是成為開發過程中的一個重要步驟。 如果有一個變化導致測試失敗，當測試還在開發者的腦海中時，開法者可以立刻知道哪裡出錯。缺點就是在開發時必須同時維護測試與生產代碼。 [1] Pulasthi Perera, …, (2017) Improve Software Quality through Practicing DevOps, IEEE Software development methodologies 在軟體開發過程或方法論定義了建立軟體的基本任務(base task)的順序(order)、控制(control)、評估(evaluation)。在這些方法論中的複雜度與控制範圍從非正式的到高度結構化不等 方法論分為兩大類: Prescriptive(規定型), Agile(敏捷型) 具體可分為: Waterfall(瀑布式), Spiral(螺旋式), Incremental(增量式), Evolutionary(演進式) 但在開發中通常是組合使用這些方法，例如: 一個組織可能使用增量式開發模型，逐步建構項目的累積片段。而在每個增量中開發者可以應用瀑布或線性方法進行開發。那麼根據增量的大小我們就能將整個方案標記成不同的方法論。 假設方程式 $\\sum_{i=1}^{N} I_i$ 代表整個專案，$I_i$則是每次的增量，我們可以去預想如果$N$大於一定量則是一個增量項目，若$N\\leq2$則使用瀑布項目。如果每個增量需要修改大量重複的軟體部份，我們就可以說具有迭代性，例如： 如果$C_i$是$\\sum_{i=1}^{N} I_i$的項目$P$中的每次增量被影響的代碼部分，並且項目$P$有迭代性則$C_i \\cap C_{i+1} \\neq \\emptyset$ Prescriptive(規定型)通常會希望有一份正式的文件，如規範文件來記錄增量的需求。 Agile(敏捷型)則文件通常是非正式的，如白板圖或一套不完整的UML圖，並且生成是快速的。 建設任務的順序對一個項目來說至關重要，傳統的順序是： Requirements elicitation(需求徵詢), Analysis(分析), Design(設計), Code(編碼), Test(測試), Integration(集成), Deployment(部署), Maintenance(維護) 在開發過程中我們能發現在Design, Code, Test階段都有不同種類的測試，如：單元測試, 整合測試, 回歸測試 TDD’s historical context Test-driven development(測試驅動開發)是與敏捷模型的興起一起出現的，都起源於20世紀50年代的迭代，增量，進化的過程模型。 將測試移動到編碼的前方並不是什麼新鮮事，在1980’s的 Cleanroom 軟體工程方法就已經包含了使用 Formal methods 對早期設計元素進行驗證。 在1998 XP(極限編程)後開始推崇先寫測試在寫程式，但在那之前就可能有非正式的測試先行的方法。 [2] K. Beck, Extreme Programming Explained: Embrace Change, Addison-Wesley, 1999. “learned test-first programming as a kid while reading a book on programming. It said that you program by taking the input tape … and typing in the output tape you expect. Then you program until you get the output tape you expect.” - Kent Beck [2] TDD就是將這種做法做到極端，總是先寫測試再編程，增量式、迭代式和演進式過程模型的發展對它的出現至關重要。 將測試分解成更小、更簡單、更具體的單元測試，這樣做的好處是能夠更快地找到問題，更容易進行測試和調試。 永遠不使 Code 退化，不允許代碼質量下降或出現新的錯誤。這可以通過不斷地運行測試來實現。 XP takes the known best practices and “turns the knobs all the way up to ten.” - Kent Beck [2] TDD developed within the context of iterative, incremental, and evolutionary models. Iterative 涉及重複一組開發任務，通常是在逐漸擴展的需求集上進行。 Incremental 則產生一系列的版本，每一個增量都提供更多的功能。 Evolutionary 方法涉及自適應和輕量級迭代開發。 Adaptive(自適應): 強調利用過去迭代的反饋來改進軟體。 Lightweight(輕量級): 減少過度的規範和流程，利用反饋進行改進，在最短時間內交付可用的版本。 Spiral Model(螺旋模型): 結合原型(prototyping)和迭代(iterative)的循環，並加入風險驅動和錨點里程碑。 that to implement XP, developers must apply all of the incumbent practices—leaving some out weakens the model and can cause it to fail. - Kent Beck [2] TDD要求將設計決策延遲(design decisions be delayed)和靈活(flexible)以影響軟體設計 設計決策延遲: 在這之前先編寫測試用力，這些測試用力會指導開發者在編寫代碼之前考慮好應該如何設計代碼才能使其滿足需求。這樣開發者可以通過通過測試用例更好的理解問題和需求。 靈活: 在設計過程中，保持靈活性以便能夠適應可能出現的變化。這意味著編寫足夠通用的測試用例，以便代碼可以更容易地進行修改，而不會破壞之前的測試。 一個自動化的測試將給予開發者勇氣重構程式碼，也給了他們需要的訊息，使他們能在改變程式碼後迅實現修改，而實現開發人員對代碼的集體所有權(Collective ownership)。 集體所有權(Collective ownership): 所有的開發人員都有對代碼的共同責任和掌控權，因為TDD自動化單元測試可以使開發者迅速檢查是否有破壞其他開發者的工作。 Automated testing Software tools 已經成為現代軟體開發的重要因素。Compilers, Debuggers, IDE, Modeling, Computer-aided software engineering tool, 這些工具提高了開發者的生產力。 TDD假定存在自動化的單元測試框架，這樣的框架提供了測試驅動(test driver), 存根(stub), 子系統的接口(interfaces to other subsystem)的測試組合。 Erich Gamma 和 Kent Beck 開發了 JUnit, 一個 Java 的自動化單元測試框架，JUnit 在很大程度上促進了 TDD 和 XP 的廣泛普及。類似 JUnit 的框架也已實現於多種不同的程式語言中，創建了一系列的框架，被稱為 xUnit。 xUnit 一般來說 xUnit 允許開發者撰寫一系列自動化單元測試，從初始化(Initialization), 執行(Execution)並對測試代碼進行斷言(Assertion)。 各個測試都是獨立的，所以測試順序並不重要。xUnit 測試是用與被測試代碼相同的語言編寫的， 同時測試也可以作為文檔(docs)，開發者通過閱讀測試程式碼來了解被測試程式碼的行為和功能。 JUnit 也提供了一個可移植的 GUI，已經被集成到流行的開發環境中，如 Eclipse。 JUnit 中一些工具簡化了 Mock object(模擬對象)、Stub(存根) 的創建，這些可以取代真實的協作對象，因此開發人員就能專門測試一個特定的對象。 同時也可以使用其他工具如 Cactus, Derby 和 JUint 一起實現涉及 J2EE 組件或 Database 的自動化測試。 支持 TDD 的工具不斷增加顯示出了 TDD 受到的支持，並且使開發人員能輕鬆開發單元測試並通過自動化執行大型測試套件，以此迅速獲得有關系統狀態的結果。 Early testing in academia 大學的計算機科學和軟體工程課程可以作為一個指標，來評估軟體實踐的廣泛接受程度。有時學界會領先於實踐，有時則會跟隨，而軟體工程，迭代開發和 TDD 則是後者的模式。 這些軟體工程課程往往落後於業界的普遍實踐，因此往往是實際軟體開發使用了新的開發過程模型，再由學者研究、最終成為課程的一部分。 1991 ACM 課程指南中迭代開發和驗證只分配了不到八小時的講座與實驗時間。而在 2001 年則分配到了更少的時間僅有五小時。 在文章撰寫的當下 2005 TDD 並還沒有被學界廣泛接受。 Recent context (2005) XP 是當時最著名的敏捷方法，經常與其他敏捷方法(例如: Scrum) 結合使用，XP 提出使用 TDD 作為開發高品質軟體的一個組成部分。 TDD 的潛在使用者常常對於編寫和維護測試單元感到擔憂， Beck 承認自動化單元測試並不是對所有事情都必要的， 但是他也堅稱 XP 無法在沒有 TDD 的情況下運作，因為它是作為將整個流程黏合在一起的黏合劑。 盡管 XP 的流行但並不代表使用時會採用它的所有實踐，或者他們不連貫的使用這些實踐。 ThoughtWorks 的一個專案中，J. Rasmusson 是一個早期的 XP 使用者，但約有 1/3 的代碼是使用 TDD 開發。[3] 在這個專案中，開發者在 37,000 行代碼中有 16000 行是用於自動化單元測試，許多測試都是在測試優先和測試最後的迭代中寫的。[3] 因此口頭證據表明，即便只採用 XP 的部分實踐，TDD也通常會包含在內。 [3] J. Rasmusson, “Introducing XP into Greenfield Projects: Lessons Learned,” IEEE Software, May/June, 2003, pp. 21-28 “If I could only recommend one coding practice to software developers, those who use XP or otherwise, it would be to write unit tests.” - J. Rasmusson [3] 在當時流行的 IDE Eclipse 中，JUnit, XP 這樣的流行結合也可以意味著 TDD 被廣泛採用的一部分證明。 Evaluative TDD research 在論文當下(2005)大部分文章都是關於應用 TDD 所寫，對於 TDD 的效果與好處的研究相對較少。 關於 TDD 的研究大致可依背景分為業界與學術的研究: 業界研究往往更注意實際應用與實用性，並著重於現有實踐進行評估與改進。 學界則更注重基礎理論與科學方法，著重於深入研究問題背後的原因與機制。 TDD in industry NCSU(North Carolina State University) 的研究者在四家不同公司進行了三項關於 TDD 的實證研究[8][9][10]，參與者是一些相對小的團退。這些研究以缺陷密度(Defect density)作為衡量品質的指標。 使用 TDD 進行開發的控制組比對照組多通過 18% - 50% 的外部測試用例。 同時使用 TDD 開發的除錯(debugging) 時間花費更少。 Table 1 summarizes these studies and labels each experiment as either a case study or a controlled experiment. [8] B. George and L. Williams, “A Structured Experiment of Test-Driven Development,” Information and Software Technology, vol. 46, no. 5, 2004, pp. 337-342. [9] E.M. Maximilien and L. Williams, “Assessing Test-Driven Development at IBM,” Proc. 25th Int’l Conf. Software Eng. (ICSE 03), IEEE CS Press, 2003, pp. 564-569. [10] L. Williams, E.M. Maximilien, and M. Vouk, “Test-Driven Development as a Defect-Reduction Practice,” Proc. 14th Int’l Symp. Software Reliability Eng. (ISSRE 03), IEEE Press, 2003, pp. 34-45. TDD in academia 盡管在學術環境中很多 TDD 相關的研究都是軼事，但在 Table 2. 列出的五個研究則有具體的實證結果。 除了 [11] 其他都聚焦於 TDD 的早期缺陷檢測能力。 [11] [12] 報告了軟體品質與程式開發者生產力的明顯改善。 [13] 報告撰寫的測試數量與生產力之間的相關性。 [14] [15] 則報告了缺陷密度和生產力方面並沒有明顯改善 以上報告都相對較小，並且沒有或很少有具有 TDD 經驗的開發者參與。 Factors in software practice adoption 多種因素影響是否採用軟體實踐其中包含: Motivation for change(改變的動機), Economics(經濟), Availability of tools(工具的可用性), Training and instructional materials(訓練和培訓工具), A sound theoretical basis(紮實的基礎理論), Empirical and anecdotal evidence of success(成功的經驗和軼事), Time(時間), The practice by highly regarded individuals or groups.(權威個人或團體的做法) Motivation for change: 軟體開發實務上有明確的改變動機，開發涉及人員、流程、技術和工具等複雜的組合，TDD 為一種嘗試改進並看似有效的方法。 Availability of tools: TDD 的工具支持很強，並且正在不斷改進，像 JUnit, MockObjects, Cactus, 這樣的工具已經成熟並廣泛可用。 Economic: 經濟模型上也指出了 XP 和 TDD 在軟體開發上的潛力，但需要進一步研究 TDD 和 XP 帶來的優缺點，如: TDD 在配合代碼使用時需要研究它在速度上是否會慢於傳統開發，與對缺陷密度(defect density)的影響。 A sound theoretical basis &amp; Empirical and anecdotal evidence of success: 研究表明，學術開發需要 5 - 15 年時間才能在商業實踐中取得成功，反之亦然。TDD 可以改善開發教育。 TDD 的普及面臨許多挑戰，首先開發者要有良好的紀律，因為 TDD 需要開發者遵從他的流程與步驟，因此需要使開發者充分理解 TDD 的好處，才能使開發者嘗試使用。 TDD 也被廣泛的誤解，很多人錯誤的認為 TDD 只關注測試，而不是設計。TDD 不僅僅是關注測試，它同時也要求開發人員在編寫程式碼之前，必須先清楚地設計出程式的架構和功能。在這個過程中，開發者必須思考如何編寫最小程式碼，減少重複代碼，設計清晰的介面等，要求開發者在設計和開發過程中相互交替地進行，從而可以促進高品質、易於維護和可擴展的程式碼產生。 TDD 並不適用於所有開發場景，開發者和管理者必須決定何時用 TDD 何時不用。 Understanding TDD’S effects 在 2005 論文發表時，TDD 對於品質的影響都將焦點放在缺陷密度(defect density) 上，應該有其他方式評估軟體品質。 未來的研究應該考慮在課程和程式設計師成熟度不同的情況下，TDD的有效性。還可以研究 TDD 與先設計後測試的方法、迭代方式進行的測試最後方法的效果差異。 也需要研究 TDD 與其他實踐結合的效果，如配對編程(Pair programming), 代碼檢查(Code inspection) 結合的效果，並且研究 TDD 是否可以納入大學教育中， 以提高學生的設計和測試能力。 XP-EF, 一個持續進行評估 XP 專案案例研究的框架[16] 配對編程(Pair programming): 兩名程式開發人員共同在同一臺電腦上工作，一人負責寫代碼，另一人負責檢查。 代碼檢查(Code inspection): 軟體開發中對於原代碼進行審查以檢查其品質和可靠性。 L. Williams, L. Layman, and W. Krebs, Extreme Programming Evaluation Framework for Object-Oriented Languages, v. 1.4, tech. report TR-2004-18, North Carolina State Univ., 2004. Even if Xp fades in popularity 即使未來 XP 逐漸失去流行，但是 TDD 可能仍然持續存在。如果TDD進入學術領域，學生們可以帶著更好的紀律和更好的軟體設計和測試技能進入軟體開發組織， 從而提高軟體工程社區可靠地生產、重用和維護高品質軟體的能力。 NOTE 這篇論文很好的介紹了 TDD 的概念與歷史、工具、在 2005 年時的未來展望，同時結尾的論述也非常準確，2023 年的今天 XP 已經不再像 2002 那樣流行， 但是 TDD 仍然是重要的開發方式，並也發展了後續的 BDD 等。 Last edit 04-29-2023 18:24"
  },"/jekyll/2023-04-18-applying_isoiec25010.html": {
    "title": "Paper | Applying the ISO/IEC 25010 Quality Models to Software Product",
    "keywords": "software software_qualitiy standard Jekyll",
    "url": "/jekyll/2023-04-18-applying_isoiec25010.html",
    "body": "John Estdale &amp; Elli Georgiadou, (2018) Applying the ISO/IEC 25010 Quality Models to Software Product, IEEE. 1. Introduction 軟體開發過程中，我們著重的是如何交付軟體產品，但是潛在的購買者其實更在意軟體產品能為他們帶來的未來服務價值，也就是軟體能夠在實際使用中帶來的效益。ISO/IEC 25010: 2011 是評估軟體產品質量的重要標準，可以幫助我們確定軟體流程的交付表現以及提出改進建議。論文從以生命週期為導向的服務觀點出發，探討 ISO/IEC 25010 模型的範圍和解釋，也確認了購買者關注的其他重要軟體產品方面，並提出了可能需要的品質要求和評估方式。 2. ISO/IEC 250xx series: SQuaRE SQuaRE 標準的目標是幫助開發和獲取系統和軟件產品的人員規範和評價產品的質量要求，並建立一個支持質量測量的過程。過去的 ISO/IEC 9001 標準主要關注是否符合先規定的規格或要求，而現再更包含了客戶上的需求與期望。 在軟體品質特徵中可分為兩個模型： 使用品質(Quality in Use) 是指產品能夠在特定使用情境下，由特定用戶滿足其需求並達成其特定目標的程度。 產品品質(Product Quality) 則是指與軟體的靜態特性和電腦系統的動態特性相關的品質特徵，這些特徵包括了例如可靠性、效能、可維護性、可移植性等。 詳細的敘述與子項可見Note - ISO/IEC 在論文中將 ISO/IEC 25010: 2011 分為兩種類型的模型 3. Applying the ISO/IEC 25010: 2011 Quality Models 不像物理世界，有明確獨立的尺寸和明確定義的度量（如長度、質量、時間、電流、熱力學溫度、光強度等）。 軟件品質概念則有點模糊例如兼容性，重新定義和重組這些概念就是 ISO/IEC 25010 工作的一部分。 “a conceptual framework and not a ready-to-use solution” from Biscoglio and Marchetti (2015) define software quality evaluation plans in a conference paper. 應用品質管理中的 7Ms Model 來涵蓋軟體開發中的行為 7Ms Model 是品質管理中常使用的工具，其中的 M 可視為是品質管理中的基本要素，其中包含: Machine, Method, Material, Manpower, Management, Milieu, Measurement 4. Quality in Use 第4、5節則對 Table 1. 的結構來依序查看各個特性的定義，並分析與評估各個特性，若有需要則進一步評估子特性。 4.1 Achievement of Needs Effectiveness(效果), Efficiency(效率) ISO/IEC 25010 不包含對應用程式的具體功能與特色的評估，它們的價值僅能由採購方的組織的需要來評估。 因此這裡的效果與效率僅為當用戶實現特定目標時的指標。 Example: Apple Inc. 在定義 App store 時將這一需求描述為: “If your App doesn’t provide some form of lasting entertainment value, or is just plain creepy, it may not be accepted.” ; 「如果你的應用程式沒有提供持久的娛樂價值，或者很令人不舒服，它可能不會被接受。」 這就與 ISO/IEC 標準所討論的 stated and implied needs 有所偏差。 4.2 Freedom from Risk 講述對於不同行業上產品應該尊崇法律和法規的要求，尤其是它們可能在不同的時間，由不同的機構所制定因此經常是複雜並易發生衝突的。 但是產品供應者應該要了解在銷售區域內使用其產品的所有限制，並明確說明使用限制與假設。 論文中認為應該回復 ISO/IEC 過去的 Compli-ance 子項目已涵蓋對於法律、監管與合同相關的合符規範性要求。 5 Product Quality 這些關於 Product Quality(產品品質)的特正主要是開發者/供應商或在技術上有更多參與的購買者所關心的。 Functional suitability(功能適用性) 其子項 Completeness(完整性), Correctness(正確性), Appropriateness(適合性)這些都是開發者所進行的先行評估，但是最終評估還是在購買方的手上。 Performance efficiency(性能效能) 對於軟體開發上所進行的評估與測試可能不是最終交付後的實際運行環境，因此在開發期間進行的軟體產品測試可能無法完全反映最終交付後的表現。 5.1 Compatibility(兼容性) Co-existence(共存性)指產品能否與其他在同一平台上運行的產品協調共存，並使用所提供的服務共享資源，並且不要影響其他服務。 Interoperability(互相操作性)指產品與其他系統、產品或組件之間是否能夠交換信息。如在作業系統檔案區域中將檔案以滑鼠拖拉至產品檔案上傳區域。 5.2 Usability(易用性) 易用性下的子特性可以被理解為用戶如何識別一個產品是否適合它們的程度，所以包含了供應者如何描述系統，說明文件等等。 5.3 Reliability(可靠性) 可靠性關注的是產品的穩定性和持續性，需要考慮多種因素，包括硬件故障、人為錯誤、系統崩潰、網路中斷等等。 5.4 Security(安全性) 產品要確保如控制存取, 確保資料完整性, 保護機密等等的機制，例如 Apple store 上因為 APP 大多經由批准過因此基本保證使用者不會在商店中遭遇惡意軟體。 5.5 Maintainability(可維護性) 可維護性定義為能被預期的使用者有效的修改與維護的程度 Analyzability(可分析性)包括可預期的評估變化的影響，判斷缺失和故障，也就是在工作前的能做的評估。與現場工作中能注意到的問題，這需要有效的識別錯誤機制。 Testability(可測試性)可測試性是很重要的，其中包含 low-level 中的組件測試、單元測試。與 high-level 的測試(通過開發和維護回歸測試套件來確認服務沒有下降級別， 即性能下降至比之前更差的狀態)。 Extensibility(可擴張性) 是在先前[20]曾提出過一個應該增加的主要特性，提出模塊化和物件導向的軟體可以更容易的擴展， 並且 Tested classed 可以直接集成到現有系統中，無須重頭開始建構或測試整個系統。 [20] Siakas, K.V., Georgiadou, E.: PERFUMES: A Scent of Product Quality Characteristics. In: International Software Quality Management Conference, pp. 211-20. BCS, London (2005) 5.6 Portability(可移植性) 傳統上軟體的可移植性是指開發者對於 Source code 的再編譯、建構等。對於指定平台購買指定的版本，當轉移到新的平台時需要購買新的實現，並將數據、配置等轉移到新的環境中。 ISO/IEC 25010 的可移植性包含購買的產品能在預期的平台上運行，包含插件兼容，虛擬的或基於雲的環境。 Replaceability(可替換性)則指現有產品的一個版本被另一個版本替換，開發者應該考慮更廣泛的服務問題，如現有數據如何遷移與減少使用者介面的改面。 商業慣例是向前兼容就是任何新版本應該保持所有以前的功能與特性，沒有倒退。 5.7 Supportability(可支援性) 作者認為應該在 ISO 中加入的特性，與5.5 Maintainability類似是預測未來的一個因素，但與可維護性不同的是這代表的是一些開發方對購買者所需要的支援， 如: 緊急求救電話，遠程診斷不接觸 Source code 或其他私密訊息的支持; 信息或工具。這是開發方在競爭市場上提供高品質產品和服務的關鍵之一。 6. Other Characteristics of the Product at Delivery 作者認為在 SQuaRE 中其他重要的特性與影響 6.1 Honesty and Openness 有明確的要求要進行開放和誠實的溝通，既針對考慮購買的買方，也針對下載應用的使用者。在SQuaRE品質模型中，誤導性的文件並未被考慮進去。 如蘋果公司拒絕某些應用的原因包括: 「應用未能如開發人員所宣稱的那樣運作」 「應用包含未公開或與描述不一致的隱藏功能」 「旨在提供詐欺或假功能的應用，但未明確標示」。 6.2 Product Maturity 產品的成熟度生命週期: initial development(初期開發), active evolution(積極發展), servicing(維護與服務), phase out(淘汰). 追求可靠性的購買者更喜歡第三階段的產品，而更關注產品特性與功能的購買者可能更喜歡第二階段的產品。 一個產品會隨著時間的變得越來越複雜，除非進行減少複雜度的維護工作。在[23]中顯示了過去產品維護對於未來品質的強烈影響。 [23] Lehman M.M., Perry D.E. Ramil J.F.: Implication of Evolution Metrics on Software Maintenance. In: International Conf on Software Maintenance, pp. 208-17, IEEE (1998). doi: 10.1109/ICSM.1998.738510 7. In-life Experience, post-Deployment 最終對購買者來說重要的是產品在實際使用上的表現，但這個表現必須等到部屬或購買後才能知曉。 SQuaRE 目前沒有涉及這些方面，這部分都是上線後流程，如果買家要求產品供應商以協議的價格提供所有這些支持服務，則需要建立全面的額外服務品質指標。 7.1 Customer Support by Supplier 儘管支援服務是一種部署後活動，但供應商的支援能力仍然是軟體產品評估中重要的一個方面，即使它被明確地排除在 ISO/IEC 250xx 系列的範圍之外因為這只受到產品技術的輕微影響，應該至少要被提及。 7.2 In-life Maintenance 購買者需要知道供應商的政策和流程，以便預測和規劃維護產品的工作與成本。例如: 承諾修復錯誤，發布錯誤修復與新版本的品質與變化等。 8. Conclusions &amp; 9. Relation to SPI Manifesto 作者最主要的貢獻是討論了 ISO/IEC 25010 的範圍，並進一步的討論: 合法，法規與合約遵循性、可擴展性、支持性、誠實描述、產品成熟度和包括供應商客戶支持和部署後的維護在內的活動。 以此使 ISO/IEC 25010 成為更全面的品質模型，可用來評估規範是否應該改進、維持或忽略某些維度的基礎。 SPI Manifesto: Base improvement on experience and measurements. Pries-Heje J., Johanson J., (eds.): SPI Manifesto, http://www.iscn.com/Images/SPI_Manifesto_A.1.2.2010.pdf last accessed 2018/05/28 NOTE Last edit 04-21-2023 12:32"
  },"/jekyll/2023-04-13-software_standard.html": {
    "title": "Note | Standard - ISO/IEC",
    "keywords": "software software_qualitiy standard Jekyll",
    "url": "/jekyll/2023-04-13-software_standard.html",
    "body": "ISO/IEC 9126 Software engineering — Product quality was an international standard for the evaluation of software quality. Intorduction 如果想得到高品質的軟體，就要先能夠對於軟體產品的品質能夠進行完整的描述，因此國際標準組織發布的ISO/IEC就是常被引用的軟體產品品質(Software Product Qualitiy)標準。 這個標準的目標是去應對一些已知的人類偏見，這些偏見將可能會對軟體開發專案的交付和認知產生不利影響。這些偏見包括在項目開始後更改優先順序[1]或沒有任何清楚的成功[2]定義。 所以通過明確說明與確定項目的優先順序，將抽象的概念轉化為可衡量的數值或指標。並且輸出數據可以根據架構X(Schema X)[3]進行驗證，不需要任何干預。 目前最新的標準是 ISO/IEC 25010:2011 使用兩個模型來描述分別為 使用品質(Quality in Use) 與 產品品質(Product Quality)。 優先順序: 優先順序指的是軟體開發中各個任務、功能、需求等進行排序，以確定其相對重要性和優先級。 成功: 就是對於項目目標的清晰定義和明確衡量標準的確立，以便能夠確定項目是否已經達到預期的成效與目標。 架構X(Schema X): 任何特定的數據架構或格式，以驗證輸出數據是否符合標準。 Product Quality 功能適用性（Functional suitability） 功能完整性（Functional completeness）: 產品是否完整涵蓋了所有指定目標與任務的程度。 功能正確性（Functional correctness）: 產品提供具有所需精度或者相符的結果的程度。 功能適合性（Functional appropriateness）: 產品是否具有適當的功能完成指定工作的程度。 性能效能（Performance efficiency） 時間行為（Time behavior）: 指一個產品或系統在執行其功能時的反應與吞吐率。 資源利用率（Resource utilization）: 產品在執行功能時使用的資源數量與類型。 容量(Capacity): 指產品或系統參數的最大負載或工作量限制。 相容性（Compatibility） 共存（Co-existence）: 指一個產品在與產品共享環境與資源時，能有效執行其功能的程度，不會對其他產品產生負面影響。 互相操作性（Interoperability）: 指兩個或多個系統，產品間可以互相交換訊息並使用的程度。 可靠性（Reliability） 成熟度（Maturity）: 產品在正常運行下滿足可靠性要求的程度。 可用性（Availability）: 產品在運行下可操作與可訪問性的程度。 容錯能力（Fault tolerance）: 盡管存在硬體或軟體故障，但軟體系統、產品或組件依然按造預期的運行的程度。 可恢復性（Recoverability）: 當發生中斷或故障時，軟體或系統能夠直接回覆受影響的數據並重新建立系統所需狀態的程度。 易用性（Usability） 被識別的適當性（Appropriateness recognizability）: 用戶能夠識別產品或系統是否符合它們需求的程度。 易學習性（Learnability）: 產品或系統能夠使用戶在緊急情況下學習如何有效的使用他的程度。 吸引力（Operability）: 產品使用者能容易操作，控制與使用的程度。 用戶錯誤保護（User error protection）: 產品保護用戶不出錯的程度。 用戶介面美觀(User Interface aesthetics): 產品提供用戶介面美觀和滿意的程度。 可訪問性(Accessibility): 產品能使所有使用者都能使用的程度，如聽障、視障等特殊需求等。 安全性（Security） 保密性(Confidentiality): 確保產品能確保資料只能被授權的人員訪問的程度。 完整性(Integrity): 產品、系統資訊在處理的過程中不被未經授權就修改，保持完整與正確的程度。 抵抗賴性(Non-repudistion): 確保產品在能證明已經發生的事件，以便未來行為不能被當事人抵賴的情況。 可追溯性(Accountability): 確保系統能追蹤與記錄所有活動與事件，以便追蹤與追責。 真實性(Authenticity): 確保資訊、系統、用戶的真實性與可信性，避免假冒、詐欺、冒用等問題的程度。 可維護性（Maintainability） 模塊性(Modularity): 產品或系統由離散組件所完成，當組件產生更改對其他組件產生最小影響的程度。 可重複性(Reusability): 產品中的元件(類別、函數等)可被多次使用降低開發時間的程度。 可分析性(Analyzability): 產品可被容易的分析，發現潛在的問題或缺陷的程度。 可修改性(Modifiability): 產品可以容易地進行修改，並且這些修改可以不影響系統的其他部分。 可測試性(Testability): 產品可以容易地進行測試，以確保它的正確性和穩定性。 可移植性（Portability） 適應性(Adapatability): 產品是否能適應不斷發展的硬體；軟體或使用環境的程度。 易安裝性(Installability): 產品能否在不同環境下安裝與配置並進行運行的程度。 可替換性(Replaceability): 在相同環境中用戶能找到其他相同目的的指定軟體的程度。 Quality in Use 效果（Effectiveness） 用戶實現特定目標的準確性和完整性。 效率（Efficiency） 相對於用戶實現目標的準確性和完整性，所耗費的資源。 滿意度（Satisfaction） 實用性（Usefulness）: 指用戶對實現實用目標的實現與使用結果和使用後果的滿意度。 信任性（Trust）: 用戶或其他相關者對於產品或系統按預期行為的信任程度。 愉悅性（Pleasure）: 指用戶從滿足個人需求中獲得的愉悅程度。 舒適性（Comfort）: 使用者在使用過程中，對於其身體上的舒適感受的滿意程度。 無風險性（Freedom from Risk） 減輕經濟風險(Economic Risk Mitigation): 產品或系統在預期使用環境中減輕財務狀況、有效運營、商業財產、聲譽或其他資源的潛在風險的程度。 降低健康和安全風險(Health and Safety Risk Mitigation): 產品或系統在預期使用環境中降低對人體的潛在風險的程度。 降低環境風險（Environmental Risk Mitigation）: 產品或系統在其預期使用環境中減輕與環境相關的潛在風險的程度。 涵構覆蓋（Context coverage） 涵構完整性（Context Completeness）: 在所有指定的使用環境中，產品或系統可以有效、高效、無風險和滿意地使用的程度。 靈活性（Flexibility）: 產品或系統在需求中最初指定的範圍以外的環境中可以有效、高效、無風險和滿意地使用的程度。 Advanced John Estdale(2018), Applying the ISO/IEC 25010 Quality Models to Software Product, IEEE 這篇論文則對標準中的各項特性做了說明與更進一步的探討，閱讀筆記 Note Link NOTE Last edit 04-17-2023 12:32"
  },"/jekyll/2023-02-04-algorithm_kmp.html": {
    "title": "Leetcode | Algorithm - KMP",
    "keywords": "algorithm string Jekyll",
    "url": "/jekyll/2023-02-04-algorithm_kmp.html",
    "body": "Notes: KMP (Knuth Morris Pratt). reference here. Introduction 字串尋找演算法 (KMP), 可在一個字串中尋找另一個字串的出現位子, 使用這個算法的平均時間複雜度是 O(n+m), 其中 n 為字串的長度, m 為模式串的長度. Brute Force 我們先看看暴力解如何去解，假設有兩個字串: text: “aabaabaaf” pattern: “aabaaf” 最值觀的寫法就是從 text 開始做 for loop, 接下來逐字匹配 text, 如果 pattern 找到匹配失敗的 text 才往前移動 1 直到能將 pattern 匹配完或者 traverse text 結束. 在這種寫法下時間複雜度為 O(m*n), 因為至少每個 text 的 element 都要經過一次 pattern 的匹配過程. 也可以想像成一個滑動的窗口, 窗口的大小為 pattern size. 28. Find the Index of the First Occurrence in a String 中的暴力解法. func strStr(haystack string, needle string) int { var result int = -1 if len(haystack) &lt; len(needle) { return result } for i := 0; i &lt; len(haystack); i++ { if checkStr(haystack, needle, i) { result = i return result } } return result } func checkStr(haystack, needle string, index int) bool { for i := 0; i &lt;= len(needle); i++ { if i == len(needle) { return true } if index &gt;= len(haystack) { return false } if haystack[index] == needle[i] { index++ } else { return false } } return false } KMP Algorithm Diagram reference 因此我們可以將暴力解用圖解來展開： 那我們就能想像如何減少不必要的搜尋, 首先如下兩張圖: 如果右移後的 overlap 都無法比對, 下次比對時我們都可以先跳過這些 overlap. 但是看下面這個例子, 這次比對到的目標中含有符合的子串. 因此我們就有必要進一步的比對, 那這段 overlap 要如何找出來? 假設已經比對成功的部分是 p’, 他是 p 的一個子串, 那重疊部分就是 p’ tail 和右移 p’ 的head. 因此我們可以說 結合以上的兩種方式, 我們可以看到這個算法最終的樣子: Last Edit 04-02-2023 19:28"
  },"/jekyll/2023-01-12-gomoku_ai.html": {
    "title": "Note | Gomoku AI - Game Tree",
    "keywords": "algorithm game Jekyll",
    "url": "/jekyll/2023-01-12-gomoku_ai.html",
    "body": "練習基礎AI演算法的入門題目，博弈樹搜尋與啟發式演算法，順手完成一個 GUI 小遊戲。 Introduction 傳統的AI演算法題目，以非神經網路的方式來嘗試AI撰寫。睡不著乾脆更新下Blog，至少忙起來能讓我轉移一些注意力，順便做個筆記。 博弈樹(Game Tree)其實就是一種將賽局中所有可能展開後的 Tree，那其中的每個 Node 就代表著遊戲進行中的某個狀態， 那我們以 Tic-Tac-Toe (井字棋)來看，就會有 26830 種遊戲過程。 Tic-Tac-Toe 的棋盤大小不過才 3x3 就有 26830 種可能，那五子棋的棋盤為 15x15 一個簡易的算法是 15! 幾近是天文數字。 如果想以全部遍歷的方式來找出最佳解幾乎是不可能做到的事，那這時就需要一些策略去找出最佳路徑，所以我們會用到幾種算法。 Maximin algorithm. (對抗性的搜尋算法) Alpha Beta pruning. (剪枝算法) Heuristic. (啟發式算法) Maximin algorithm Maximin algorithm (極大極小值演算法)，是一種找出失敗的最大可能性下的最小值的演算法，這是 wikipedia 上的解釋。 簡單來說在一個五子棋博弈樹中，必然有兩個不同的玩家互相下棋，故博弈樹我們也可以分成玩家層與AI層來看待，因此在搜尋的過程中我們要去找尋每一層的最有利狀態， 最後去找到玩家下的最好的狀態下，AI能下出的最佳步驟。 the source picture 其實看上圖就能發現其實就跟 Max-Min-Heap 很相像，只是今天 Heap 是從下往上， 但 Tree 是從上往下，一個中序遍歷的搜尋方式。在搜尋過程中我們要去找到都是極大或極小的路徑， 但是如果我們真的去遍歷整個棋盤，時間複雜度將為 O(b2)， 在棋盤為15*15，深度為4的情況下，2254是一個非常慢的演算法。 Alpha Beta pruning 但是即便我們能做到棋盤的對抗搜尋，但是搜尋時間還是很慢，因此我們需要去做到剪枝的動作， 放棄不可能的分支做搜尋，把希望放在更有可能的分支上以做到更深的深度。在最糟的情況下， 時間複雜度將為 O(b2)，而在最佳的情況下有機會達到 O(sqrt(bd))， 實作上我們就是在遞迴時，如果當前層數為極大層，但是下下層出現一個比最大值還要小的節點我們就直接剪掉， 因為我們要找的是極大值，就不用去考慮更小的值了，同理運用在極小層。 Wikipedia中圖的第三層中的 7 節點其實也是要剪掉的，圖有錯誤。 Heuristic 但是即使我們能做到剪枝搜索時間還是平均需要 O(b3d/4)，但同時我們也知道初始的搜尋節點很重要， 如果一個棋盤如下圖，我們以一個2D Array來實現這個棋盤狀態，像是 x, y = 0, 0這樣的位置如果不會影響大局完全沒有搜尋的必要。 State Operate 五子 直接返回 活四 直接返回 活三 … 死三 … 因此我們可以在尋找搜尋節點以有鄰居的空位為主，並且加入一些評分機制來對這些位置排序： 把每次搜尋的位置 print 出來來觀察搜尋的順序與影響。除去五子活四這種直接將軍的局面， 剩下的依照分數排序來做搜尋，這樣我們能更快的找到最佳的路徑， 分數不符的路徑就將會被剪掉，把時間用來做到更深的搜尋層數。 要記住即便使用了啟發式函數，但是只要局面變得複雜，搜尋速度同樣會下降很多， 畢竟每做一個搜尋就是需要付出 Pd 的時間消耗，因此排序並消除不重要位置的步驟就很重要。 Note 寫輔助函數時的注意事項 在寫這些輔助函數的時候，要盡量減少做整個棋盤的搜尋動作，同時可以嘗試將棋盤視為字串， 這樣就能以 Regex 來處理連線確認將會大幅加快執行速度，尤其是如果你的棋盤 評估函數要仔細設計 評估函數；尋找的棋形；搜尋深度；是最直接的影響棋力的選項，如果AI的落子有問題， 通常應該往這幾個方向做修改，例如搜尋深度與評估函數設計不好就有可能使AI自殺的情形發生。 NOTE 之後更新，目前已完成一個簡易的算法在Github，希望能在過年前把它做到一個更滿意的狀態。"
  },"/jekyll/2022-11-24-git_commit.html": {
    "title": "Note | Commit Message Format",
    "keywords": "github tool Jekyll",
    "url": "/jekyll/2022-11-24-git_commit.html",
    "body": "說明 Git 提交時應注意的 Commit message format，建立良好的規範才能有效的合作 做 issue 的時候不應該一次 Commit 所有變動！應該獨立每個 Commit 不同意義的異動，這樣才能使 Commit 快速閱讀與程式碼間的關係。 每次 Commit 都是針對異動做說明，Why &amp; What。 每次 Commit 加上 issue 編號，方便追蹤後續問題。 Basic format Header: type: 代表 commit 的類別：feat, fix, docs, style, refactor, test, chore，必要欄位。 scope 代表 commit 影響的範圍，例如資料庫、控制層、模板層等等，視專案不同而不同，為可選欄位。 subject 代表此 commit 的簡短描述，不要超過 50 個字元，結尾不要加句號，為必要欄位。 Body: Body 部份是對本次 Commit 的詳細描述，可以分成多行，每一行不要超過 72 個字元。 說明程式碼變動的項目與原因，還有與先前行為的對比。 Footer: 填寫任務編號（如果有的話）. BREAKING CHANGE（可忽略），記錄不兼容的變動，以 BREAKING CHANGE: 開頭，後面是對變動的描述、 以及變動原因和遷移方法。 type 需規範好有哪些類別： feat: 新增/修改功能 (feature)。 fix: 修補 bug (bug fix)。 docs: 文件 (documentation)。 style: 格式 (不影響程式碼運行的變動 white-space, formatting, missing semi colons, etc)。 refactor: 重構 (既不是新增功能，也不是修補 bug 的程式碼變動)。 perf: 改善效能 (A code change that improves performance)。 test: 增加測試 (when adding missing tests)。 chore: 建構程序或輔助工具的變動 (maintain)。 revert: 撤銷回覆先前的 commit 例如：revert: type(scope): subject (回覆版本：xxxx)。 Example 一個簡單的 feat 範例 #Feat Example feat: message 信件通知功能 因應新需求做調整： 通知和 message 都要寄發每日信件， 通知和 message 都用放在同一封信裡面就好， 不然信件太多可能也不會有人想去看。 調整項目： 1. mail_template.php，新增 message 區塊。 2. Send_today_notify_mail.php，新增 取得每日 Message 邏輯。 3. Message_model_api.php，新增 $where 參數，以便取得每日訊息。 4. Message_api.php、Message_group_user_model_api.php，新增 *取得訊息使用者* 邏輯，以便撈取每日訊息。 issue #863 NOTE 只會寫程式只能代表你是一個 Coder，能跟一群人一起寫程式才是一個 Engineer。 What’s the Difference Between a Programmer, Coder, Developer, and Software Engineer?"
  },"/jekyll/2022-11-08-ai_csp.html": {
    "title": "Note | Constraint Satisfaction Problem",
    "keywords": "ai algorithm Jekyll",
    "url": "/jekyll/2022-11-08-ai_csp.html",
    "body": "Introduction to Artificial Intelligence Week 6 Notes CSPs Introduction Constraint Satisfaction Problem 其定義為一組物件，而這些物件需要滿足一定的限制或條件，而這個問題可能有很多的解。CSP 問題經常表現出高複雜性，需要結合啟發式搜尋和搜尋方法來在一個合理的時間內解決問題。 主要解法：通過識別違反約束的變量與值的組合消除大規模的搜索空間。 CSP related Linear programming Nonlinear progaramming Numerical analysis CSP application Operations research Network flows optimization problems CSP Define 定義一個 3-tuple(X, D, C) 其中 X = {X1, …, Xn} Finite set of variables. D = {D1, …, Dn} Nonempty domain of possible values for each variable. C = {C1, …, Cn} Finite set of constraints, Each constraint Ci limits the values that variables can take. Example Map coloring 就是一個經典的 CSP。每個區域即是變數，顏色便是值域，相鄰區域顏色不同是約束。 其中關於 Constraint 可被劃分為: unary constraint: 只約束單個 variable 的取值。如 SA 不能被染成綠色。 binary constraint: 兩個 variable 相關的約束。如 SA 不能與 WA 的顏色相同。 global constraint: 全局約束。如 Alldiff, 即約束中所有 variable 皆需取不同的值。 Arc Consistency example Backtracking search for CSPs 回朔搜索，用於 DFS 中。他每次為 Single variable 進行取值，當沒有合法的值可給某個 variable 時就進行回朔。 為使 search 變的高效，須解決以下問題: 下一步應該給哪個 variable 取值? 按照什麼順序取值? 每步 search 應該做怎樣的推理? Variable select: Minimum remaining values (MRV) 最少剩餘值啟發式: 選擇合法取值最少的 variable 開始。這樣選擇的 variable 可能很快地導致失敗，從而進行回朔。 Degree heuristic 鄰接度啟發式: 選擇與其他未取值 variable 約束最多的 variable 來試圖降低未來可能的分支。 Value order Least constraining value (最少限制值): 選擇 value 時優先選擇給鄰居 variable 留下最多選擇的分支。 Inference in CSPs 在 CSP 問題中，Algorithm 可以進行搜索，也可以做約束傳播 (The constraint propagation) 的推理 約束傳播: 使用約束來減少一個 variable 的合法取值範圍，從而影響與此 variable 有約束關係的另一個 variable 的取值。 (局部相容性) Node Consistency (節點相容) Single variable (In CSP Single node) 值域中的所有取值滿足他的 unary constraint. if SA = NA = {Red, Blue, Green}; SA != Blue, NA != Red, SA = {Green, Red}, NA = {Blue, Green}; Arc Consistency (弧相容) CSP 中某 variable range 所有取值滿足該 variable 的所有 binary constraint. 最常用的算法為 AC-3, 算法流程大致如下: Get all the constraint and turn each one into two arcs. Expmale: A &gt; B becomes A &gt; B and B &lt; A. Add all the arcs to a queue. Repeat until the queue is empty: 3.1. Take the first arc (𝑥, 𝑦), off the queue (dequeue). 3.2. For every value in the 𝑥 domain, there must be some value of the 𝑦 domain. 3.3. Make 𝑥 arc consistent with 𝑦. To do so, remove values from 𝑥 domain for which there is no possible corresponding value for 𝑦 domain. 3.4. If the 𝑥 domain has changed, add all arcs of the form (𝑘, 𝑥) to the queue (enqueue). Here 𝑘 is another variable different from 𝑦 that has a relation to 𝑥. Forward Checking 向前檢驗是最簡單的推理形式，只要 X variable 被賦值了，就向前檢驗過程對他做 Arc Consistency. 檢查對於每個通過約束與 X 相關的, 未賦予值的 Y variable, 從 Y 的 range 中消去與 X 不相容的值。 NOTE 待更新"
  },"/jekyll/2022-11-07-network_urat.html": {
    "title": "Note | Basic UART Concept",
    "keywords": "protocol Jekyll",
    "url": "/jekyll/2022-11-07-network_urat.html",
    "body": "修網路實作的時候，給學弟妹講解 URAT 跟怎麼在 Arduino 上實作準備的一些教材，簡單介紹下 UART 怎麼在 Arduino 中進行資料傳遞，實驗使用單芯線進行通訊。 How to transfer data between two computers? 5 Volts logic: Signal on transmission medium Metal : Square wave &amp; Sine ware Optical fiber : Light square ware Wireless : Electromagnetic waves The Universal Asynchronous Receiver/Transmitter (UART) UART這種簡單的通訊方式已經存在了幾十年，依然廣受歡迎。 In a world where technology can become obsolete very quickly Still enjoys immense popularity. Asynchronous communication UART 是非同步通訊，所代表的是通訊中兩個byte之間的空隙是不固定的，而一個byte中的bit間隔是固定的。因此發送端與接收端都要有相同的 UART 設定。 Capabilities and Characteristics a basic UART system provides robust, moderate-speed, full-duplex communication with only three signals: Tx (transmitted serial data), Rx (received serial data), and ground. 一個基本收送的UART傳輸，僅需要三個端口Tx, Rx, GND。但在這之前的前提是 Rx, Tx, 在相同的數據傳輸頻率。 Key Terms Start bit: The first bit of a one-byte UART transmission. It indicates that the data line is leaving its idle state. The idle state is typically logic high, so the start bit is logic low. The start bit is an overhead bit; this means that it facilitates communication between receiver and transmitter but does not transfer meaningful data. Stop bit: The last bit of a one-byte UART transmission. Its logic level is the same as the signal’s idle state, i.e., logic high. This is another overhead bit. Start bit 代表空閒結束，Srart bit 僅代表開始，不具實際數據。 Stop bit 代表傳輸結束，電位拉高等待下一次 Start。 上圖可以發現發送 10 bit 的資料但其實真正的數據僅有 8 bit。 Baud rate: The approximate rate (in bits per second, or bps) at which data can be transferred. Example: 9600-baud system，即 1 bit 需要 1/(9600 bps) ≈ 104.2 µs，注意不是實際上每秒傳送 9600 資料， 實際上有開銷 bit 的消耗。 Check bit(Parity bit) Parity bit: An error-detection bit added to the end of the byte. Odd or Even 如果要設定校正位，就多傳送一個Bit，並預先設計好 Odd or Even，如今天要傳送 00001110 而 even 即 校正為 1 這樣就會有偶數個 1。 可以看到如果加入 Parity bit，想要發送一個 byte 的成本也增加了 1 個 bit。 Synchronizing and Sampling the UART interface does not use a clock signal to synchronize the Tx and Rx devices. So how does the receiver know when to sample the transmitter’s data signal? 因為是非同步通訊，所以接收器的 clock 完全獨立於發送器 clock，只需要知道 Start bit 的開始位置後就能依照固定的 clock 進行接收。 Conclusion 所以當今天要設計一個UART單方向傳輸，僅用一條線就可以完成，以預設的頻率收接下來的 8 bit，當電位拉高代表一次傳送的結束，等待下次開始。 這部分可以設計一個 Finite-State Machine 來完成發送與接收的程式設計。 Reference Back to Basics: The Universal Asynchronous Receiver/Transmitter (UART) Practice One-Line-Communication"
  },"/jekyll/2022-11-05-docker_jekyll.html": {
    "title": "Note | Docker Build Github Pages",
    "keywords": "github tool Jekyll",
    "url": "/jekyll/2022-11-05-docker_jekyll.html",
    "body": "說明如何使用 Jekyll docker image 在不用熟悉 Ruby 與相關套件管理下，生成靜態文件。 之前就想找一個能用 Markdown 寫筆記的地方，過去都是寫在 Github 的 Repositories 裡面但是檔案一多起來想整理也不方便，那就自己寫個 Blog 當作紀錄， 剛好就趁這個機會把這次的內容當作第一篇紀錄。 Jekyll 是一個用 Ruby 寫的簡單靜態網頁生成器，但是目前我幾乎都是用 Lab 的電腦做事，平時也是遠端到上面，所以很直覺的就想用 Docker 來處理環境， 之後跑腳本把生成好的文件在推上 Github 就可以做好一次更新了。 Required: Docker image Jekyll/Jekyll Html, Javascript, CSS 剛開始就先找個模板來用，Jekyll themes上就有很多可以用的模板來用，像我用的就是使用 GitBook 風格的模板，同時有搜尋功能之後文章的找尋也會比較方便。 找到模板之後去把他 forks 到自己的儲存庫，clone 下來就可以開始修改了。 Docker Jekyll Jekyll 官方有一個 Docker image 所以拉這個 image 就可以了，裡面 Readme 教學寫得還蠻詳細的，只要把模板 volume 到 container 裡面就可以執行 Jekyll 生成。第一次運行安裝套件等等會花一點時間，之後啟動容器速度就快很多了。 之後再簡單寫個 bash script 這樣一個能快速生成的 Jekyll 環境就搭建完成了。 jekyll build 直接生成網頁 jekyll serve 生成網頁後運行在 localhost:4000 docker run \\ -v $WD:/srv/jekyll:z \\ -v /etc/localtime:/etc/localtime:ro\\ -p 4000:4000 \\ --name jekyll \\ -it jekyll/jekyll \\ jekyll serve 2&gt; /dev/null || docker start jekyll &amp;&amp; docker attach jekyll; Customize 之後就等文件生成好，同時記得設定 Github pages publishing source, 把發布源改到生成的目錄。這樣 github.io 的內容就直接指向這個目錄。然後就是一些自定義的小修改，這裡只要會一點 Js, Html 就可以搞定。 像我用的模板本來是舊的 post 優先，稍微改排序，預設字體，加入時間註記，這樣一個簡單的靜態網頁就完成了。 Change default font size: gitbook-plugin-fontsettings \"pluginsConfig\": { \"fontsettings\": { \"size\": 1, } } Add date in post: _layout/post.html change sort method: _includes/toc-date.htnl NOTE 之後想到要修改的再更新吧，可能加入留言系統、標籤之類的，目前這樣的靜態網頁我就很滿意了。"
  },"/jekyll/0000-01-01-virtual_machine_tool.html": {
    "title": "Tool | Virtual Machine",
    "keywords": "linux tool Jekyll",
    "url": "/jekyll/0000-01-01-virtual_machine_tool.html",
    "body": "Notes How to using virtual machine tool. 1. ESXI 1.1 ESXI 5.5 import OVF Environment: VMware Player 16, ESXI 5.5 因為 5.5 是非常老舊的版本了，所以在匯入 OVF 檔案時會有很多問題，這裡記錄下如何解決 因為 5.5 不支援 SHA256，改用 SHA1 的方式匯出 OVF 檔案 ovftool.exe --shaAlgorithm=SHA1 /path/to/the/original/ova_file.ova /path/to/the/new/ova/file-SHA1.ova Unspported hardware family ‘vmx-18’ .ovf 找到 &lt;VirtualSystemType&gt;vmx-18&lt;/VirtualSystemType&gt; 改成 &lt;VirtualSystemType&gt;vmx-8&lt;/VirtualSystemType&gt; 檔案 ovf_file.ovf 未通過完整性檢查，可能在傳輸過程中已損毀。 .mf 找到 SHA1(ovf_file.ovf)= 5ba21a516c7b499e22c3463e4bd0596ab5336c4e 刪除 No support for the virtual hardware device type ‘20’ ESXI 5.5 不支援 NVME Controller，下面整段替換 &lt;Item&gt; &lt;rasd:Address&gt;0&lt;/rasd:Address&gt; &lt;rasd:Description&gt;NVME Controller&lt;/rasd:Description&gt; &lt;rasd:ElementName&gt;nvmeController0&lt;/rasd:ElementName&gt; &lt;rasd:InstanceID&gt;3&lt;/rasd:InstanceID&gt; &lt;rasd:ResourceSubType&gt;vmware.nvme.controller&lt;/rasd:ResourceSubType&gt; &lt;rasd:ResourceType&gt;20&lt;/rasd:ResourceType&gt; &lt;/Item&gt; &lt;Item&gt; &lt;rasd:Address&gt;0&lt;/rasd:Address&gt; &lt;rasd:Description&gt;SCSI Controller&lt;/rasd:Description&gt; &lt;rasd:ElementName&gt;scsiController0&lt;/rasd:ElementName&gt; &lt;rasd:InstanceID&gt;3&lt;/rasd:InstanceID&gt; &lt;rasd:ResourceSubType&gt;lsilogic&lt;/rasd:ResourceSubType&gt; &lt;rasd:ResourceType&gt;6&lt;/rasd:ResourceType&gt; &lt;/Item&gt; invalid configuration for device ‘0’ 找到 &lt;vmw:Config ovf:required=\"false\" vmw:key=\"videoRamSizeInKB\" vmw:value=\"262144\"/&gt; 改成 ` ` 這樣應該就能成功部屬了，但是詳細會有什麼問題還沒測試過 2. Virtualbox 2.1 Vboxmanage Virtual box指令操作 手動相關指令說明: 新建一個名為「New VM」的虛擬機器 vboxmanage createvm -name 「New VM」 -register 設定「New VM」的記憶體是128MB並開啟acpi 設定第一開機碟為dvd 以及新增一個網路介面 vboxmanage modifyvm 「New VM」 -memory 「128MB」 -acpi on -boot1 dvd -nic1 intnet 建立一個虛擬硬碟名為「newhd.vdi」 大小為 4000MB vboxmanage createvdi -filename 「newhd.vdi」 -size 4000 -register 將「New VM」的 hda 設定為「newhd.vdi」虛擬磁碟 vboxmanage modifyvm 「New VM」 -hda 「newhd.vdi」 將在\"/home/file/iso.iso\"的ISO映像檔 設定到 名為 dvd的光碟映像檔庫 vboxmanage registerimage dvd /home/file/iso.iso 設定名為「New VM」的 dvd裝置為 /home/file/iso.iso vboxmanage modifyvm 「New VM」 -dvd /home/file/iso.iso 設定「New VM」所使用的 VRDP 的連接Port為 3390 vboxmanage modifyvm 「New VM」 -vrdpport 3390 啟動 VRDP VBoxVRDP -startvm 「New VM」 ----- List function 查詢目前vbox上有設定多少個vm vboxmanage list vms 查看支援的 OS Type vboxmanage list ostypes 查看運行中的 VM vboxmanage list runningvms 其它可以list的指令 vboxmanage list hostdvds vboxmanage list hostinfo vboxmanage list hddbackends vboxmanage list systemproperties vboxmanage list dhcpservers vboxmanage list hdds vboxmanage list dvds 指令啟動vm vboxmanage startvm \"VM name\" --type headless (用背景啟動，不加上--type headless參數可能會有錯誤!!) 2.2 Autostart Virtualbox VMs How to autostart virtual machine by systemctl. reference Create a systemd service file. sudo vim /etc/systemd/system/$service-filename [Unit] Description=VBox Virtual Machine %i Service Requires=systemd-modules-load.service After=systemd-modules-load.service [Service] Restart=always RestartSec=3 User=%u Group=vboxusers ExecStart=/usr/bin/VBoxHeadless -s %i ExecStop=/usr/bin/VBoxManage controlvm %i savestate [Install] WantedBy=multi-user.target change %i to you virtual machine UUID or name. %u is you virtual machine manager username. reload systemd service file and enable service. sudo systemctl daemon-reload sudo systemctl enable $service-filename sudo systemctl start $service-filename check virtual machine is runing vboxmanage list runningvms Last Edit 10-01-2023 12:22"
  },"/jekyll/0000-01-01-linux_config.html": {
    "title": "Tool | Linux Config",
    "keywords": "linux tool Jekyll",
    "url": "/jekyll/0000-01-01-linux_config.html",
    "body": "Notes Linux config Change username 要改使用者名稱通常很麻煩，這個是一個我覺得比較好的做法，多了 Link 至少讓沒改到的地方能連結到新的 home How To Change Username On Ubuntu, Debian, Linux Mint Or Fedora Create a temporary user sudo adduser tempuser sudo usermod -aG sudo tempuser Login with tempuser sudo usermod -l ${newusername} -d /home/${newusername} -m ${oldusername} sudo groupmod -n ${newusername} ${oldusername} Create a symbolic link sudo ln -s /home/${newusername} /home/${oldusername} Login new username and delete temporary user sudo userdel -r tempuser Firewall ufw (Uncomplicated Firewall) # 如果要允許連線指定 port 可以輸入指令: sudo ufw allow &lt;port-number&gt; sudo ufw deny &lt;port-number&gt; # 只允許特定 IP 才能連線的話，可以輸入以下指令: sudo ufw allow from &lt;IP&gt; to any port &lt;port-number&gt; sudo ufw deny from &lt;IP&gt; to any port &lt;port-number&gt; # 只允許子網路可以連線到，可以輸入以下指令: sudo ufw allow from &lt;IP-with-mask&gt; to any port &lt;port-number&gt; sudo ufw deny from &lt;IP-with-mask&gt; to any port &lt;port-number&gt; sudo ufw allow from 159.66.109.0/24 to any port 22 # 刪除已經建立的規則: sudo ufw status numbered # 知道指定編號可以輸入以下指令來刪除規則: sudo ufw delete &lt;rule-number&gt; Network config ubuntu wifi config $ sudo vim /etc/netplan/50-cloud-init.yaml # This file is generated from information provided by the datasource. Changes # to it will not persist across an instance reboot. To disable cloud-init's # network configuration capabilities, write a file # /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg with the following: # network: {config: disabled} network: ethernets: eth0: dhcp4: true optional: true version: 2 wifis: wl0: optional: true access-points: \"SSID-NAME-HERE\": password: \"PASSWORD-HERE\" dhcp4: true debian static ip config sudo vim /etc/network/interface # This file describes the network interfaces available on your system # and how to activate them. For more information, see interfaces(5). source /etc/network/interfaces.d/* # The loopback network interface auto lo iface lo inet loopback # The primary network interface allow-hotplug ens160 iface ens160 inet static address ${address} netmask ${netmask} gateway ${gateway} # This an autoconfigured IPv6 interface iface ens160 inet6 auto sudo systemctl restart networking.service fix Wifi Mt7601u driver How to fix wireless adapter Mt7601u not working, Can run correctly on kernel 5.15. Reference git clone https://github.com/jeremyb31/mt7601u.git sudo dkms add ./mt7601u sudo dkms install mt7601u/1.0 ZeroTier Route Config Install ZeroTier and add route to between vLan and Physical Lan curl -s https://install.zerotier.com | sudo bash sudo zerotier-cli join $NETWORK_ID Add to zerotier network, and Authorize it at https://my.zerotier.com/network/$NETWORK_ID. Configure the ZeroTier managed route: At my.zerotier.com/network/$NETWORK_ID -&gt; Settings -&gt; Managed Routes, adds another route to every device joined to the ZeroTier network. Destination (Via) $PHY_SUB $ZT_ADDR 192.168.100.0/23 172.27.0.1 Edit /etc/sysctl.conf to uncomment net.ipv4.ip_forward. This enables forwarding at boot. sudo sysctl -w net.ipv4.ip_forward=1 # Add you network interface to shell variables. PHY_IFACE=eth0; ZT_IFACE=zt7nnig26 Add ip forwarding rules in iptables. sudo iptables -t nat -A POSTROUTING -o $PHY_IFACE -j MASQUERADE sudo iptables -A FORWARD -i $PHY_IFACE -o $ZT_IFACE -m state --state RELATED,ESTABLISHED -j ACCEPT sudo iptables -A FORWARD -i $ZT_IFACE -o $PHY_IFACE -j ACCEPT # Save iptables rules for next boot. sudo apt install iptables-persistent sudo bash -c iptables-save &gt; /etc/iptables/rules.v4 Last using sudo iptables -L -v to check iptables rules. Other ulimit ulimit 可以用來限制 shell 執行程式所需的資源 ulimit [options] [limit] ulimit Man Page Last Edit 30-09-2023 ulimit."
  },"/jekyll/0000-01-01-leetcode_guide.html": {
    "title": "Leetcode | Master Guide",
    "keywords": "leetcode algorithm Jekyll",
    "url": "/jekyll/0000-01-01-leetcode_guide.html",
    "body": "Notes leetcode problem Reference to the leetcode-master guide for the sequence of questions. Array 704. Binary search 35. Search Insert Position 34. Find First and Last Position of Element in Sorted Array 69. Sqrt(x) 367. Valid Perfect Square 27. Remove Element 26. Remove Duplicates from Sorted Array 80. Remove Duplicates from Sorted Array II 283. Move Zeroes 844. Backspace String Compare 977. Squares of a Sorted Array 4. Median of Two Sorted Arrays 59. Spiral Matrix II 209. Minimum Size Subarray Sum Linkedlist 203. Remove Linked List Elements 707. Design Linked List 206. Reverse Linked List 24. Swap Nodes in Pairs 19. Remove Nth Node From End of List 160. Intersection of Two Linked Lists 141. Linked List Cycle 142. Linked List Cycle II 21. Merge Two Sorted Lists 23. Merge k Sorted Lists 25. Reverse Nodes in k-Group 83. Remove Duplicates from Sorted List Linkedlist Summarize String 344. Reverse String 541. Reverse String II 151. Reverse Words in a String 58. Length of Last Word 28. Find the Index of the First Occurrence in a String 459. Repeated Substring Pattern String Summarize Hash 242. Valid Anagram 1002. Find Common Characters 349. Intersection of Two Arrays 202. Happy Number 454. 4Sum II 383. Ransom Note 15. 3Sum (Hash) 18. 4Sum (Hash) 459. Repeated Substring Pattern 268. Missing Number 41. First Missing Positive Two Pointer 1365. How Many Numbers Are Smaller Than the Current Number 125. Valid Palindrome 5. Longest Palindromic Substring 15. 3Sum (E) 18. 4Sum (E) 42. Trapping Rain Water Queue &amp; Stack 232. Implement Queue using Stacks 225. Implement Stack using Queues 20. Valid Parentheses 1047. Remove All Adjacent Duplicates In String 150. Evaluate Reverse Polish Notation 239. Sliding Window Maximum 347. Top K Frequent Elements Stack&amp;Queue Summarize Binary Tree Build Binary Tree for Array Recursion Binary Tree Traversal Iteration Binary Tree Traversal Iteration Binary Trees Unified Method Binary Tree Level Order Traversal N-ary Tree Traversal 226. Invert Binary Tree 559. Maximum Depth of N-ary Tree 783. Minimum Distance Between BST Nodes Binary Tree Summarize 1 100. Same Tree 572. Subtree of Another Tree 101. Symmetric Tree 222. Count Complete Tree Nodes 513. Find Bottom Left Tree Value 110. Balanced Binary Tree 257. Binary Tree Paths 112. Path Sum &amp; II &amp; III Binary Tree Summarize 2 Backtracking 77. Combinations 17. Letter Combinations of a Phone Number 39. Combination Sum I &amp; II &amp; III Backtracking Summarize 131. Palindrome Partitioning 93. Restore IP Addresses 78. Subsets Backtracking Summarize 2 51. N-Queens 52. N-Queens II Greedy Algorithm 55. Jump Game I &amp; II 455. Assign Cookies Dynamic Programming 509. Fibonacci Number 70. Climbing Stairs Other 1. Two sum 2. Add Two Numbers 7. Reverse Integer 11. Container With Most Water 13. Roman to Integer 16. 3Sum_Closest 49. Group Anagrams 50. Pow(x, n) 67. Add Binary 989. Add to Array-Form of Integer 1523. Count Odd Numbers in an Interval Range 1979. Find Greatest Common Divisor of Array Last Edit 10-02-2023 59. Spiral Matrix II."
  },"/jekyll/0000-01-01-editor_envirmnment.html": {
    "title": "Tool | Edirot Guide",
    "keywords": "tool Jekyll",
    "url": "/jekyll/0000-01-01-editor_envirmnment.html",
    "body": "Notes editor environment VScode for Java Add Java jdk in vscode in setting.json \"java.configuration.runtimes\": [ { \"name\": \"JavaSE-17\", \"path\": \"/usr/bin/java\" }, ] Hide Run | Debug in editor Editor: Code Lens Controls whether the editor shows CodeLens. Hide Inlay Hints Editor › Inlay Hints: Enabled Enables the inlay hints in the editor. on -&gt; off [Vscode Debugger for C/C++ using GDB] Install gdb in Linux { \"name\": \"C++ Launch\", \"type\": \"cppdbg\", \"request\": \"launch\", \"program\": \"${workspaceFolder}/target.out\", \"stopAtEntry\": false, \"customLaunchSetupCommands\": [ { \"text\": \"target-run\", \"description\": \"run target\", \"ignoreFailures\": false } ], \"launchCompleteCommand\": \"exec-run\", \"linux\": { \"MIMode\": \"gdb\", \"miDebuggerPath\": \"/usr/bin/gdb\" }, \"osx\": { \"MIMode\": \"lldb\" }, \"windows\": { \"MIMode\": \"gdb\", \"miDebuggerPath\": \"C:\\\\MinGw\\\\bin\\\\gdb.exe\" } } Last Edit 09-29-2023 12:22"
  }}
